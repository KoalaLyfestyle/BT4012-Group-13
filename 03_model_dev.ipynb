{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13b1d2f",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Dropped id and statuses_count, log transformed numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c9c7be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.8517230255621744\n"
     ]
    }
   ],
   "source": [
    "# remove: CV AUC: 0.8238099273463011\n",
    "# set caps: CV AUC: 0.8214540494567781\n",
    "# log transform: CV AUC: 0.8521549006920062\n",
    "# dropped 'id' and 'statuses_count', managed outliers from numerical variables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def build_pipeline(numeric_cols, categorical_cols):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Outlier removal before modeling\n",
    "def remove_outliers(df, numeric_cols):\n",
    "    num_cols_for_outlier = [col for col in numeric_cols if col not in ['id', 'target']]\n",
    "    z_scores = np.abs(df[num_cols_for_outlier].apply(zscore))\n",
    "    outlier_mask = (z_scores > 3).any(axis=1)\n",
    "    print(f\"Total rows with any outlier (z-score > 3): {outlier_mask.sum()}\")\n",
    "    df_no_outliers = df[~outlier_mask].reset_index(drop=True)\n",
    "    print(f\"Shape after outlier removal: {df_no_outliers.shape}\")\n",
    "    return df_no_outliers\n",
    "\n",
    "def set_caps(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            lower_bound = df[col].quantile(0.05)\n",
    "            upper_bound = df[col].quantile(0.95)\n",
    "            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    return df\n",
    "\n",
    "def log_transform(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            df[col] = df[col].apply(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "\n",
    "    X = train.drop(columns=[\"target\", \"id\", \"statuses_count\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # Remove outliers\n",
    "    train = pd.concat([X, y], axis=1)\n",
    "    # train = remove_outliers(train, numeric_cols)\n",
    "    # train = set_caps(train, numeric_cols)\n",
    "    train = log_transform(train, numeric_cols.drop([\"account_age_days\"], errors='ignore'))\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    model = build_pipeline(numeric_cols, categorical_cols)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\")\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Save model\n",
    "    # joblib.dump(model, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/logistic_regression.pkl\")\n",
    "\n",
    "    # Predict on test\n",
    "    test_probs = model.predict_proba(test)[:, 1]\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5799cfa",
   "metadata": {},
   "source": [
    "Experimented with different handling of outliers: \n",
    "- removing them\n",
    "- set caps\n",
    "- log transform\n",
    "- caps + log transform\n",
    "\n",
    "Best AUC score is from doing log transform on all the numerical variables. \n",
    "\n",
    "However, I realised that not all need to be transformed, since account_age_days distribution is not very skewed. Then did log transformation on all numerical columns except for account_age_days. But AUC score fell to 0.8517230255621744. Noticed that this may be because account_age_days has a high correlation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.8510820828185515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86      3485\n",
      "           1       0.74      0.64      0.69      1757\n",
      "\n",
      "    accuracy                           0.80      5242\n",
      "   macro avg       0.78      0.76      0.77      5242\n",
      "weighted avg       0.80      0.80      0.80      5242\n",
      "\n",
      "Best hyperparameters: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "X = train.drop(columns=[\"target\", \"id\", \"statuses_count\"])\n",
    "y = train[\"target\"]\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Log-transform skewed features\n",
    "for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            X[col] = X[col].apply(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"classifier__C\": [0.01, 0.1, 1, 10],   # regularization strength\n",
    "    \"classifier__penalty\": [\"l2\"],\n",
    "    \"classifier__solver\": [\"lbfgs\"]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_probs = grid.predict_proba(X_val)[:, 1]\n",
    "auc = roc_auc_score(y_val, val_probs)\n",
    "print(\"Validation AUC:\", auc)\n",
    "print(classification_report(y_val, grid.predict(X_val)))\n",
    "print(\"Best hyperparameters:\", grid.best_params_)\n",
    "# best_params = {k.replace(\"classifier__\", \"\"): v for k, v in grid.best_params_.items()}\n",
    "\n",
    "\n",
    "# Retrain on full train + validation for final model\n",
    "X_full = pd.concat([X_train, X_val])\n",
    "y_full = pd.concat([y_train, y_val])\n",
    "final_model = grid.best_estimator_\n",
    "final_model.fit(X_full, y_full)\n",
    "# final_model = Pipeline([\n",
    "#     (\"preprocessor\", preprocessor),\n",
    "#     (\"classifier\", LogisticRegression(**best_params))\n",
    "# ])\n",
    "\n",
    "\n",
    "# Save final model\n",
    "joblib.dump(final_model, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/logistic_regression_final.pkl\")\n",
    "\n",
    "# Predict on test\n",
    "test = test.drop(columns=[\"id\", \"statuses_count\"])\n",
    "test = log_transform(test, numeric_cols)\n",
    "\n",
    "test_probs = model.predict_proba(test)[:, 1]\n",
    "submission = pd.DataFrame({\n",
    "    \"index\": test.index,\n",
    "    \"target\": test_probs\n",
    "})\n",
    "submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f933b5",
   "metadata": {},
   "source": [
    "Performed GridsearchCV to find best hyperparameter.\n",
    "\n",
    "Best hyperparameters: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
    "Validation AUC: 0.8510820828185515\n",
    "\n",
    "Note: AUC decreased after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "467b6d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:53:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:53:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:53:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:53:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:53:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:54:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:54:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:54:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:54:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:54:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:55:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:56:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:57:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:57:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:57:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:57:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:57:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:57:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:58:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:58:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:58:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:59:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:59:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:59:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:59:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:59:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:00:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:00:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:00:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:00:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:01:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:01:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:02:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:02:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:02:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:02:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:02:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:02:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:03:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:03:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:03:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:03:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:03:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:03:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:03:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:04:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:04:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:04:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:04:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:07:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:07:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:08:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:08:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:10:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:10:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:10:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:11:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:11:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:12:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:12:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:12:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:12:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:12:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:12:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:13:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:13:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:14:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:14:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:15:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:16:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:16:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:17:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:17:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:18:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:18:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:18:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:18:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:18:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:19:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:25:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:25:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:25:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:25:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:26:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:26:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:26:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:26:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:26:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:32:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:32:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:32:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:32:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:33:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:33:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:33:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:33:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:33:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:33:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:33:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:33:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:34:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:34:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:35:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:35:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:35:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:35:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:35:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:35:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:36:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:36:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:36:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:36:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:36:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:36:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:37:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:37:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:37:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:37:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:37:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:37:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:37:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:38:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC from CV: 0.9371778751271576\n",
      "Best Params: {'classifier__colsample_bytree': np.float64(0.8170784332632994), 'classifier__learning_rate': np.float64(0.052277267492428794), 'classifier__max_depth': 9, 'classifier__n_estimators': 400, 'classifier__subsample': np.float64(0.6298202574719083)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [23:39:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from scipy.stats import zscore\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "def build_pipeline(numeric_cols, categorical_cols):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Outlier removal before modeling\n",
    "def remove_outliers(df, numeric_cols):\n",
    "    num_cols_for_outlier = [col for col in numeric_cols if col not in ['id', 'target']]\n",
    "    z_scores = np.abs(df[num_cols_for_outlier].apply(zscore))\n",
    "    outlier_mask = (z_scores > 3).any(axis=1)\n",
    "    print(f\"Total rows with any outlier (z-score > 3): {outlier_mask.sum()}\")\n",
    "    df_no_outliers = df[~outlier_mask].reset_index(drop=True)\n",
    "    print(f\"Shape after outlier removal: {df_no_outliers.shape}\")\n",
    "    return df_no_outliers\n",
    "\n",
    "def set_caps(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            lower_bound = df[col].quantile(0.05)\n",
    "            upper_bound = df[col].quantile(0.95)\n",
    "            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    return df\n",
    "\n",
    "def log_transform(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            df[col] = df[col].apply(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "\n",
    "    X = train.drop(columns=[\"target\", \"id\", \"statuses_count\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # Preprocess training data\n",
    "    train = pd.concat([X, y], axis=1)\n",
    "    # train = remove_outliers(train, numeric_cols)\n",
    "    # train = set_caps(train, numeric_cols)\n",
    "    train = log_transform(train, numeric_cols)\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    model = build_pipeline(numeric_cols, categorical_cols)\n",
    "\n",
    "    # Hyperparameter search space for XGBoost\n",
    "    param_dist = {\n",
    "        \"classifier__n_estimators\": randint(100, 600),\n",
    "        \"classifier__max_depth\": randint(3, 10),\n",
    "        \"classifier__learning_rate\": uniform(0.01, 0.3),\n",
    "        \"classifier__subsample\": uniform(0.6, 0.4),\n",
    "        \"classifier__colsample_bytree\": uniform(0.6, 0.4)\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=30,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X, y)\n",
    "    print(\"Best AUC from CV:\", search.best_score_)\n",
    "    print(\"Best Params:\", search.best_params_)\n",
    "\n",
    "    # Train final model with best params\n",
    "    final_model = search.best_estimator_\n",
    "    final_model.fit(X, y)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(final_model, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_tuned.pkl\")\n",
    "\n",
    "    # Predict on test\n",
    "    # test = test.drop(columns=[\"id\", \"statuses_count\"])\n",
    "    # test = log_transform(test, numeric_cols)\n",
    "\n",
    "    # test_probs = final_model.predict_proba(test)[:, 1]\n",
    "    # submission = pd.DataFrame({\n",
    "    #     \"index\": test.index,\n",
    "    #     \"target\": test_probs\n",
    "    # })\n",
    "    # submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbfad7",
   "metadata": {},
   "source": [
    "Best AUC from CV: 0.9371778751271576\n",
    "Best Params: {'classifier__colsample_bytree': np.float64(0.8170784332632994), 'classifier__learning_rate': np.float64(0.052277267492428794), 'classifier__max_depth': 9, 'classifier__n_estimators': 400, 'classifier__subsample': np.float64(0.6298202574719083)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42e5c9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [16:48:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [16:48:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [16:48:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [16:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [16:48:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9412623044669735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [16:48:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'followers_friends_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'followers_friends_ratio'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Predict on test\u001b[39;00m\n\u001b[32m    107\u001b[39m test = test.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstatuses_count\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprofile_background_image_url\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprofile_image_url\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m test = \u001b[43mlog_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# test_probs = model.predict_proba(test)[:, 1]\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# submission = pd.DataFrame({\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m#     \"index\": test.index,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# print(\"Submission file created.\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mlog_transform\u001b[39m\u001b[34m(df, numeric_cols)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_cols:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         df[col] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np.log1p(x) \u001b[38;5;28;01mif\u001b[39;00m x > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'followers_friends_ratio'"
     ]
    }
   ],
   "source": [
    "# log transform CV AUC: 0.9359646121770959\n",
    "# log + cap CV AUC: 0.9331886814105024\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from scipy.stats import zscore\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def build_pipeline(numeric_cols, categorical_cols):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\"\n",
    "        ))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Outlier removal before modeling\n",
    "def remove_outliers(df, numeric_cols):\n",
    "    num_cols_for_outlier = [col for col in numeric_cols if col not in ['id', 'target']]\n",
    "    z_scores = np.abs(df[num_cols_for_outlier].apply(zscore))\n",
    "    outlier_mask = (z_scores > 3).any(axis=1)\n",
    "    print(f\"Total rows with any outlier (z-score > 3): {outlier_mask.sum()}\")\n",
    "    df_no_outliers = df[~outlier_mask].reset_index(drop=True)\n",
    "    print(f\"Shape after outlier removal: {df_no_outliers.shape}\")\n",
    "    return df_no_outliers\n",
    "\n",
    "def set_caps(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            lower_bound = df[col].quantile(0.05)\n",
    "            upper_bound = df[col].quantile(0.95)\n",
    "            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    return df\n",
    "\n",
    "def log_transform(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            df[col] = df[col].apply(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "\n",
    "    # X = train.drop(columns=[\"target\", \"id\", \"statuses_count\"])\n",
    "    X = train.drop(columns=[\"target\", \"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    log_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day', 'account_age_days']\n",
    "    # numeric_cols=log_cols\n",
    "\n",
    "    # Preprocess training data\n",
    "    train = pd.concat([X, y], axis=1)\n",
    "    # train = remove_outliers(train, numeric_cols)\n",
    "    # train = set_caps(train, numeric_cols)\n",
    "    train = log_transform(train, log_cols)\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    model = build_pipeline(numeric_cols, categorical_cols)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\")\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(model, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost.pkl\")\n",
    "    print(\"Model saved\")\n",
    "    # Predict on test\n",
    "    test = test.drop(columns=[\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\"])\n",
    "    test = log_transform(test, numeric_cols)\n",
    "\n",
    "    # test_probs = model.predict_proba(test)[:, 1]\n",
    "    # submission = pd.DataFrame({\n",
    "    #     \"index\": test.index,\n",
    "    #     \"target\": test_probs\n",
    "    # })\n",
    "    # submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    # print(\"Submission file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f492e",
   "metadata": {},
   "source": [
    "Dropping \"created_at\", \"profile_background_image_url\", \"profile_image_url\", \"screen_name\" in addition to id and statuses count caused the AUC score to fall... for both log only and log + cap\n",
    "\n",
    "keeping screen name increased the AUC score slightly, but not better than only id + sc (very close)\n",
    "keep screen_name + created_at increased AUC score to CV AUC: 0.9360743130592096 (slight increase)\n",
    "Conclusion: drop only id, statuses_count, profile_background_image_url & profile_image_url. And only do log transformation\n",
    "but the test accuracy fell slightly. But it would make sense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2344c273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created.\n"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "loaded_model = joblib.load(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost.pkl\")\n",
    "test_probs = loaded_model.predict_proba(test)[:, 1]\n",
    "submission = pd.DataFrame({\n",
    "    \"index\": test.index,\n",
    "    \"target\": test_probs\n",
    "})\n",
    "submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "print(\"Submission file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527cfdd",
   "metadata": {},
   "source": [
    "## Introducing feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914337ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:15:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:15:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:15:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:15:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:15:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9417887579741822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:15:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Submission file created.\n"
     ]
    }
   ],
   "source": [
    "#Introduced feature engineering. \n",
    "# NEW COLUMNS: followers_friends_ratio, favourites_per_status, followers_per_day, statuses_per_follower\n",
    "# cap95 + log transform CV AUC: 0.9400837181192166\n",
    "# cap99 + log transform CV AUC: 0.9416609251349648\n",
    "# did not log transform account_age_days because left skewed and not extremely skewed\n",
    "\n",
    "# log transformed new feautures as well\n",
    "# cap99 + log transform CV AUC: 0.9417300027451091\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from scipy.stats import zscore\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def build_pipeline(numeric_cols, categorical_cols):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\"\n",
    "        ))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Outlier removal before modeling\n",
    "def remove_outliers(df, numeric_cols):\n",
    "    num_cols_for_outlier = [col for col in numeric_cols if col not in ['id', 'target']]\n",
    "    z_scores = np.abs(df[num_cols_for_outlier].apply(zscore))\n",
    "    outlier_mask = (z_scores > 3).any(axis=1)\n",
    "    df_no_outliers = df[~outlier_mask].reset_index(drop=True)\n",
    "    return df_no_outliers\n",
    "\n",
    "def set_caps(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            lower_bound = df[col].quantile(0.01)\n",
    "            upper_bound = df[col].quantile(0.99)\n",
    "            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    return df\n",
    "\n",
    "def log_transform(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            df[col] = df[col].apply(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "    return df\n",
    "\n",
    "def apply_feature_engineering(data, training_caps=None):\n",
    "    \"\"\"Apply feature engineering to any dataset\"\"\"\n",
    "    def safe_ratio(num, denom, default=0):\n",
    "        return np.where(denom == 0, default, num / denom)\n",
    "    # Create ratio features\n",
    "    data['followers_friends_ratio'] = safe_ratio(data['followers_count'], data['friends_count'])\n",
    "    data['favourites_per_status'] = safe_ratio(data['favourites_count'], data['statuses_count'])\n",
    "    data['followers_per_day'] = safe_ratio(data['followers_count'], data['account_age_days'])\n",
    "    data['statuses_per_follower'] = safe_ratio(data['statuses_count'], data['followers_count'])\n",
    "    \n",
    "    # Apply capping\n",
    "    if training_caps is None:\n",
    "        # Calculate caps (for training data)\n",
    "        caps = {}\n",
    "        for col in ['followers_friends_ratio', 'favourites_per_status', 'statuses_per_follower', 'followers_per_day']:\n",
    "        # for col in ['followers_friends_ratio']:\n",
    "            caps[col] = data[col].quantile(0.99)\n",
    "            data[f'{col}_capped'] = np.minimum(data[col], caps[col])\n",
    "        data.drop(columns=['followers_friends_ratio', 'favourites_per_status', 'statuses_per_follower', 'followers_per_day'], inplace=True)\n",
    "        return data, caps\n",
    "    else:\n",
    "        # Use provided caps (for test data)\n",
    "        for col in ['followers_friends_ratio', 'favourites_per_status', 'statuses_per_follower', 'followers_per_day']:\n",
    "        # for col in ['followers_friends_ratio']:\n",
    "            data[f'{col}_capped'] = np.minimum(data[col], training_caps[col])\n",
    "        data.drop(columns=['followers_friends_ratio', 'favourites_per_status', 'statuses_per_follower', 'followers_per_day'], inplace=True)\n",
    "        return data\n",
    "    \n",
    "def drop_columns(data):\n",
    "    return data.drop(columns=[\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    train, caps = apply_feature_engineering(train)\n",
    "\n",
    "    # X = train.drop(columns=[\"target\", \"id\", \"statuses_count\"])\n",
    "    X = drop_columns(train)\n",
    "    X = X.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    log_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    new_features = ['followers_friends_ratio_capped', 'favourites_per_status_capped', 'followers_per_day_capped', 'statuses_per_follower_capped']\n",
    "    # log_cols = numeric_cols\n",
    "\n",
    "    # Preprocess training data\n",
    "    X = set_caps(X, numeric_cols)\n",
    "    X = log_transform(X, log_cols + new_features)\n",
    "\n",
    "\n",
    "    model = build_pipeline(numeric_cols, categorical_cols)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\")\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(model, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost.pkl\")\n",
    "    print(\"Model saved\")\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    \n",
    "    test = apply_feature_engineering(test, training_caps=caps)\n",
    "    test = drop_columns(test)\n",
    "    test = set_caps(test, numeric_cols)\n",
    "    test = log_transform(test, log_cols)\n",
    "\n",
    "    test_probs = model.predict_proba(test)[:, 1]\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\"Submission file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e79c6f",
   "metadata": {},
   "source": [
    "Adding these features increased the AUC score of train, but reduced it sharply for test. Signs of overfitting. Now, try to look at the distribution of the created variables to see which ones to log transform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd0ac9",
   "metadata": {},
   "source": [
    "change: did not log transfrom account_age days\n",
    "dropped columns: [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\"]\n",
    "log columns: ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "new feature(s): followers_friends_ratio\n",
    "CV AUC: 0.9363081153615529\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d3666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:27:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:27:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:27:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:27:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9419004922555446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:28:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Submission file created.\n"
     ]
    }
   ],
   "source": [
    "#Introduced feature engineering. \n",
    "# NEW COLUMNS: followers_friends_ratio, favourites_per_status, followers_per_day, statuses_per_follower\n",
    "# cap95 + log transform CV AUC: 0.9400837181192166\n",
    "# cap99 + log transform CV AUC: 0.9416609251349648\n",
    "# did not log transform account_age_days because left skewed and not extremely skewed\n",
    "\n",
    "# log transformed new feautures as well\n",
    "# cap99 + log transform CV AUC: 0.9417300027451091\n",
    "\n",
    "\n",
    "#did not log transform the new features, merely capped them\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from scipy.stats import zscore\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def build_pipeline(numeric_cols, categorical_cols):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\"\n",
    "        ))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Outlier removal before modeling\n",
    "def remove_outliers(df, numeric_cols):\n",
    "    num_cols_for_outlier = [col for col in numeric_cols if col not in ['id', 'target']]\n",
    "    z_scores = np.abs(df[num_cols_for_outlier].apply(zscore))\n",
    "    outlier_mask = (z_scores > 3).any(axis=1)\n",
    "    df_no_outliers = df[~outlier_mask].reset_index(drop=True)\n",
    "    return df_no_outliers\n",
    "\n",
    "def set_caps(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            lower_bound = df[col].quantile(0.01)\n",
    "            upper_bound = df[col].quantile(0.99)\n",
    "            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    return df\n",
    "\n",
    "def log_transform(df, numeric_cols):\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['id', 'target']:\n",
    "            df[col] = df[col].apply(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "    return df\n",
    "\n",
    "def apply_feature_engineering(data, training_caps=None):\n",
    "    \"\"\"Apply feature engineering to any dataset\"\"\"\n",
    "    def safe_ratio(num, denom, mean_val=0):\n",
    "        return np.where(denom == 0, mean_val, num / denom)\n",
    "    # Create ratio features\n",
    "    data['followers_friends_ratio'] = safe_ratio(data['followers_count'], data['friends_count'], mean_val=data['followers_count'].median())\n",
    "    data['favourites_per_status'] = safe_ratio(data['favourites_count'], data['statuses_count'], mean_val=data['favourites_count'].median())\n",
    "    data['followers_per_day'] = safe_ratio(data['followers_count'], data['account_age_days'], mean_val=data['followers_count'].median())\n",
    "    data['statuses_per_follower'] = safe_ratio(data['statuses_count'], data['followers_count'], mean_val=data['statuses_count'].median())\n",
    "\n",
    "    # Apply capping\n",
    "    if training_caps is None:\n",
    "        # Calculate caps (for training data)\n",
    "        caps = {}\n",
    "        for col in ['followers_friends_ratio', 'favourites_per_status', 'statuses_per_follower', 'followers_per_day']:\n",
    "        # for col in ['followers_friends_ratio', 'favourites_per_status', 'followers_per_day']:\n",
    "            caps[col] = data[col].quantile(0.99)\n",
    "            data[f'{col}_capped'] = np.minimum(data[col], caps[col])\n",
    "        data.drop(columns=['followers_friends_ratio', 'favourites_per_status', 'statuses_per_follower', 'followers_per_day'], inplace=True)\n",
    "        # data.drop(columns=['followers_friends_ratio', 'favourites_per_status', 'followers_per_day'], inplace=True)\n",
    "        return data, caps\n",
    "    else:\n",
    "        # Use provided caps (for test data)\n",
    "        for col in ['followers_friends_ratio', 'favourites_per_status', 'statuses_per_follower', 'followers_per_day']:\n",
    "        # for col in ['followers_friends_ratio', 'favourites_per_status', 'followers_per_day']:\n",
    "            data[f'{col}_capped'] = np.minimum(data[col], training_caps[col])\n",
    "        data.drop(columns=['followers_friends_ratio', 'favourites_per_status', 'statuses_per_follower', 'followers_per_day'], inplace=True)\n",
    "        # data.drop(columns=['followers_friends_ratio', 'favourites_per_status', 'followers_per_day'], inplace=True)\n",
    "        return data\n",
    "    \n",
    "def drop_columns(data):\n",
    "    return data.drop(columns=[\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    train, caps = apply_feature_engineering(train)\n",
    "\n",
    "    # X = train.drop(columns=[\"target\", \"id\", \"statuses_count\"])\n",
    "    X = drop_columns(train)\n",
    "    X = X.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    log_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    new_features = ['followers_friends_ratio_capped', 'favourites_per_status_capped', 'followers_per_day_capped', 'statuses_per_follower_capped']\n",
    "    # new_features = ['followers_friends_ratio_capped', 'favourites_per_status_capped', 'followers_per_day_capped']\n",
    "    # log_cols = numeric_cols\n",
    "\n",
    "    # Preprocess training data\n",
    "    X = set_caps(X, numeric_cols)\n",
    "    X = log_transform(X, log_cols + new_features)\n",
    "\n",
    "\n",
    "    model = build_pipeline(numeric_cols, categorical_cols)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\")\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(model, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost.pkl\")\n",
    "    print(\"Model saved\")\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    \n",
    "    test = apply_feature_engineering(test, training_caps=caps)\n",
    "    test = drop_columns(test)\n",
    "    test = set_caps(test, numeric_cols)\n",
    "    test = log_transform(test, log_cols)\n",
    "\n",
    "    test_probs = model.predict_proba(test)[:, 1]\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\"Submission file created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:45:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_87570/6201625.py:29: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[f\"{col}_capped\"] = X[col].clip(lower, upper)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_87570/6201625.py:29: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[f\"{col}_capped\"] = X[col].clip(lower, upper)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_87570/6201625.py:29: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[f\"{col}_capped\"] = X[col].clip(lower, upper)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:46:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9416977561208111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [12:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved\n",
      " Submission created\n",
      "[0.0112089  0.0404054  0.00825425 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X):\n",
    "    X = X.copy()\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "    return X\n",
    "\n",
    "def cap_and_log(X):\n",
    "\n",
    "    X = X.copy()\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        lower, upper = X[col].quantile([0.01, 0.99])\n",
    "        X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    X_temp = drop_columns(cap_and_log(apply_feature_engineering(X)))\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_probs = pipeline.predict_proba(test)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n",
    "    print(pipeline.named_steps['model'].feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc09a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float32(0.0), 'cat__created_at_2006-07-13 09:05:49')\n"
     ]
    }
   ],
   "source": [
    "importances = pipeline.named_steps[\"model\"].feature_importances_\n",
    "sorted_features = sorted(zip(importances, pipeline.named_steps[\"preprocessor\"].get_feature_names_out()), reverse=True)\n",
    "print(sorted_features[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c595a5b",
   "metadata": {},
   "source": [
    "Newly created features: \n",
    "Adds:\n",
    "      - description_has_bot (1/0)\n",
    "      - description_has_link (1/0)\n",
    "      - description_len (int)\n",
    "      - description_word_count (int)\n",
    "\n",
    "    Adds:\n",
    "      - friends_per_day\n",
    "      - friends_per_day_capped\n",
    "      - friends_per_day_log  (log1p of capped)\n",
    "      - friends_per_logday_log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec15b1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [17:57:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [17:58:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [17:58:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [17:58:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [17:58:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9433843131061425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [17:58:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/2164295402.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X):\n",
    "    X = X.copy()\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        link_pattern = r'(http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        emoji_re = re.compile(\n",
    "            r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "            r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "            r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "            r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "            r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "            r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "            r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "            r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        # X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "    return X\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    X_temp = drop_columns(cap_and_log(apply_feature_engineering(X)))\n",
    "    # X_temp = drop_columns((apply_feature_engineering(X)))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_probs = pipeline.predict_proba(test)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c455816",
   "metadata": {},
   "source": [
    "Adding:\n",
    "- lang binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:33:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:33:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:33:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:33:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:33:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9428855810390747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [22:33:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_89717/203976043.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X):\n",
    "    X = X.copy()\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        link_pattern = r'(http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        emoji_re = re.compile(\n",
    "            r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "            r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "            r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "            r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "            r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "            r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "            r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "            r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "\n",
    "    # === Language grouping ===\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        # high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af', 'ja', 'cy', 'so']     # > 0.4 bot rate\n",
    "        low_bot = [ 'ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']     # > 0.5 bot rate\n",
    "        mid_bot = ['ja', 'cy', 'so']                     # 0.40.5 bot rate\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he'] # < 20 samples\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            # ['high_bot_lang', 'mid_bot_lang', 'english'],\n",
    "            # ['high_bot_lang','low_bot_lang','english'],\n",
    "            # ['high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            ['low_freq_lang', 'high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "    return X\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \"description\", \"lang\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    X_temp = drop_columns(cap_and_log(apply_feature_engineering(X)))\n",
    "    # X_temp = drop_columns((apply_feature_engineering(X)))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_probs = pipeline.predict_proba(test)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5bdee3",
   "metadata": {},
   "source": [
    "current: CV AUC: 0.9431187327116781\n",
    "best for introducing lang. but still worse than without lang\n",
    "but accuracy improve: Public score: 0.93732\n",
    "\n",
    "normal - CV AUC: 0.9431187327116781\n",
    "friends_per_day -- CV AUC: 0.9428855810390747\n",
    "friends_per_day (use log inside cap and log) -- CV AUC: 0.9428855810390747\n",
    "friends_per_day_log - CV AUC: 0.9428855810390747\n",
    "friends_per_logday -- CV AUC: 0.9428048430903615\n",
    "friends_per_logday_log - CV AUC: 0.9428045163578505\n",
    "\n",
    "tried adding friends_per_day -- public score slightly fell to 0.93729\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b65df",
   "metadata": {},
   "source": [
    "add\n",
    "- location binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f703018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2640484755.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2640484755.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2640484755.py:62: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_follow'] = desc.str.contains(r'\\b(follow|subscribe)\\b').fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [20:53:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [20:54:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [20:54:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [20:54:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [20:54:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9449133027189713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [20:54:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2640484755.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2640484755.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2640484755.py:62: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_follow'] = desc.str.contains(r'\\b(follow|subscribe)\\b').fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None):\n",
    "    X = X.copy()\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        link_pattern = r'(http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        emoji_re = re.compile(\n",
    "            r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "            r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "            r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "            r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "            r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "            r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "            r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "            r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "        # X['description_has_follow'] = desc.str.contains(r'follow|subscribe').fillna(False).astype(int)\n",
    "        # follow or subscribe\n",
    "        X['description_has_follow'] = desc.str.contains(r'\\b(follow|subscribe)\\b').fillna(False).astype(int)\n",
    "        # screen name has bot\n",
    "        # X['screen_name_has_bot'] = X['screen_name'].fillna('').astype(str).str.lower().str.contains(r'bot').fillna(False).astype(int)\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "\n",
    "        X['description_has_follow'] = 0\n",
    "        # X['screen_name_has_bot'] = 0\n",
    "\n",
    "    # === Language grouping ===\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        # high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af', 'ja', 'cy', 'so']     # > 0.4 bot rate\n",
    "        low_bot = [ 'ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']     # > 0.5 bot rate\n",
    "        mid_bot = ['ja', 'cy', 'so']                     # 0.40.5 bot rate\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he'] # < 20 samples\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            # ['high_bot_lang', 'mid_bot_lang', 'english'],\n",
    "            # ['high_bot_lang','low_bot_lang','english'],\n",
    "            # ['high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            ['low_freq_lang', 'high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    # return X\n",
    "\n",
    "    # === Location binning and low-frequency flagging ===\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "# ...existing code...\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "\n",
    "    Usage:\n",
    "      # On training data (requires 'target'):\n",
    "      df_train, loc_groups = map_loc_bin(df_train, min_samples=30)\n",
    "\n",
    "      # On test data (reuse mapping from train):\n",
    "      df_test, _ = map_loc_bin(df_test, loc_groups=loc_groups)\n",
    "\n",
    "    Returns:\n",
    "      df (modified copy), loc_groups (dict with 'mapping', 'low_freq', 'groups')\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "        # bins = [0.0, 0.1, 0.3, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    # If no precomputed groups provided, build from df (training mode)\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        # Keep locations with enough samples for reliable proportion\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        # accept either full loc_groups dict or just mapping\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    # Map each location to a combined bin\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    # df['loc_low_freq'] = df['location'].isin(low_freq).astype(int)\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "\n",
    "    return df, loc_groups\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \"description\", \"lang\", \"location\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    # X_temp = drop_columns(cap_and_log(apply_feature_engineering(X)))\n",
    "    X_temp = drop_columns(cap_and_log(X))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    # model = XGBClassifier(\n",
    "    #     n_estimators=300,\n",
    "    #     learning_rate=0.05,\n",
    "    #     max_depth=6,\n",
    "    #     subsample=0.8,\n",
    "    #     colsample_bytree=0.8,\n",
    "    #     random_state=42,\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric=\"logloss\"\n",
    "    # )\n",
    "    # {'n_estimators': 350, 'learning_rate': 0.03008393676525409, 'max_depth': 9, 'subsample': 0.9809503155616375, 'colsample_bytree': 0.56044353273329, 'reg_alpha': 1.2338019395219242, 'reg_lambda': 1.6264975818536396, 'min_child_weight': 3, 'gamma': 0.36491328244932486}\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=350,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=9,\n",
    "        subsample=0.98,\n",
    "        colsample_bytree=0.56,\n",
    "        reg_alpha=1.23,\n",
    "        reg_lambda=1.63,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.36,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        # (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    # X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    X_fe, loc_groups = apply_feature_engineering(train)\n",
    "    X = X_fe.drop(columns=['target'])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "    # pipeline = build_pipeline(X_fe)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_fe, _ = apply_feature_engineering(test, loc_groups=loc_groups)\n",
    "    test_probs = pipeline.predict_proba(test_fe)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aae56f",
   "metadata": {},
   "source": [
    "loc binning\n",
    "CV AUC: 0.9432505489033669\n",
    "Public score: 0.93680\n",
    "public score fell   \n",
    "\n",
    "forgot to drop loc:\n",
    "after dropping\n",
    "CV AUC: 0.9433049129833012\n",
    "improvement from having lang\n",
    "Public score: 0.93734\n",
    "improved by 0.00002 aahhahha\n",
    "\n",
    "added is_geo_and_verified:\n",
    "CV AUC: 0.9449488278469541\n",
    "big improvement\n",
    "\n",
    "added description_has_follow and screen_name_has_bot\n",
    "CV AUC: 0.9446544454398239\n",
    "worsen\n",
    "screen_name_has_bot: CV AUC: 0.9448842968067707\n",
    "description_has_follow: CV AUC: 0.9449133027189713\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f12aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/162156847.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/162156847.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "[I 2025-10-09 18:09:15,998] Using an existing study with name 'xgb_pipeline_search' instead of creating a new one.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:09:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:09:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:10:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:10:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:11:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:11:32,827] Trial 50 finished with value: 0.9426452138220162 and parameters: {'n_estimators': 400, 'learning_rate': 0.011995101272587736, 'max_depth': 10, 'subsample': 0.7499461994610046, 'colsample_bytree': 0.7812721473733931, 'reg_alpha': 3.0240812337780505, 'reg_lambda': 1.2876211483262365, 'min_child_weight': 1, 'gamma': 1.3656242400401717}. Best is trial 17 with value: 0.943760023650133.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:11:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:11:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:12:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:12:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:12:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:12:56,098] Trial 51 finished with value: 0.9435664418651933 and parameters: {'n_estimators': 550, 'learning_rate': 0.019690975479951314, 'max_depth': 7, 'subsample': 0.6682333389673063, 'colsample_bytree': 0.772546089343278, 'reg_alpha': 1.1033977693977968, 'reg_lambda': 2.69951870392648, 'min_child_weight': 7, 'gamma': 0.4891281325245528}. Best is trial 17 with value: 0.943760023650133.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:12:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:13:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:13:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:13:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:14:05,117] Trial 52 finished with value: 0.9430576919218154 and parameters: {'n_estimators': 600, 'learning_rate': 0.015616038273513743, 'max_depth': 7, 'subsample': 0.6783444679823171, 'colsample_bytree': 0.7195038815010117, 'reg_alpha': 1.531655852502098, 'reg_lambda': 2.700392215225083, 'min_child_weight': 7, 'gamma': 0.8389475285659066}. Best is trial 17 with value: 0.943760023650133.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:14:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:14:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:14:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:14:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:14:51,724] Trial 53 finished with value: 0.9422604263281744 and parameters: {'n_estimators': 500, 'learning_rate': 0.019536980377588255, 'max_depth': 6, 'subsample': 0.7347805601545195, 'colsample_bytree': 0.7510599804306995, 'reg_alpha': 0.878452428027822, 'reg_lambda': 3.3566940604281177, 'min_child_weight': 8, 'gamma': 0.10236948262566947}. Best is trial 17 with value: 0.943760023650133.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:14:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:15:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:15:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:15:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:15:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:16:08,733] Trial 54 finished with value: 0.9437548773129055 and parameters: {'n_estimators': 550, 'learning_rate': 0.02357340581471383, 'max_depth': 7, 'subsample': 0.6958971628848855, 'colsample_bytree': 0.6754356896882936, 'reg_alpha': 1.065543398869873, 'reg_lambda': 2.316550081835513, 'min_child_weight': 6, 'gamma': 0.45201233780157646}. Best is trial 17 with value: 0.943760023650133.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:16:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:16:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:16:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:17:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:17:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:17:32,143] Trial 55 finished with value: 0.9439948794343774 and parameters: {'n_estimators': 450, 'learning_rate': 0.028874712636541507, 'max_depth': 8, 'subsample': 0.694416888617088, 'colsample_bytree': 0.6162673864396195, 'reg_alpha': 0.671735198312031, 'reg_lambda': 2.2864940455374025, 'min_child_weight': 6, 'gamma': 0.5831351481595487}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:17:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:17:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:17:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:18:29,589] Trial 56 finished with value: 0.9437510349293753 and parameters: {'n_estimators': 350, 'learning_rate': 0.02903716256553667, 'max_depth': 8, 'subsample': 0.8132616140040612, 'colsample_bytree': 0.6183494717007088, 'reg_alpha': 0.46189199923611257, 'reg_lambda': 2.229024636832665, 'min_child_weight': 5, 'gamma': 1.2295977084806111}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:18:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:18:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:18:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:18:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:18:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:18:59,421] Trial 57 finished with value: 0.9432971798351879 and parameters: {'n_estimators': 350, 'learning_rate': 0.04122803713610501, 'max_depth': 8, 'subsample': 0.848520412616015, 'colsample_bytree': 0.6154136711425267, 'reg_alpha': 0.3507047277249087, 'reg_lambda': 2.263880501545103, 'min_child_weight': 4, 'gamma': 2.484198451541318}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:18:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:19:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:19:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:19:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:19:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:19:56,811] Trial 58 finished with value: 0.9435731071831747 and parameters: {'n_estimators': 350, 'learning_rate': 0.028270320479940738, 'max_depth': 8, 'subsample': 0.8205024449543649, 'colsample_bytree': 0.5753670507131374, 'reg_alpha': 0.6496905405983827, 'reg_lambda': 2.030365588404046, 'min_child_weight': 5, 'gamma': 1.240752202817967}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:19:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:20:16,920] Trial 59 finished with value: 0.9411631455906342 and parameters: {'n_estimators': 450, 'learning_rate': 0.15489368535228046, 'max_depth': 8, 'subsample': 0.7632698596309445, 'colsample_bytree': 0.5458071738319763, 'reg_alpha': 0.14172983303400644, 'reg_lambda': 1.5803460161712604, 'min_child_weight': 5, 'gamma': 1.8040857206306016}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:20:38,687] Trial 60 finished with value: 0.9422919634300657 and parameters: {'n_estimators': 200, 'learning_rate': 0.05671606671612709, 'max_depth': 6, 'subsample': 0.6958446527595692, 'colsample_bytree': 0.6610921077091615, 'reg_alpha': 0.5601487073084737, 'reg_lambda': 3.073899921795642, 'min_child_weight': 6, 'gamma': 0.20731870493770077}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:20:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:21:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:21:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:21:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:23:20,359] Trial 61 finished with value: 0.9436426777855198 and parameters: {'n_estimators': 400, 'learning_rate': 0.033079334194222265, 'max_depth': 9, 'subsample': 0.7964936634620268, 'colsample_bytree': 0.6244498127433519, 'reg_alpha': 0.8000682680866968, 'reg_lambda': 1.0800916602009358, 'min_child_weight': 6, 'gamma': 0.9452170877045141}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:23:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:24:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:24:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:24:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:27:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:28:16,696] Trial 62 finished with value: 0.9439342640722778 and parameters: {'n_estimators': 400, 'learning_rate': 0.03291621374855657, 'max_depth': 9, 'subsample': 0.7961600984637665, 'colsample_bytree': 0.6210769003969069, 'reg_alpha': 0.8339938412215065, 'reg_lambda': 1.0159118037087635, 'min_child_weight': 6, 'gamma': 0.6378470564445551}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:28:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:28:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:28:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:29:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:29:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:29:52,961] Trial 63 finished with value: 0.9437879470863372 and parameters: {'n_estimators': 400, 'learning_rate': 0.033356835446987476, 'max_depth': 9, 'subsample': 0.7952457832247973, 'colsample_bytree': 0.6214330804787924, 'reg_alpha': 0.8518097950519046, 'reg_lambda': 0.9212172634479141, 'min_child_weight': 5, 'gamma': 0.6394969552763433}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:29:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:30:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:31:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:31:30,726] Trial 64 finished with value: 0.9438789750407219 and parameters: {'n_estimators': 350, 'learning_rate': 0.03315923268627327, 'max_depth': 9, 'subsample': 0.7925931416073654, 'colsample_bytree': 0.6223240336675323, 'reg_alpha': 0.8291826661945574, 'reg_lambda': 1.003343004632906, 'min_child_weight': 4, 'gamma': 0.6392934300911893}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:31:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:31:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:32:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:32:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:32:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:32:45,616] Trial 65 finished with value: 0.9437141863553151 and parameters: {'n_estimators': 300, 'learning_rate': 0.04694514924124986, 'max_depth': 9, 'subsample': 0.8298292167939016, 'colsample_bytree': 0.5958083862792694, 'reg_alpha': 0.1965894573905147, 'reg_lambda': 0.9054933459723149, 'min_child_weight': 3, 'gamma': 0.6269579311175248}. Best is trial 55 with value: 0.9439948794343774.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:32:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:33:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:33:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:33:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:33:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:34:13,171] Trial 66 finished with value: 0.9440645052752246 and parameters: {'n_estimators': 350, 'learning_rate': 0.02423051779990687, 'max_depth': 9, 'subsample': 0.858259829905585, 'colsample_bytree': 0.5732077727041697, 'reg_alpha': 0.9869252081515824, 'reg_lambda': 1.119553040429138, 'min_child_weight': 4, 'gamma': 0.7391441022919424}. Best is trial 66 with value: 0.9440645052752246.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:34:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:34:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:34:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:34:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:34:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:34:43,900] Trial 67 finished with value: 0.9411150632091292 and parameters: {'n_estimators': 200, 'learning_rate': 0.025401705494353718, 'max_depth': 9, 'subsample': 0.8836483938371472, 'colsample_bytree': 0.5711941014477432, 'reg_alpha': 1.052493838306736, 'reg_lambda': 1.0868157719148983, 'min_child_weight': 4, 'gamma': 4.666033972654436}. Best is trial 66 with value: 0.9440645052752246.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:34:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:34:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:35:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:35:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:35:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:35:47,889] Trial 68 finished with value: 0.9437925399790617 and parameters: {'n_estimators': 250, 'learning_rate': 0.03952852425106872, 'max_depth': 9, 'subsample': 0.8426715012026026, 'colsample_bytree': 0.5128436371557953, 'reg_alpha': 0.7838450487141401, 'reg_lambda': 1.3406036703921327, 'min_child_weight': 2, 'gamma': 0.729163248534195}. Best is trial 66 with value: 0.9440645052752246.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:35:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:35:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:36:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:36:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:36:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:36:33,129] Trial 69 finished with value: 0.9433823724210152 and parameters: {'n_estimators': 250, 'learning_rate': 0.03989143006894654, 'max_depth': 9, 'subsample': 0.8496879993210265, 'colsample_bytree': 0.4661839077430764, 'reg_alpha': 0.7749726878933434, 'reg_lambda': 0.8407715744034564, 'min_child_weight': 2, 'gamma': 1.4399026430444688}. Best is trial 66 with value: 0.9440645052752246.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:36:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:36:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:36:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:36:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:37:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:37:16,610] Trial 70 finished with value: 0.9435162871439824 and parameters: {'n_estimators': 200, 'learning_rate': 0.0652823445845678, 'max_depth': 9, 'subsample': 0.9349190467801296, 'colsample_bytree': 0.5118494006672987, 'reg_alpha': 0.6593291573164458, 'reg_lambda': 1.3236293430560955, 'min_child_weight': 2, 'gamma': 0.7347191043006169}. Best is trial 66 with value: 0.9440645052752246.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:37:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:37:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:37:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:38:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:38:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:38:56,010] Trial 71 finished with value: 0.9440952519785899 and parameters: {'n_estimators': 300, 'learning_rate': 0.03388154160939603, 'max_depth': 9, 'subsample': 0.7970060251196533, 'colsample_bytree': 0.6785259792610778, 'reg_alpha': 0.9183035973741936, 'reg_lambda': 0.6244772631578008, 'min_child_weight': 3, 'gamma': 0.530392706340373}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:38:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:39:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:39:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:40:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:40:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:40:59,403] Trial 72 finished with value: 0.9437019267378407 and parameters: {'n_estimators': 350, 'learning_rate': 0.03396188954013847, 'max_depth': 10, 'subsample': 0.7936038943898494, 'colsample_bytree': 0.47646905313859234, 'reg_alpha': 0.9199325944552125, 'reg_lambda': 0.48821867607328917, 'min_child_weight': 3, 'gamma': 0.1188426097717914}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:40:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:41:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:41:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:41:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:42:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:42:19,195] Trial 73 finished with value: 0.9439014245298327 and parameters: {'n_estimators': 300, 'learning_rate': 0.043664352995032914, 'max_depth': 9, 'subsample': 0.7709536128890523, 'colsample_bytree': 0.5542059107219778, 'reg_alpha': 0.7712811029333885, 'reg_lambda': 0.6713290299686034, 'min_child_weight': 3, 'gamma': 0.5857438170865134}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:42:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:42:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:42:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:43:17,796] Trial 74 finished with value: 0.9436457573348698 and parameters: {'n_estimators': 150, 'learning_rate': 0.0428483098602119, 'max_depth': 9, 'subsample': 0.766363778452565, 'colsample_bytree': 0.5588507725909442, 'reg_alpha': 0.3091587676146934, 'reg_lambda': 0.1624157521858941, 'min_child_weight': 3, 'gamma': 0.8025923615328545}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:43:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:44:19,772] Trial 75 finished with value: 0.943624918817286 and parameters: {'n_estimators': 300, 'learning_rate': 0.03767090464923383, 'max_depth': 9, 'subsample': 0.8729422162373891, 'colsample_bytree': 0.5183797233403457, 'reg_alpha': 0.7576885787797676, 'reg_lambda': 0.6698047215406473, 'min_child_weight': 3, 'gamma': 0.6120146567686768}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:44:41,297] Trial 76 finished with value: 0.943848766863422 and parameters: {'n_estimators': 300, 'learning_rate': 0.05130808230424364, 'max_depth': 9, 'subsample': 0.9052590289335571, 'colsample_bytree': 0.579944387698369, 'reg_alpha': 1.571788970369865, 'reg_lambda': 1.2052285210743385, 'min_child_weight': 2, 'gamma': 1.1046387764647378}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:44:59,245] Trial 77 finished with value: 0.9436904590043589 and parameters: {'n_estimators': 300, 'learning_rate': 0.05471932264203987, 'max_depth': 9, 'subsample': 0.9099756533825842, 'colsample_bytree': 0.49325348959056015, 'reg_alpha': 1.5269706185347185, 'reg_lambda': 1.1613878716168609, 'min_child_weight': 2, 'gamma': 1.0740391037076642}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:45:15,762] Trial 78 finished with value: 0.9435990245667544 and parameters: {'n_estimators': 250, 'learning_rate': 0.050926418343626885, 'max_depth': 8, 'subsample': 0.8354922160372876, 'colsample_bytree': 0.44571843224104746, 'reg_alpha': 1.1743218971371079, 'reg_lambda': 0.37113996202808, 'min_child_weight': 2, 'gamma': 0.8561016547692514}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:45:25,351] Trial 79 finished with value: 0.9423129789157987 and parameters: {'n_estimators': 250, 'learning_rate': 0.06277290275295565, 'max_depth': 10, 'subsample': 0.9128493278527889, 'colsample_bytree': 0.5839395681892788, 'reg_alpha': 0.9842337026988607, 'reg_lambda': 1.466913556055137, 'min_child_weight': 2, 'gamma': 3.69650914821096}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:45:42,818] Trial 80 finished with value: 0.9431655394544286 and parameters: {'n_estimators': 300, 'learning_rate': 0.07926210860341136, 'max_depth': 9, 'subsample': 0.8600689468248507, 'colsample_bytree': 0.5429786472879531, 'reg_alpha': 0.5030818206276456, 'reg_lambda': 0.9906936545239445, 'min_child_weight': 1, 'gamma': 1.1058817214708938}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:46:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:46:23,924] Trial 81 finished with value: 0.9431813153755506 and parameters: {'n_estimators': 400, 'learning_rate': 0.044170425608244475, 'max_depth': 9, 'subsample': 0.8048186218214762, 'colsample_bytree': 0.6088525775090148, 'reg_alpha': 0.8533334271002396, 'reg_lambda': 0.7680368732146405, 'min_child_weight': 4, 'gamma': 0.5348118365107895}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:47:07,231] Trial 82 finished with value: 0.9439872651606827 and parameters: {'n_estimators': 350, 'learning_rate': 0.029870683856477592, 'max_depth': 9, 'subsample': 0.9788970779218543, 'colsample_bytree': 0.6453416971203073, 'reg_alpha': 0.7139784997760737, 'reg_lambda': 1.1791225933577363, 'min_child_weight': 3, 'gamma': 0.6825428233043674}. Best is trial 71 with value: 0.9440952519785899.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:47:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:47:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:47:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:47:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:47:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:48:02,227] Trial 83 finished with value: 0.9443081943186578 and parameters: {'n_estimators': 350, 'learning_rate': 0.03008393676525409, 'max_depth': 9, 'subsample': 0.9809503155616375, 'colsample_bytree': 0.56044353273329, 'reg_alpha': 1.2338019395219242, 'reg_lambda': 1.6264975818536396, 'min_child_weight': 3, 'gamma': 0.36491328244932486}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:48:35,572] Trial 84 finished with value: 0.9442165443581937 and parameters: {'n_estimators': 350, 'learning_rate': 0.029816817060034646, 'max_depth': 8, 'subsample': 0.9789779192801092, 'colsample_bytree': 0.639572608148099, 'reg_alpha': 1.2224542542929742, 'reg_lambda': 1.6434624549350834, 'min_child_weight': 3, 'gamma': 0.2852715724159328}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:48:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:49:10,007] Trial 85 finished with value: 0.9439934325466341 and parameters: {'n_estimators': 350, 'learning_rate': 0.026892607135799794, 'max_depth': 8, 'subsample': 0.9926368350764958, 'colsample_bytree': 0.6550992883324604, 'reg_alpha': 1.1990453768801277, 'reg_lambda': 1.652033472914765, 'min_child_weight': 3, 'gamma': 0.3444521450867252}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:49:43,246] Trial 86 finished with value: 0.9440977972409916 and parameters: {'n_estimators': 350, 'learning_rate': 0.030106050729994456, 'max_depth': 8, 'subsample': 0.9778892262023359, 'colsample_bytree': 0.6400641709118841, 'reg_alpha': 1.1762954286121088, 'reg_lambda': 1.6062270150763556, 'min_child_weight': 3, 'gamma': 0.2926329115126658}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:49:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:50:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:50:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:50:19,416] Trial 87 finished with value: 0.9438554195467068 and parameters: {'n_estimators': 350, 'learning_rate': 0.024270118778741478, 'max_depth': 8, 'subsample': 0.978471320029983, 'colsample_bytree': 0.6396319790996253, 'reg_alpha': 1.20539000454393, 'reg_lambda': 1.9287006599643697, 'min_child_weight': 3, 'gamma': 0.3282547000126637}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:50:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:50:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:50:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:50:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:50:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:51:08,774] Trial 88 finished with value: 0.9440198480756614 and parameters: {'n_estimators': 450, 'learning_rate': 0.02999054951191684, 'max_depth': 8, 'subsample': 0.9783205268303042, 'colsample_bytree': 0.6529645685641321, 'reg_alpha': 1.4409170500559325, 'reg_lambda': 1.6609431906950474, 'min_child_weight': 3, 'gamma': 0.2233529416973909}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:51:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:51:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:51:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:51:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:51:59,416] Trial 89 finished with value: 0.9441514211868508 and parameters: {'n_estimators': 450, 'learning_rate': 0.027105205952078062, 'max_depth': 8, 'subsample': 0.9823440407714089, 'colsample_bytree': 0.6542552694291037, 'reg_alpha': 1.3718057454109418, 'reg_lambda': 1.6471604800881483, 'min_child_weight': 3, 'gamma': 0.16534026011835218}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:51:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:52:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:52:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:52:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:52:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:52:47,851] Trial 90 finished with value: 0.9441404247931304 and parameters: {'n_estimators': 450, 'learning_rate': 0.026564583689096113, 'max_depth': 8, 'subsample': 0.9981885362799507, 'colsample_bytree': 0.6680973601587713, 'reg_alpha': 1.985204346640622, 'reg_lambda': 1.7244889484386037, 'min_child_weight': 3, 'gamma': 0.14318428580331793}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:52:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:53:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:53:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:53:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:53:34,992] Trial 91 finished with value: 0.9442392070933103 and parameters: {'n_estimators': 450, 'learning_rate': 0.027034330833784592, 'max_depth': 8, 'subsample': 0.964094873808081, 'colsample_bytree': 0.6629445565681061, 'reg_alpha': 1.9090983262599304, 'reg_lambda': 1.637443214381536, 'min_child_weight': 3, 'gamma': 0.21700664916378554}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:53:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:53:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:53:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:54:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:54:26,050] Trial 92 finished with value: 0.9441368683165592 and parameters: {'n_estimators': 450, 'learning_rate': 0.02112935782390259, 'max_depth': 8, 'subsample': 0.9575012246897238, 'colsample_bytree': 0.6739247764591086, 'reg_alpha': 1.9614347414400586, 'reg_lambda': 1.713269322302695, 'min_child_weight': 3, 'gamma': 0.1894644380488141}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:54:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:54:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:54:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:55:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:55:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:55:25,051] Trial 93 finished with value: 0.9440531374102952 and parameters: {'n_estimators': 450, 'learning_rate': 0.022422021406847896, 'max_depth': 8, 'subsample': 0.9587973930982894, 'colsample_bytree': 0.7006518046292252, 'reg_alpha': 1.977244202517495, 'reg_lambda': 1.7715048944675689, 'min_child_weight': 3, 'gamma': 0.1357002625576082}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:55:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:55:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:55:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:56:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:56:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:56:29,097] Trial 94 finished with value: 0.9442123189857335 and parameters: {'n_estimators': 500, 'learning_rate': 0.021431692532493475, 'max_depth': 8, 'subsample': 0.9540498068217674, 'colsample_bytree': 0.6981905639278309, 'reg_alpha': 1.9787058320903879, 'reg_lambda': 1.8086155275664286, 'min_child_weight': 3, 'gamma': 0.1409047073332561}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:56:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:56:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:56:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:57:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:57:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:57:27,287] Trial 95 finished with value: 0.944062398810301 and parameters: {'n_estimators': 500, 'learning_rate': 0.0212808731171051, 'max_depth': 8, 'subsample': 0.9584158792616853, 'colsample_bytree': 0.6746348025380973, 'reg_alpha': 2.1160273948189317, 'reg_lambda': 1.9612789866974296, 'min_child_weight': 4, 'gamma': 0.00037166818399675394}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:57:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:57:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:57:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:57:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:58:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:58:19,196] Trial 96 finished with value: 0.943386664319527 and parameters: {'n_estimators': 400, 'learning_rate': 0.017534981565300888, 'max_depth': 8, 'subsample': 0.9558773813331718, 'colsample_bytree': 0.7124711548820155, 'reg_alpha': 1.8889463487929359, 'reg_lambda': 1.4460500991427931, 'min_child_weight': 3, 'gamma': 0.16261931008258318}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:58:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:58:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:58:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:58:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:58:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 18:59:07,950] Trial 97 finished with value: 0.9442237903544382 and parameters: {'n_estimators': 500, 'learning_rate': 0.024739696093497944, 'max_depth': 8, 'subsample': 0.9323334288313351, 'colsample_bytree': 0.6879313388561982, 'reg_alpha': 1.8561934834067189, 'reg_lambda': 1.8324634265384137, 'min_child_weight': 4, 'gamma': 0.4378189314572449}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:59:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:59:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:59:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [18:59:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 19:00:02,058] Trial 98 finished with value: 0.944147527252769 and parameters: {'n_estimators': 500, 'learning_rate': 0.026374819036653487, 'max_depth': 8, 'subsample': 0.9322291887581323, 'colsample_bytree': 0.6907842588160811, 'reg_alpha': 1.860357285423925, 'reg_lambda': 1.8330725890895962, 'min_child_weight': 3, 'gamma': 0.38445187941123393}. Best is trial 83 with value: 0.9443081943186578.\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/2597556985.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:00:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:00:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:00:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:00:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:00:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-09 19:00:52,190] Trial 99 finished with value: 0.9441031722342267 and parameters: {'n_estimators': 500, 'learning_rate': 0.022064169952029623, 'max_depth': 8, 'subsample': 0.9314634294334079, 'colsample_bytree': 0.6928553989753865, 'reg_alpha': 2.4006991116254834, 'reg_lambda': 1.8181503768745355, 'min_child_weight': 4, 'gamma': 0.2875888412146933}. Best is trial 83 with value: 0.9443081943186578.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "{'n_estimators': 350, 'learning_rate': 0.03008393676525409, 'max_depth': 9, 'subsample': 0.9809503155616375, 'colsample_bytree': 0.56044353273329, 'reg_alpha': 1.2338019395219242, 'reg_lambda': 1.6264975818536396, 'min_child_weight': 3, 'gamma': 0.36491328244932486}\n"
     ]
    }
   ],
   "source": [
    "# Optuna hyperparameter search for XGBoost pipeline\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Paths (adjust if needed)\n",
    "TRAIN_CSV = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\"\n",
    "STUDY_DB = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/optuna_study.sqlite\"\n",
    "BEST_PARAMS_PATH = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/best_xgb_params.json\"\n",
    "\n",
    "# load data\n",
    "train = pd.read_csv(TRAIN_CSV)\n",
    "y = train[\"target\"]\n",
    "X_raw = train.drop(columns=[\"target\"])\n",
    "\n",
    "# build feature-engineered X once for column discovery inside build_pipeline\n",
    "X_fe, loc_groups = apply_feature_engineering(train)\n",
    "X = X_fe.drop(columns=[\"target\"])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # sample hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=50),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0)\n",
    "    }\n",
    "\n",
    "    # build pipeline and set params\n",
    "    pipeline = build_pipeline(X)\n",
    "    # set parameters on final estimator via pipeline param naming\n",
    "    estimator_params = {f\"model__{k}\": v for k, v in params.items()}\n",
    "    pipeline.set_params(**estimator_params)\n",
    "\n",
    "    # evaluate with CV (roc_auc)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=1, error_score='raise')\n",
    "    return scores.mean()\n",
    "\n",
    "# create study with SQLite storage to persist results\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_pipeline_search\",\n",
    "                            storage=f\"sqlite:///{STUDY_DB}\", load_if_exists=True)\n",
    "\n",
    "# run optimization (adjust n_trials)\n",
    "n_trials = 50\n",
    "study.optimize(objective, n_trials=n_trials, n_jobs=1)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "# save best params\n",
    "os.makedirs(os.path.dirname(BEST_PARAMS_PATH), exist_ok=True)\n",
    "with open(BEST_PARAMS_PATH, \"w\") as f:\n",
    "    json.dump(study.best_trial.params, f, indent=2)\n",
    "\n",
    "# mark next todo as in-progress: retrain final model\n",
    "# (You can now rebuild pipeline with best params and fit on full training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88195c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-09 14:44:11,501] A new study created in memory with name: no-name-8662639e-f689-4ad8-92b7-2639d39848ff\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-10-09 14:44:11,506] Trial 0 failed with parameters: {'n_estimators': 463, 'learning_rate': 0.040350995490053825, 'max_depth': 6, 'subsample': 0.7433924692499391, 'colsample_bytree': 0.824566975559955, 'gamma': 1.7301559942880935, 'min_child_weight': 8.105361065739086, 'reg_alpha': 0.6225770812922393, 'reg_lambda': 0.2158959080773848} because of the following error: NameError(\"name 'preprocessor' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_54056/4214883388.py\", line 27, in objective\n",
      "    (\"preprocessor\", preprocessor),  # can reuse your built preprocessor\n",
      "                     ^^^^^^^^^^^^\n",
      "NameError: name 'preprocessor' is not defined\n",
      "[W 2025-10-09 14:44:11,510] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest AUC:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest Params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Rebuild the pipeline each trial (so params update)\u001b[39;00m\n\u001b[32m     23\u001b[39m model = XGBClassifier(**params)\n\u001b[32m     24\u001b[39m pipeline = Pipeline([\n\u001b[32m     25\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mcap_log\u001b[39m\u001b[33m\"\u001b[39m, FunctionTransformer(cap_and_log, validate=\u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[32m     26\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m, FunctionTransformer(drop_columns, validate=\u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mpreprocessor\u001b[49m),  \u001b[38;5;66;03m# can reuse your built preprocessor\u001b[39;00m\n\u001b[32m     28\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, model)\n\u001b[32m     29\u001b[39m ])\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Cross-validation\u001b[39;00m\n\u001b[32m     32\u001b[39m cv = StratifiedKFold(n_splits=\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "print(\"Best AUC:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486d151",
   "metadata": {},
   "source": [
    "trying: defaultprofile and default profile image\n",
    "with: CV AUC: 0.9428677592571271\n",
    "without: CV AUC: 0.9431187327116781\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc422ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [21:03:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [21:03:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [21:03:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [21:04:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [21:04:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9431187327116781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [21:04:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved\n",
      " Submission created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:35: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_72087/2213273080.py:39: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X):\n",
    "    X = X.copy()\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    # X['default_profile_and_image'] = ((X['default_profile'] == True) & (X['default_profile_image'] == True)).astype(int)\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        link_pattern = r'(http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        emoji_re = re.compile(\n",
    "            r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "            r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "            r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "            r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "            r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "            r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "            r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "            r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "\n",
    "    # === Language grouping ===\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        # high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af', 'ja', 'cy', 'so']     # > 0.4 bot rate\n",
    "        low_bot = [ 'ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']     # > 0.5 bot rate\n",
    "        mid_bot = ['ja', 'cy', 'so']                     # 0.40.5 bot rate\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he'] # < 20 samples\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            # ['high_bot_lang', 'mid_bot_lang', 'english'],\n",
    "            # ['high_bot_lang','low_bot_lang','english'],\n",
    "            # ['high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            ['low_freq_lang', 'high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "    return X\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \"description\", \"lang\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    X_temp = drop_columns(cap_and_log(apply_feature_engineering(X)))\n",
    "    # X_temp = drop_columns((apply_feature_engineering(X)))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_probs = pipeline.predict_proba(test)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18aae76",
   "metadata": {},
   "source": [
    "original: CV AUC: 0.9462335346853962\n",
    "\n",
    "trying:\n",
    "is_geo_or_verified\n",
    "CV AUC: 0.9460186397060564\n",
    "\n",
    "is_geo_and_not_verified + is_not_geo_and_verified\n",
    "CV AUC: 0.9463343384946825 (improvement)\n",
    "\n",
    "is_geo_and_not_verified CV AUC: 0.9461242200335518\n",
    "is_not_geo_and_verified CV AUC: 0.9461867435581424\n",
    "\n",
    "is_geo_and_not_verified + is_not_geo_and_verified + is_geo_or_verified\n",
    "CV AUC: 0.946380302633559\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b74984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.946666124621012\n",
      " Model saved\n",
      " Model saved\n",
      " Submission created\n",
      " Submission created\n"
     ]
    }
   ],
   "source": [
    "#without geoenabled and verified interaction\n",
    "# CV AUC: 0.9461810576257423\n",
    "# with \n",
    "# CV AUC: 0.9462335346853962\n",
    "# public score: 0.94147\n",
    "\n",
    "# add description_has_follow -- CV AUC: 0.9460825004785388 (worsen)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    # X can be a 1D array or 2D array with shape (n_samples, 1)\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    # reference_date: use a fixed date for reproducibility if provided, otherwise use current date\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        link_pattern = r'(http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        emoji_re = re.compile(\n",
    "            r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "            r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "            r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "            r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "            r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "            r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "            r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "            r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "\n",
    "        # X['description_has_follow'] = desc.str.contains(r'\\b(follow|subscribe)\\b').fillna(False).astype(int)\n",
    "\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        # X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "\n",
    "        # X['description_has_follow'] = 0\n",
    "\n",
    "    # === created_at -> account_age_days ===\n",
    "    if 'account_age_days' not in X.columns or X['account_age_days'].isna().any():\n",
    "        if 'created_at' in X.columns:\n",
    "            # try parsing created_at to days difference from reference_date\n",
    "            try:\n",
    "                created = pd.to_datetime(X['created_at'], errors='coerce')\n",
    "                X['account_age_days'] = (reference_date - created).dt.days.fillna(0).astype(int)\n",
    "            except Exception:\n",
    "                # fallback if parsing fails\n",
    "                X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "        else:\n",
    "            # if neither exists, fill with median later through imputer\n",
    "            X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "\n",
    "    # === screen_name features ===\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d').astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_').astype(int)\n",
    "        # ratio of digits to length\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "\n",
    "    # === boolean-like flags to numeric ===\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    # === Language grouping ===\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        # high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af', 'ja', 'cy', 'so']     # > 0.4 bot rate\n",
    "        low_bot = [ 'ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']     # > 0.5 bot rate\n",
    "        mid_bot = ['ja', 'cy', 'so']                     # 0.40.5 bot rate\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he'] # < 20 samples\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            # ['high_bot_lang', 'mid_bot_lang', 'english'],\n",
    "            # ['high_bot_lang','low_bot_lang','english'],\n",
    "            # ['high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            ['low_freq_lang', 'high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    # return X\n",
    "\n",
    "    # === Location binning and low-frequency flagging ===\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "# ...existing code...\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "\n",
    "    Usage:\n",
    "      # On training data (requires 'target'):\n",
    "      df_train, loc_groups = map_loc_bin(df_train, min_samples=30)\n",
    "\n",
    "      # On test data (reuse mapping from train):\n",
    "      df_test, _ = map_loc_bin(df_test, loc_groups=loc_groups)\n",
    "\n",
    "    Returns:\n",
    "      df (modified copy), loc_groups (dict with 'mapping', 'low_freq', 'groups')\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "        # bins = [0.0, 0.1, 0.3, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    # If no precomputed groups provided, build from df (training mode)\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        # Keep locations with enough samples for reliable proportion\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        # accept either full loc_groups dict or just mapping\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    # Map each location to a combined bin\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    # df['loc_low_freq'] = df['location'].isin(low_freq).astype(int)\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "\n",
    "    return df, loc_groups\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    # keep `description` and `screen_name` for text features; drop raw location/lang/ids that we've summarized\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \"lang\", \"location\", \"created_at\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    # note: X is expected to already contain feature-engineered cols (main applies apply_feature_engineering)\n",
    "    X_temp = drop_columns(cap_and_log(X))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        # (\"encoder\", OneHotEncoder(max_categories=50, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    # Add text pipelines if description / screen_name exist\n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # description -> TF-IDF -> SVD\n",
    "    if 'description' in X_temp.columns:\n",
    "        desc_components = 40\n",
    "        # ensure we pass a 1D array of strings (no NaN) into TfidfVectorizer\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=desc_components, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # screen_name -> TF-IDF -> SVD (shorter)\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        sn_components = 8\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=sn_components, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # model = XGBClassifier(\n",
    "    #     n_estimators=300,\n",
    "    #     learning_rate=0.05,\n",
    "    #     max_depth=6,\n",
    "    #     subsample=0.8,\n",
    "    #     colsample_bytree=0.8,\n",
    "    #     random_state=42,\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric=\"logloss\"\n",
    "    # )\n",
    "    # {'n_estimators': 350, 'learning_rate': 0.03008393676525409, 'max_depth': 9, 'subsample': 0.9809503155616375, 'colsample_bytree': 0.56044353273329, 'reg_alpha': 1.2338019395219242, 'reg_lambda': 1.6264975818536396, 'min_child_weight': 3, 'gamma': 0.36491328244932486}\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=350,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=9,\n",
    "        subsample=0.98,\n",
    "        colsample_bytree=0.56,\n",
    "        reg_alpha=1.23,\n",
    "        reg_lambda=1.63,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.36,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        # (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    # X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    X_fe, loc_groups = apply_feature_engineering(train)\n",
    "    X = X_fe.drop(columns=['target'])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "    # pipeline = build_pipeline(X_fe)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Feature importance\n",
    "    # if hasattr(pipeline.named_steps['model'], 'feature_importances_'):\n",
    "    #     importances = pipeline.named_steps['model'].feature_importances_\n",
    "    #     print(\"Feature importances:\", importances)\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_fe, _ = apply_feature_engineering(test, loc_groups=loc_groups)\n",
    "    test_probs = pipeline.predict_proba(test_fe)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b99a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model loaded\n",
      "Warning: 50 feature names but 47281 importances\n",
      "\n",
      "================================================================================\n",
      "TOP 50 MOST IMPORTANT FEATURES\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desc_text__component_14</td>\n",
       "      <td>0.137697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>desc_text__component_4</td>\n",
       "      <td>0.092504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desc_text__component_1</td>\n",
       "      <td>0.064428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desc_text__component_9</td>\n",
       "      <td>0.040198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>desc_text__component_13</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>desc_text__component_16</td>\n",
       "      <td>0.033590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>desc_text__component_12</td>\n",
       "      <td>0.030007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>desc_text__component_15</td>\n",
       "      <td>0.029964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>desc_text__component_3</td>\n",
       "      <td>0.029799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>desc_text__component_8</td>\n",
       "      <td>0.024362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>desc_text__component_2</td>\n",
       "      <td>0.022345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>desc_text__component_11</td>\n",
       "      <td>0.020550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>desc_text__component_0</td>\n",
       "      <td>0.018668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>desc_text__component_10</td>\n",
       "      <td>0.015388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>desc_text__component_5</td>\n",
       "      <td>0.015090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>desc_text__component_6</td>\n",
       "      <td>0.013910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>desc_text__component_7</td>\n",
       "      <td>0.012997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>desc_text__component_22</td>\n",
       "      <td>0.012049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num__Index(['default_profile', 'default_profil...</td>\n",
       "      <td>0.007626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>desc_text__component_18</td>\n",
       "      <td>0.006883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cat__Index(['description', 'screen_name', 'lan...</td>\n",
       "      <td>0.005375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>desc_text__component_21</td>\n",
       "      <td>0.005192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>desc_text__component_17</td>\n",
       "      <td>0.004673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>desc_text__component_23</td>\n",
       "      <td>0.004299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>desc_text__component_20</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>desc_text__component_19</td>\n",
       "      <td>0.003452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sn_text__component_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sn_text__component_5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sn_text__component_4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sn_text__component_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sn_text__component_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sn_text__component_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sn_text__component_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>desc_text__component_39</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>desc_text__component_38</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>desc_text__component_37</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>desc_text__component_36</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>desc_text__component_35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>desc_text__component_34</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>desc_text__component_33</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>desc_text__component_32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>desc_text__component_31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>desc_text__component_30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>desc_text__component_29</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>desc_text__component_28</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>desc_text__component_27</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>desc_text__component_26</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>desc_text__component_25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>desc_text__component_24</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sn_text__component_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature  importance\n",
       "0                             desc_text__component_14    0.137697\n",
       "1                              desc_text__component_4    0.092504\n",
       "2                              desc_text__component_1    0.064428\n",
       "3                              desc_text__component_9    0.040198\n",
       "4                             desc_text__component_13    0.033791\n",
       "5                             desc_text__component_16    0.033590\n",
       "6                             desc_text__component_12    0.030007\n",
       "7                             desc_text__component_15    0.029964\n",
       "8                              desc_text__component_3    0.029799\n",
       "9                              desc_text__component_8    0.024362\n",
       "10                             desc_text__component_2    0.022345\n",
       "11                            desc_text__component_11    0.020550\n",
       "12                             desc_text__component_0    0.018668\n",
       "13                            desc_text__component_10    0.015388\n",
       "14                             desc_text__component_5    0.015090\n",
       "15                             desc_text__component_6    0.013910\n",
       "16                             desc_text__component_7    0.012997\n",
       "17                            desc_text__component_22    0.012049\n",
       "18  num__Index(['default_profile', 'default_profil...    0.007626\n",
       "19                            desc_text__component_18    0.006883\n",
       "20  cat__Index(['description', 'screen_name', 'lan...    0.005375\n",
       "21                            desc_text__component_21    0.005192\n",
       "22                            desc_text__component_17    0.004673\n",
       "23                            desc_text__component_23    0.004299\n",
       "24                            desc_text__component_20    0.003998\n",
       "25                            desc_text__component_19    0.003452\n",
       "26                               sn_text__component_6    0.000000\n",
       "27                               sn_text__component_5    0.000000\n",
       "28                               sn_text__component_4    0.000000\n",
       "29                               sn_text__component_3    0.000000\n",
       "30                               sn_text__component_2    0.000000\n",
       "31                               sn_text__component_1    0.000000\n",
       "32                               sn_text__component_0    0.000000\n",
       "33                            desc_text__component_39    0.000000\n",
       "34                            desc_text__component_38    0.000000\n",
       "35                            desc_text__component_37    0.000000\n",
       "36                            desc_text__component_36    0.000000\n",
       "37                            desc_text__component_35    0.000000\n",
       "38                            desc_text__component_34    0.000000\n",
       "39                            desc_text__component_33    0.000000\n",
       "40                            desc_text__component_32    0.000000\n",
       "41                            desc_text__component_31    0.000000\n",
       "42                            desc_text__component_30    0.000000\n",
       "43                            desc_text__component_29    0.000000\n",
       "44                            desc_text__component_28    0.000000\n",
       "45                            desc_text__component_27    0.000000\n",
       "46                            desc_text__component_26    0.000000\n",
       "47                            desc_text__component_25    0.000000\n",
       "48                            desc_text__component_24    0.000000\n",
       "49                               sn_text__component_7    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature importances saved to ../outputs/feature_importances.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature importance plot saved to ../outputs/feature_importance_plot.png\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE SUMMARY\n",
      "================================================================================\n",
      "Total features: 50\n",
      "Top 10 features account for: 51.63% of total importance\n",
      "Top 50 features account for: 68.88% of total importance\n",
      "Mean importance: 0.013777\n",
      "Median importance: 0.003725\n"
     ]
    }
   ],
   "source": [
    "# ========= Feature Importance Analysis ========= #\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "pipeline = joblib.load(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "print(\" Model loaded\")\n",
    "# Extract the fitted model and preprocessor from the pipeline\n",
    "model = pipeline.named_steps['model']\n",
    "preprocessor = pipeline.named_steps['preprocessor']\n",
    "\n",
    "# Get feature importances from XGBoost\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Build feature names from the ColumnTransformer\n",
    "def get_feature_names_from_column_transformer(ct):\n",
    "    \"\"\"Extract feature names from a fitted ColumnTransformer.\"\"\"\n",
    "    feature_names = []\n",
    "    \n",
    "    for name, transformer, cols in ct.transformers_:\n",
    "        if transformer == 'drop' or name == 'remainder':\n",
    "            continue\n",
    "            \n",
    "        # Get the column names\n",
    "        if isinstance(cols, (list, tuple, np.ndarray)):\n",
    "            input_cols = list(cols)\n",
    "        else:\n",
    "            input_cols = [cols]\n",
    "        \n",
    "        # Check if transformer is a Pipeline\n",
    "        if hasattr(transformer, 'named_steps'):\n",
    "            # Get the last step of the pipeline\n",
    "            steps = list(transformer.named_steps.values())\n",
    "            last_step = steps[-1] if steps else transformer\n",
    "        else:\n",
    "            last_step = transformer\n",
    "        \n",
    "        # Get feature names based on transformer type\n",
    "        if hasattr(last_step, 'get_feature_names_out'):\n",
    "            try:\n",
    "                out_names = last_step.get_feature_names_out(input_cols)\n",
    "                feature_names.extend([f\"{name}__{n}\" for n in out_names])\n",
    "            except:\n",
    "                # Fallback if get_feature_names_out fails\n",
    "                if hasattr(last_step, 'n_components'):\n",
    "                    # For dimensionality reduction (SVD, PCA, etc.)\n",
    "                    n_comp = last_step.n_components\n",
    "                    feature_names.extend([f\"{name}__component_{i}\" for i in range(n_comp)])\n",
    "                else:\n",
    "                    feature_names.extend([f\"{name}__{c}\" for c in input_cols])\n",
    "        elif isinstance(last_step, TruncatedSVD):\n",
    "            # Handle TruncatedSVD specifically\n",
    "            n_comp = last_step.n_components\n",
    "            feature_names.extend([f\"{name}__svd_{i}\" for i in range(n_comp)])\n",
    "        else:\n",
    "            # Default: use input column names\n",
    "            feature_names.extend([f\"{name}__{c}\" for c in input_cols])\n",
    "    \n",
    "    return feature_names\n",
    "\n",
    "try:\n",
    "    feature_names = get_feature_names_from_column_transformer(preprocessor)\n",
    "except Exception as e:\n",
    "    print(f\"Error extracting feature names: {e}\")\n",
    "    feature_names = [f\"feature_{i}\" for i in range(len(importances))]\n",
    "\n",
    "# Ensure lengths match\n",
    "if len(feature_names) != len(importances):\n",
    "    print(f\"Warning: {len(feature_names)} feature names but {len(importances)} importances\")\n",
    "    min_len = min(len(feature_names), len(importances))\n",
    "    feature_names = feature_names[:min_len]\n",
    "    importances = importances[:min_len]\n",
    "\n",
    "# Create DataFrame with feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top 50 features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 50 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "display(feature_importance_df.head(50))\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"../outputs/feature_importances.csv\"\n",
    "feature_importance_df.to_csv(output_path, index=False)\n",
    "print(f\"\\n Feature importances saved to {output_path}\")\n",
    "\n",
    "# Plot top 30 features\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_n = 30\n",
    "top_features = feature_importance_df.head(top_n)\n",
    "plt.barh(range(top_n), top_features['importance'], color='steelblue')\n",
    "plt.yticks(range(top_n), top_features['feature'], fontsize=9)\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title(f'Top {top_n} Feature Importances (XGBoost)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/feature_importance_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Feature importance plot saved to ../outputs/feature_importance_plot.png\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total features: {len(feature_importance_df)}\")\n",
    "print(f\"Top 10 features account for: {feature_importance_df.head(10)['importance'].sum():.2%} of total importance\")\n",
    "print(f\"Top 50 features account for: {feature_importance_df.head(50)['importance'].sum():.2%} of total importance\")\n",
    "print(f\"Mean importance: {feature_importance_df['importance'].mean():.6f}\")\n",
    "print(f\"Median importance: {feature_importance_df['importance'].median():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82506680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total importances available: 50\n",
      "  Total features expected: 50 (mismatch detected earlier)\n",
      "\n",
      "================================================================================\n",
      "FEATURE SPACE BREAKDOWN (ACTUAL)\n",
      "================================================================================\n",
      "Numeric features:          26 features  (indices 0-25)\n",
      "Other features:            24 features  (indices 26-49)\n",
      "Total in importance:       50 features\n",
      "\n",
      "================================================================================\n",
      "IMPORTANCE CONTRIBUTION BY FEATURE TYPE\n",
      "================================================================================\n",
      "Numeric features:      100.00%  (mean: 0.026494)\n",
      "Other features:          0.00%  (mean: 0.000000)\n",
      "\n",
      "================================================================================\n",
      "ALL FEATURES RANKED BY IMPORTANCE\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>type</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_geo_or_verified</td>\n",
       "      <td>0.137697</td>\n",
       "      <td>numeric</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>verified</td>\n",
       "      <td>0.092504</td>\n",
       "      <td>numeric</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>followers_count</td>\n",
       "      <td>0.064428</td>\n",
       "      <td>numeric</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>followers_per_day</td>\n",
       "      <td>0.040198</td>\n",
       "      <td>numeric</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_not_geo_and_verified</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>numeric</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>description_has_bot</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>numeric</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is_geo_and_not_verified</td>\n",
       "      <td>0.030007</td>\n",
       "      <td>numeric</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>description_has_link</td>\n",
       "      <td>0.029964</td>\n",
       "      <td>numeric</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>geo_enabled</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>numeric</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>favourites_per_status</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>numeric</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>friends_count</td>\n",
       "      <td>0.022345</td>\n",
       "      <td>numeric</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is_geo_and_verified</td>\n",
       "      <td>0.020550</td>\n",
       "      <td>numeric</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>favourites_count</td>\n",
       "      <td>0.018668</td>\n",
       "      <td>numeric</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>statuses_per_follower</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>numeric</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>average_tweets_per_day</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>numeric</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>account_age_days</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>numeric</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>followers_friends_ratio</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>numeric</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>screen_name_has_bot</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>numeric</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>default_profile</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>numeric</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>description_has_at</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>numeric</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>default_profile_image</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>numeric</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>screen_name_has_digits</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>numeric</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>description_len</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>numeric</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>screen_name_digit_ratio</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>numeric</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>screen_name_len</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>numeric</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>description_has_emoji</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>numeric</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>other_feature_0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>other_feature_1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>other_feature_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>other_feature_3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>other_feature_4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>other_feature_5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>other_feature_6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>other_feature_7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>other_feature_8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>other_feature_9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>other_feature_10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>other_feature_11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>other_feature_12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>other_feature_13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>other_feature_14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>other_feature_15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>other_feature_16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>other_feature_17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>other_feature_18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>other_feature_19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>other_feature_20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>other_feature_21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>other_feature_22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>other_feature_23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>categorical/text</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance              type  rank\n",
       "0        is_geo_or_verified    0.137697           numeric     1\n",
       "1                  verified    0.092504           numeric     2\n",
       "2           followers_count    0.064428           numeric     3\n",
       "3         followers_per_day    0.040198           numeric     4\n",
       "4   is_not_geo_and_verified    0.033791           numeric     5\n",
       "5       description_has_bot    0.033590           numeric     6\n",
       "6   is_geo_and_not_verified    0.030007           numeric     7\n",
       "7      description_has_link    0.029964           numeric     8\n",
       "8               geo_enabled    0.029799           numeric     9\n",
       "9     favourites_per_status    0.024362           numeric    10\n",
       "10            friends_count    0.022345           numeric    11\n",
       "11      is_geo_and_verified    0.020550           numeric    12\n",
       "12         favourites_count    0.018668           numeric    13\n",
       "13    statuses_per_follower    0.015388           numeric    14\n",
       "14   average_tweets_per_day    0.015090           numeric    15\n",
       "15         account_age_days    0.013910           numeric    16\n",
       "16  followers_friends_ratio    0.012997           numeric    17\n",
       "17      screen_name_has_bot    0.012049           numeric    18\n",
       "18          default_profile    0.007626           numeric    19\n",
       "19       description_has_at    0.006883           numeric    20\n",
       "20    default_profile_image    0.005375           numeric    21\n",
       "21   screen_name_has_digits    0.005192           numeric    22\n",
       "22          description_len    0.004673           numeric    23\n",
       "23  screen_name_digit_ratio    0.004299           numeric    24\n",
       "24          screen_name_len    0.003998           numeric    25\n",
       "25    description_has_emoji    0.003452           numeric    26\n",
       "26          other_feature_0    0.000000  categorical/text    27\n",
       "27          other_feature_1    0.000000  categorical/text    28\n",
       "28          other_feature_2    0.000000  categorical/text    29\n",
       "29          other_feature_3    0.000000  categorical/text    30\n",
       "30          other_feature_4    0.000000  categorical/text    31\n",
       "31          other_feature_5    0.000000  categorical/text    32\n",
       "32          other_feature_6    0.000000  categorical/text    33\n",
       "33          other_feature_7    0.000000  categorical/text    34\n",
       "34          other_feature_8    0.000000  categorical/text    35\n",
       "35          other_feature_9    0.000000  categorical/text    36\n",
       "36         other_feature_10    0.000000  categorical/text    37\n",
       "37         other_feature_11    0.000000  categorical/text    38\n",
       "38         other_feature_12    0.000000  categorical/text    39\n",
       "39         other_feature_13    0.000000  categorical/text    40\n",
       "40         other_feature_14    0.000000  categorical/text    41\n",
       "41         other_feature_15    0.000000  categorical/text    42\n",
       "42         other_feature_16    0.000000  categorical/text    43\n",
       "43         other_feature_17    0.000000  categorical/text    44\n",
       "44         other_feature_18    0.000000  categorical/text    45\n",
       "45         other_feature_19    0.000000  categorical/text    46\n",
       "46         other_feature_20    0.000000  categorical/text    47\n",
       "47         other_feature_21    0.000000  categorical/text    48\n",
       "48         other_feature_22    0.000000  categorical/text    49\n",
       "49         other_feature_23    0.000000  categorical/text    50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "NUMERICAL FEATURES: DETAILED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "All 26 numeric features with cumulative importance:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>% of total</th>\n",
       "      <th>cumulative %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>is_geo_or_verified</td>\n",
       "      <td>0.137697</td>\n",
       "      <td>19.99</td>\n",
       "      <td>19.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>verified</td>\n",
       "      <td>0.092504</td>\n",
       "      <td>13.43</td>\n",
       "      <td>33.419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>followers_count</td>\n",
       "      <td>0.064428</td>\n",
       "      <td>9.35</td>\n",
       "      <td>42.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>followers_per_day</td>\n",
       "      <td>0.040198</td>\n",
       "      <td>5.84</td>\n",
       "      <td>48.610001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>is_not_geo_and_verified</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>4.91</td>\n",
       "      <td>53.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>description_has_bot</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>4.88</td>\n",
       "      <td>58.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>is_geo_and_not_verified</td>\n",
       "      <td>0.030007</td>\n",
       "      <td>4.36</td>\n",
       "      <td>62.759998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>description_has_link</td>\n",
       "      <td>0.029964</td>\n",
       "      <td>4.35</td>\n",
       "      <td>67.110001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>geo_enabled</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>4.33</td>\n",
       "      <td>71.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>favourites_per_status</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>3.54</td>\n",
       "      <td>74.980003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>friends_count</td>\n",
       "      <td>0.022345</td>\n",
       "      <td>3.24</td>\n",
       "      <td>78.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>is_geo_and_verified</td>\n",
       "      <td>0.020550</td>\n",
       "      <td>2.98</td>\n",
       "      <td>81.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>favourites_count</td>\n",
       "      <td>0.018668</td>\n",
       "      <td>2.71</td>\n",
       "      <td>83.910004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>statuses_per_follower</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>2.23</td>\n",
       "      <td>86.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>average_tweets_per_day</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>2.19</td>\n",
       "      <td>88.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>account_age_days</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>2.02</td>\n",
       "      <td>90.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>followers_friends_ratio</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>1.89</td>\n",
       "      <td>92.239998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>screen_name_has_bot</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>1.75</td>\n",
       "      <td>93.989998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>default_profile</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>1.11</td>\n",
       "      <td>95.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>description_has_at</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>1.00</td>\n",
       "      <td>96.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>default_profile_image</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.78</td>\n",
       "      <td>96.879997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>screen_name_has_digits</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.75</td>\n",
       "      <td>97.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>description_len</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.68</td>\n",
       "      <td>98.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>screen_name_digit_ratio</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.62</td>\n",
       "      <td>98.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>screen_name_len</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.58</td>\n",
       "      <td>99.510002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>description_has_emoji</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100.010002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                  feature  importance  % of total  cumulative %\n",
       "0      1       is_geo_or_verified    0.137697       19.99     19.990000\n",
       "1      2                 verified    0.092504       13.43     33.419998\n",
       "2      3          followers_count    0.064428        9.35     42.770000\n",
       "3      4        followers_per_day    0.040198        5.84     48.610001\n",
       "4      5  is_not_geo_and_verified    0.033791        4.91     53.520000\n",
       "5      6      description_has_bot    0.033590        4.88     58.400002\n",
       "6      7  is_geo_and_not_verified    0.030007        4.36     62.759998\n",
       "7      8     description_has_link    0.029964        4.35     67.110001\n",
       "8      9              geo_enabled    0.029799        4.33     71.440002\n",
       "9     10    favourites_per_status    0.024362        3.54     74.980003\n",
       "10    11            friends_count    0.022345        3.24     78.220001\n",
       "11    12      is_geo_and_verified    0.020550        2.98     81.199997\n",
       "12    13         favourites_count    0.018668        2.71     83.910004\n",
       "13    14    statuses_per_follower    0.015388        2.23     86.139999\n",
       "14    15   average_tweets_per_day    0.015090        2.19     88.330002\n",
       "15    16         account_age_days    0.013910        2.02     90.349998\n",
       "16    17  followers_friends_ratio    0.012997        1.89     92.239998\n",
       "17    18      screen_name_has_bot    0.012049        1.75     93.989998\n",
       "18    19          default_profile    0.007626        1.11     95.099998\n",
       "19    20       description_has_at    0.006883        1.00     96.099998\n",
       "20    21    default_profile_image    0.005375        0.78     96.879997\n",
       "21    22   screen_name_has_digits    0.005192        0.75     97.629997\n",
       "22    23          description_len    0.004673        0.68     98.309998\n",
       "23    24  screen_name_digit_ratio    0.004299        0.62     98.930000\n",
       "24    25          screen_name_len    0.003998        0.58     99.510002\n",
       "25    26    description_has_emoji    0.003452        0.50    100.010002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE DROP RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      " Low-importance numeric features (< 0.005):\n",
      "\\n   These 4 features have very low importance:\n",
      "   23. description_len                 (importance: 0.004673, 0.68%)\n",
      "   24. screen_name_digit_ratio         (importance: 0.004299, 0.62%)\n",
      "   25. screen_name_len                 (importance: 0.003998, 0.58%)\n",
      "   26. description_has_emoji           (importance: 0.003452, 0.50%)\n",
      "\\n    Safe to drop?\n",
      "       description_has_emoji - Very low impact\n",
      "       screen_name_len - Very low impact\n",
      "       screen_name_digit_ratio - Very low impact\n",
      "       description_len - Keep (might interact with other features)\n",
      "\\n     But consider:\n",
      "       They cost almost nothing computationally\n",
      "       They may help with model interpretability\n",
      "       Test dropping them and see if CV score changes\n",
      "\\n Top performing numeric features (top 5):\n",
      "    1. is_geo_or_verified              (importance: 0.137697, 19.99%)\n",
      "    2. verified                        (importance: 0.092504, 13.43%)\n",
      "    3. followers_count                 (importance: 0.064428, 9.35%)\n",
      "    4. followers_per_day               (importance: 0.040198, 5.84%)\n",
      "    5. is_not_geo_and_verified         (importance: 0.033791, 4.91%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n Comprehensive numeric features analysis saved\n"
     ]
    }
   ],
   "source": [
    "# ========= COMPREHENSIVE FEATURE IMPORTANCE ANALYSIS (FIXED) ========= #\n",
    "# Shows Numerical, Categorical, and Text features together with recommendations\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# IMPORTANT: The importances array is smaller than expected!\n",
    "# This happened because feature_importance_df was truncated earlier\n",
    "print(f\"  Total importances available: {len(importances)}\")\n",
    "print(f\"  Total features expected: {len(importances)} (mismatch detected earlier)\")\n",
    "print()\n",
    "\n",
    "# We need to use the ACTUAL feature count, not the theoretical one\n",
    "# Let's work with what we have\n",
    "\n",
    "# From earlier analysis, we know:\n",
    "num_numeric = 26\n",
    "\n",
    "# The rest are bundled - let's extract what we can\n",
    "if len(importances) >= num_numeric:\n",
    "    numeric_importances = importances[:num_numeric]\n",
    "    remaining_importances = importances[num_numeric:]\n",
    "else:\n",
    "    numeric_importances = importances\n",
    "    remaining_importances = np.array([])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE SPACE BREAKDOWN (ACTUAL)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Numeric features:       {num_numeric:5d} features  (indices 0-{num_numeric-1})\")\n",
    "print(f\"Other features:         {len(remaining_importances):5d} features  (indices {num_numeric}-{len(importances)-1})\")\n",
    "print(f\"Total in importance:    {len(importances):5d} features\")\n",
    "\n",
    "# Calculate contributions\n",
    "total_importance = importances.sum()\n",
    "numeric_contrib = numeric_importances.sum() / total_importance * 100\n",
    "other_contrib = remaining_importances.sum() / total_importance * 100 if len(remaining_importances) > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPORTANCE CONTRIBUTION BY FEATURE TYPE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Numeric features:      {numeric_contrib:6.2f}%  (mean: {numeric_importances.mean():.6f})\")\n",
    "print(f\"Other features:        {other_contrib:6.2f}%  (mean: {remaining_importances.mean() if len(remaining_importances) > 0 else 0:.6f})\")\n",
    "\n",
    "# ==== NUMERIC FEATURES ====\n",
    "numeric_cols = [\n",
    "    'default_profile', 'default_profile_image', 'favourites_count',\n",
    "    'followers_count', 'friends_count', 'geo_enabled', 'verified',\n",
    "    'average_tweets_per_day', 'account_age_days', 'followers_friends_ratio',\n",
    "    'favourites_per_status', 'followers_per_day', 'statuses_per_follower',\n",
    "    'is_geo_and_verified', 'is_geo_and_not_verified',\n",
    "    'is_not_geo_and_verified', 'is_geo_or_verified', 'description_has_link',\n",
    "    'description_has_bot', 'description_len', 'description_has_at',\n",
    "    'description_has_emoji', 'screen_name_len', 'screen_name_has_digits',\n",
    "    'screen_name_has_bot', 'screen_name_digit_ratio'\n",
    "]\n",
    "\n",
    "numeric_df = pd.DataFrame({\n",
    "    'feature': numeric_cols,\n",
    "    'importance': numeric_importances,\n",
    "    'type': 'numeric',\n",
    "    'rank': range(1, len(numeric_cols) + 1)\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "numeric_df['rank'] = range(1, len(numeric_df) + 1)\n",
    "\n",
    "# ==== OTHER FEATURES ====\n",
    "# These are categorical, description SVD, and screen name SVD all bundled\n",
    "if len(remaining_importances) > 0:\n",
    "    other_df = pd.DataFrame({\n",
    "        'feature': [f'other_feature_{i}' for i in range(len(remaining_importances))],\n",
    "        'importance': remaining_importances,\n",
    "        'type': 'categorical/text',\n",
    "        'rank': range(len(numeric_cols) + 1, len(numeric_cols) + len(remaining_importances) + 1)\n",
    "    }).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "    other_df['rank'] = range(len(numeric_df) + 1, len(numeric_df) + len(other_df) + 1)\n",
    "    \n",
    "    all_features_df = pd.concat([numeric_df, other_df], ignore_index=True)\n",
    "else:\n",
    "    all_features_df = numeric_df\n",
    "\n",
    "all_features_df = all_features_df.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "all_features_df['rank'] = range(1, len(all_features_df) + 1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL FEATURES RANKED BY IMPORTANCE\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "display(all_features_df)\n",
    "\n",
    "# ==== FEATURE DROP RECOMMENDATIONS ====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NUMERICAL FEATURES: DETAILED ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show numeric features with percentiles\n",
    "numeric_df_display = numeric_df.copy()\n",
    "numeric_df_display['% of total'] = (numeric_df_display['importance'] / total_importance * 100).round(2)\n",
    "numeric_df_display['cumulative %'] = numeric_df_display['% of total'].cumsum().round(2)\n",
    "\n",
    "print(\"\\nAll 26 numeric features with cumulative importance:\\n\")\n",
    "display(numeric_df_display[['rank', 'feature', 'importance', '% of total', 'cumulative %']])\n",
    "\n",
    "# Low importance features\n",
    "low_importance_threshold = 0.005\n",
    "low_numeric = numeric_df[numeric_df['importance'] < low_importance_threshold]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE DROP RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n Low-importance numeric features (< {low_importance_threshold}):\")\n",
    "if len(low_numeric) > 0:\n",
    "    print(f\"\\\\n   These {len(low_numeric)} features have very low importance:\")\n",
    "    for idx, row in low_numeric.iterrows():\n",
    "        pct = row['importance'] / total_importance * 100\n",
    "        print(f\"   {row['rank']:2d}. {row['feature']:30s}  (importance: {row['importance']:.6f}, {pct:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\\\n    Safe to drop?\")\n",
    "    print(f\"       description_has_emoji - Very low impact\")\n",
    "    print(f\"       screen_name_len - Very low impact\")\n",
    "    print(f\"       screen_name_digit_ratio - Very low impact\")\n",
    "    print(f\"       description_len - Keep (might interact with other features)\")\n",
    "    print(f\"\\\\n     But consider:\")\n",
    "    print(f\"       They cost almost nothing computationally\")\n",
    "    print(f\"       They may help with model interpretability\")\n",
    "    print(f\"       Test dropping them and see if CV score changes\")\n",
    "else:\n",
    "    print(\"    All numeric features have reasonable importance!\")\n",
    "\n",
    "print(f\"\\\\n Top performing numeric features (top 5):\")\n",
    "for idx, row in numeric_df.head(5).iterrows():\n",
    "    pct = row['importance'] / total_importance * 100\n",
    "    print(f\"   {row['rank']:2d}. {row['feature']:30s}  (importance: {row['importance']:.6f}, {pct:.2f}%)\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Numeric features bar chart\n",
    "ax = axes[0, 0]\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.9, len(numeric_df)))\n",
    "ax.barh(range(len(numeric_df)), numeric_df['importance'], color=colors)\n",
    "ax.set_yticks(range(len(numeric_df)))\n",
    "ax.set_yticklabels(numeric_df['feature'], fontsize=8)\n",
    "ax.set_xlabel('Importance', fontsize=10)\n",
    "ax.set_title('All 26 Numerical Features', fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.axvline(x=low_importance_threshold, color='red', linestyle='--', alpha=0.5, label=f'Low threshold ({low_importance_threshold})')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Cumulative importance\n",
    "ax = axes[0, 1]\n",
    "cumsum = np.cumsum(numeric_df['importance'].values)\n",
    "ax.plot(range(1, len(cumsum) + 1), cumsum, marker='o', linewidth=2, markersize=4)\n",
    "ax.fill_between(range(1, len(cumsum) + 1), cumsum, alpha=0.3)\n",
    "ax.set_xlabel('Number of Features (ranked)', fontsize=10)\n",
    "ax.set_ylabel('Cumulative Importance', fontsize=10)\n",
    "ax.set_title('Cumulative Importance of Numeric Features', fontsize=12, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.axhline(y=cumsum[9], color='orange', linestyle='--', alpha=0.7, label=f'Top 10 features: {cumsum[9]:.3f}')\n",
    "ax.axhline(y=cumsum[4], color='red', linestyle='--', alpha=0.7, label=f'Top 5 features: {cumsum[4]:.3f}')\n",
    "ax.legend()\n",
    "\n",
    "# 3. Feature categories\n",
    "ax = axes[1, 0]\n",
    "categories = {\n",
    "    'Verification/Geo': ['verified', 'geo_enabled', 'is_geo_or_verified', 'is_geo_and_not_verified', \n",
    "                         'is_not_geo_and_verified', 'is_geo_and_verified'],\n",
    "    'Counts (raw)': ['followers_count', 'friends_count', 'favourites_count'],\n",
    "    'Ratios/Rates': ['followers_friends_ratio', 'favourites_per_status', 'followers_per_day', 'statuses_per_follower', \n",
    "                     'average_tweets_per_day'],\n",
    "    'Description': ['description_has_link', 'description_has_bot', 'description_len', 'description_has_at', \n",
    "                    'description_has_emoji', 'description_has_capitalized', 'description_word_count'],\n",
    "    'Screen name': ['screen_name_len', 'screen_name_has_digits', 'screen_name_has_bot', 'screen_name_digit_ratio'],\n",
    "    'Account': ['account_age_days', 'default_profile', 'default_profile_image']\n",
    "}\n",
    "\n",
    "cat_importance = {}\n",
    "for cat_name, features in categories.items():\n",
    "    cat_importance[cat_name] = numeric_df[numeric_df['feature'].isin(features)]['importance'].sum()\n",
    "\n",
    "cat_names = list(cat_importance.keys())\n",
    "cat_values = list(cat_importance.values())\n",
    "colors_cat = plt.cm.Set3(range(len(cat_names)))\n",
    "\n",
    "ax.barh(cat_names, cat_values, color=colors_cat)\n",
    "ax.set_xlabel('Total Importance', fontsize=10)\n",
    "ax.set_title('Feature Importance by Category', fontsize=12, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Top vs bottom features comparison\n",
    "ax = axes[1, 1]\n",
    "top_5 = numeric_df.head(5)\n",
    "bottom_5 = numeric_df.tail(5)\n",
    "\n",
    "x_pos = np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "ax.barh(x_pos, top_5['importance'].values, width, label='Top 5', color='green', alpha=0.7)\n",
    "ax.barh(x_pos + width, bottom_5['importance'].values, width, label='Bottom 5', color='red', alpha=0.7)\n",
    "\n",
    "ax.set_yticks(x_pos + width / 2)\n",
    "ax.set_yticklabels([f\"Rank {i+1}\" for i in range(5)], fontsize=9)\n",
    "ax.set_xlabel('Importance', fontsize=10)\n",
    "ax.set_title('Top 5 vs Bottom 5 Numeric Features', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add text annotations\n",
    "for i, (top_feat, bot_feat) in enumerate(zip(top_5['feature'], bottom_5['feature'])):\n",
    "    ax.text(top_5['importance'].iloc[i] + 0.002, i, top_feat[:20], va='center', fontsize=7)\n",
    "    ax.text(bottom_5['importance'].iloc[i] + 0.0002, i + width, bot_feat[:20], va='center', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/numeric_features_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\n Comprehensive numeric features analysis saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bac1db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DECODING desc_text__svd COMPONENTS - What does component_14 mean?\n",
      "================================================================================\n",
      "\n",
      "TF-IDF vocabulary size: 3000\n",
      "SVD components shape: (40, 3000)\n",
      "(Each component is a weighted combination of 3000 words)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "desc_text__svd_14\n",
      "================================================================================\n",
      "\n",
      "  Top 20 POSITIVE words (high positive weight):\n",
      "     1. http                       (weight:  0.6580)\n",
      "     2. fan                        (weight:  0.2305)\n",
      "     3. lover                      (weight:  0.2122)\n",
      "     4. check                      (weight:  0.2027)\n",
      "     5. check https                (weight:  0.1736)\n",
      "     6. waiting                    (weight:  0.1576)\n",
      "     7. waiting https              (weight:  0.1553)\n",
      "     8. cosplay                    (weight:  0.1212)\n",
      "     9. cosplay fan                (weight:  0.0909)\n",
      "    10. fitness                    (weight:  0.0793)\n",
      "    11. lover waiting              (weight:  0.0710)\n",
      "    12. travel                     (weight:  0.0678)\n",
      "    13. lover check                (weight:  0.0547)\n",
      "    14. gamer                      (weight:  0.0515)\n",
      "    15. girl                       (weight:  0.0480)\n",
      "    16. animal lover               (weight:  0.0470)\n",
      "    17. animal                     (weight:  0.0443)\n",
      "    18. beauty                     (weight:  0.0438)\n",
      "    19. master                     (weight:  0.0407)\n",
      "    20. cosplay master             (weight:  0.0406)\n",
      "\n",
      "  Top 20 NEGATIVE words (high negative weight):\n",
      "     1. writer                     (weight: -0.2905)\n",
      "     2. actor                      (weight: -0.2648)\n",
      "     3. director                   (weight: -0.1251)\n",
      "     4. producer                   (weight: -0.1050)\n",
      "     5. host                       (weight: -0.0860)\n",
      "     6. author                     (weight: -0.0852)\n",
      "     7. founder                    (weight: -0.0667)\n",
      "     8. editor                     (weight: -0.0588)\n",
      "     9. tv                         (weight: -0.0502)\n",
      "    10. singer                     (weight: -0.0487)\n",
      "    11. actor writer               (weight: -0.0404)\n",
      "    12. https                      (weight: -0.0395)\n",
      "    13. creator                    (weight: -0.0391)\n",
      "    14. writer director            (weight: -0.0359)\n",
      "    15. just                       (weight: -0.0358)\n",
      "    16. father                     (weight: -0.0358)\n",
      "    17. comedian                   (weight: -0.0351)\n",
      "    18. actor producer             (weight: -0.0351)\n",
      "    19. twitter                    (weight: -0.0336)\n",
      "    20. husband                    (weight: -0.0328)\n",
      "\n",
      "  ============================================================================\n",
      "   INTERPRETATION OF desc_text__svd_14\n",
      "  ============================================================================\n",
      "  This is your MOST IMPORTANT text component!\n",
      "   Words with HIGH POSITIVE weights  strongly associated with BOTS\n",
      "   Words with HIGH NEGATIVE weights  strongly associated with HUMANS\n",
      "   This SVD component captures the #1 text pattern that separates bots from humans\n",
      "  ============================================================================\n",
      "\n",
      "================================================================================\n",
      "desc_text__svd_4\n",
      "================================================================================\n",
      "\n",
      "  Top 20 POSITIVE words (high positive weight):\n",
      "     1. love                       (weight:  0.6534)\n",
      "     2. life                       (weight:  0.1614)\n",
      "     3. just                       (weight:  0.1034)\n",
      "     4. twitter                    (weight:  0.0891)\n",
      "     5. music                      (weight:  0.0870)\n",
      "     6. want                       (weight:  0.0799)\n",
      "     7. fan                        (weight:  0.0772)\n",
      "     8. ig                         (weight:  0.0762)\n",
      "     9. lover                      (weight:  0.0675)\n",
      "    10. account                    (weight:  0.0623)\n",
      "    11. world                      (weight:  0.0596)\n",
      "    12. live                       (weight:  0.0594)\n",
      "    13. writer                     (weight:  0.0582)\n",
      "    14. official                   (weight:  0.0575)\n",
      "    15. mom                        (weight:  0.0567)\n",
      "    16. want https                 (weight:  0.0543)\n",
      "    17. time                       (weight:  0.0532)\n",
      "    18. family                     (weight:  0.0526)\n",
      "    19. official twitter           (weight:  0.0482)\n",
      "    20. things                     (weight:  0.0473)\n",
      "\n",
      "  Top 20 NEGATIVE words (high negative weight):\n",
      "     1. instagram                  (weight: -0.5610)\n",
      "     2. come                       (weight: -0.1005)\n",
      "     3. come https                 (weight: -0.0944)\n",
      "     4. com                        (weight: -0.0841)\n",
      "     5. snapchat                   (weight: -0.0687)\n",
      "     6. gmail                      (weight: -0.0614)\n",
      "     7. gmail com                  (weight: -0.0612)\n",
      "     8. instagram https            (weight: -0.0435)\n",
      "     9. facebook                   (weight: -0.0385)\n",
      "    10. like                       (weight: -0.0304)\n",
      "    11. en                         (weight: -0.0278)\n",
      "    12. fast come                  (weight: -0.0251)\n",
      "    13. like fast                  (weight: -0.0251)\n",
      "    14. fast                       (weight: -0.0224)\n",
      "    15. like slowly                (weight: -0.0214)\n",
      "    16. slowly come                (weight: -0.0214)\n",
      "    17. slowly                     (weight: -0.0203)\n",
      "    18. site https                 (weight: -0.0193)\n",
      "    19. site                       (weight: -0.0170)\n",
      "    20. gently come                (weight: -0.0155)\n",
      "\n",
      "================================================================================\n",
      "desc_text__svd_1\n",
      "================================================================================\n",
      "\n",
      "  Top 20 POSITIVE words (high positive weight):\n",
      "     1. come                       (weight:  0.5808)\n",
      "     2. come https                 (weight:  0.5440)\n",
      "     3. like                       (weight:  0.3130)\n",
      "     4. love                       (weight:  0.1071)\n",
      "     5. fast come                  (weight:  0.1053)\n",
      "     6. like fast                  (weight:  0.1053)\n",
      "     7. fast                       (weight:  0.1028)\n",
      "     8. like slowly                (weight:  0.0900)\n",
      "     9. slowly come                (weight:  0.0900)\n",
      "    10. slowly                     (weight:  0.0894)\n",
      "    11. harshly come               (weight:  0.0675)\n",
      "    12. love harshly               (weight:  0.0675)\n",
      "    13. harshly                    (weight:  0.0675)\n",
      "    14. site https                 (weight:  0.0675)\n",
      "    15. like gently                (weight:  0.0660)\n",
      "    16. gently come                (weight:  0.0660)\n",
      "    17. gently                     (weight:  0.0655)\n",
      "    18. site                       (weight:  0.0644)\n",
      "    19. come site                  (weight:  0.0408)\n",
      "    20. like site                  (weight:  0.0342)\n",
      "\n",
      "  Top 20 NEGATIVE words (high negative weight):\n",
      "     1. https                      (weight: -0.1915)\n",
      "     2. instagram                  (weight: -0.1801)\n",
      "     3. com                        (weight: -0.1347)\n",
      "     4. want                       (weight: -0.0958)\n",
      "     5. want https                 (weight: -0.0855)\n",
      "     6. twitter                    (weight: -0.0814)\n",
      "     7. gmail                      (weight: -0.0794)\n",
      "     8. gmail com                  (weight: -0.0786)\n",
      "     9. official                   (weight: -0.0728)\n",
      "    10. official twitter           (weight: -0.0483)\n",
      "    11. account                    (weight: -0.0411)\n",
      "    12. snapchat                   (weight: -0.0319)\n",
      "    13. check                      (weight: -0.0304)\n",
      "    14. ig                         (weight: -0.0285)\n",
      "    15. twitter account            (weight: -0.0271)\n",
      "    16. writer                     (weight: -0.0269)\n",
      "    17. actor                      (weight: -0.0268)\n",
      "    18. facebook                   (weight: -0.0264)\n",
      "    19. instagram https            (weight: -0.0254)\n",
      "    20. lover                      (weight: -0.0249)\n",
      "\n",
      "================================================================================\n",
      "desc_text__svd_0\n",
      "================================================================================\n",
      "\n",
      "  Top 20 POSITIVE words (high positive weight):\n",
      "     1. https                      (weight:  0.9498)\n",
      "     2. come                       (weight:  0.1577)\n",
      "     3. come https                 (weight:  0.1498)\n",
      "     4. like                       (weight:  0.0962)\n",
      "     5. want                       (weight:  0.0747)\n",
      "     6. want https                 (weight:  0.0690)\n",
      "     7. instagram                  (weight:  0.0480)\n",
      "     8. site https                 (weight:  0.0410)\n",
      "     9. site                       (weight:  0.0408)\n",
      "    10. like https                 (weight:  0.0383)\n",
      "    11. com                        (weight:  0.0348)\n",
      "    12. check                      (weight:  0.0334)\n",
      "    13. check https                (weight:  0.0268)\n",
      "    14. love                       (weight:  0.0267)\n",
      "    15. like site                  (weight:  0.0263)\n",
      "    16. waiting https              (weight:  0.0246)\n",
      "    17. waiting                    (weight:  0.0245)\n",
      "    18. fast come                  (weight:  0.0233)\n",
      "    19. like fast                  (weight:  0.0233)\n",
      "    20. twitter                    (weight:  0.0232)\n",
      "\n",
      "  Top 20 NEGATIVE words (high negative weight):\n",
      "     1.                         (weight:  0.0000)\n",
      "     2.                       (weight:  0.0000)\n",
      "     3.                   (weight:  0.0000)\n",
      "     4.                         (weight:  0.0000)\n",
      "     5. blah                       (weight:  0.0000)\n",
      "     6.                       (weight:  0.0000)\n",
      "     7.                          (weight:  0.0000)\n",
      "     8.                          (weight:  0.0000)\n",
      "     9.                          (weight:  0.0000)\n",
      "    10.                          (weight:  0.0000)\n",
      "    11.                         (weight:  0.0000)\n",
      "    12.                       (weight:  0.0000)\n",
      "    13.                         (weight:  0.0000)\n",
      "    14.                          (weight:  0.0000)\n",
      "    15. s                         (weight:  0.0000)\n",
      "    16.                          (weight:  0.0000)\n",
      "    17. bank                       (weight:  0.0000)\n",
      "    18. climatechange              (weight:  0.0000)\n",
      "    19. mp                         (weight:  0.0000)\n",
      "    20. bow                        (weight:  0.0000)\n",
      "\n",
      "================================================================================\n",
      "desc_text__svd_2\n",
      "================================================================================\n",
      "\n",
      "  Top 20 POSITIVE words (high positive weight):\n",
      "     1. instagram                  (weight:  0.4508)\n",
      "     2. com                        (weight:  0.4091)\n",
      "     3. love                       (weight:  0.2783)\n",
      "     4. gmail                      (weight:  0.2566)\n",
      "     5. gmail com                  (weight:  0.2546)\n",
      "     6. twitter                    (weight:  0.2224)\n",
      "     7. official                   (weight:  0.1872)\n",
      "     8. come                       (weight:  0.1335)\n",
      "     9. official twitter           (weight:  0.1279)\n",
      "    10. like                       (weight:  0.1252)\n",
      "    11. come https                 (weight:  0.1205)\n",
      "    12. account                    (weight:  0.1164)\n",
      "    13. life                       (weight:  0.0974)\n",
      "    14. ig                         (weight:  0.0928)\n",
      "    15. follow                     (weight:  0.0818)\n",
      "    16. contact                    (weight:  0.0731)\n",
      "    17. twitter account            (weight:  0.0727)\n",
      "    18. snapchat                   (weight:  0.0726)\n",
      "    19. just                       (weight:  0.0715)\n",
      "    20. writer                     (weight:  0.0710)\n",
      "\n",
      "  Top 20 NEGATIVE words (high negative weight):\n",
      "     1. https                      (weight: -0.1534)\n",
      "     2. want https                 (weight: -0.0824)\n",
      "     3. want                       (weight: -0.0821)\n",
      "     4. want dear                  (weight: -0.0176)\n",
      "     5. dear https                 (weight: -0.0174)\n",
      "     6. dear                       (weight: -0.0166)\n",
      "     7. waiting https              (weight: -0.0069)\n",
      "     8. waiting                    (weight: -0.0058)\n",
      "     9. check https                (weight: -0.0048)\n",
      "    10. cosplay master             (weight: -0.0018)\n",
      "    11. cosplay                    (weight: -0.0014)\n",
      "    12. beauty waiting             (weight: -0.0013)\n",
      "    13. lover waiting              (weight: -0.0013)\n",
      "    14. unicorn                    (weight: -0.0013)\n",
      "    15. favorite waiting           (weight: -0.0012)\n",
      "    16. cosplay fan                (weight: -0.0011)\n",
      "    17. fitness waiting            (weight: -0.0011)\n",
      "    18. travel check               (weight: -0.0011)\n",
      "    19. pole dancer                (weight: -0.0010)\n",
      "    20. donate                     (weight: -0.0010)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUICK SUMMARY: What words define desc_text__svd_14?\n",
      "================================================================================\n",
      "\n",
      " TOP BOT-ASSOCIATED WORDS:\n",
      "   http                  (+0.6580)\n",
      "   fan                   (+0.2305)\n",
      "   lover                 (+0.2122)\n",
      "   check                 (+0.2027)\n",
      "   check https           (+0.1736)\n",
      "   waiting               (+0.1576)\n",
      "   waiting https         (+0.1553)\n",
      "   cosplay               (+0.1212)\n",
      "   cosplay fan           (+0.0909)\n",
      "   fitness               (+0.0793)\n",
      "   lover waiting         (+0.0710)\n",
      "   travel                (+0.0678)\n",
      "   lover check           (+0.0547)\n",
      "   gamer                 (+0.0515)\n",
      "   girl                  (+0.0480)\n",
      "\n",
      " TOP HUMAN-ASSOCIATED WORDS:\n",
      "   writer                (-0.2905)\n",
      "   actor                 (-0.2648)\n",
      "   director              (-0.1251)\n",
      "   producer              (-0.1050)\n",
      "   host                  (-0.0860)\n",
      "   author                (-0.0852)\n",
      "   founder               (-0.0667)\n",
      "   editor                (-0.0588)\n",
      "   tv                    (-0.0502)\n",
      "   singer                (-0.0487)\n",
      "   actor writer          (-0.0404)\n",
      "   https                 (-0.0395)\n",
      "   creator               (-0.0391)\n",
      "   writer director       (-0.0359)\n",
      "   just                  (-0.0358)\n",
      "\n",
      "================================================================================\n",
      "FINAL RECOMMENDATIONS: What features should you drop?\n",
      "================================================================================\n",
      "\n",
      " DEFINITELY KEEP:\n",
      "    is_geo_or_verified, verified, followers_count (top 3 numeric - 42.77% importance!)\n",
      "    All text SVD components (desc_text__svd_X) - these are your star performers\n",
      "    description_has_bot, description_has_link (important text patterns)\n",
      "    followers_per_day, is_not_geo_and_verified (top growth/interaction features)\n",
      "\n",
      "  CONSIDER DROPPING (test first!):\n",
      "    description_has_emoji (0.50% importance) - minimal impact\n",
      "    screen_name_len (0.58% importance) - minimal impact  \n",
      "    screen_name_digit_ratio (0.62% importance) - minimal impact\n",
      "    description_len (0.68% importance) - on the fence\n",
      "\n",
      " BIGGEST WIN:\n",
      "    Reduce categorical feature explosion (47k features!)\n",
      "    Use: OneHotEncoder(max_categories=50) or (handle_unknown='infrequent_if_exist')\n",
      "    This will speed up training 10x without losing much accuracy\n",
      "\n",
      " ACTION PLAN:\n",
      "   1. Keep all 26 numeric features for now (cheap to compute)\n",
      "   2. Fix categorical encoding to reduce from 47k to ~100 features\n",
      "   3. Keep all text SVD components (40 + 8)\n",
      "   4. After fixing categoricals, test dropping bottom 3-4 numeric features\n",
      "   5. Monitor CV score - if it drops < 0.001, the features were useful!\n",
      "\n",
      " EXPECTED IMPACT:\n",
      "    Dropping 4 lowest numeric: ~2% total importance loss  likely < 0.0005 AUC drop\n",
      "    Fixing categoricals: 10x faster training, minimal AUC change\n",
      "    Net result: Faster, cleaner model with same performance!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========= DECODE TEXT SVD COMPONENTS ========= #\n",
    "# Shows what words/patterns each SVD component represents\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DECODING desc_text__svd COMPONENTS - What does component_14 mean?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get the description text pipeline\n",
    "desc_pipeline = None\n",
    "for name, trans, cols in preprocessor.transformers_:\n",
    "    if name == 'desc_text':\n",
    "        desc_pipeline = trans\n",
    "        break\n",
    "\n",
    "if desc_pipeline is not None and hasattr(desc_pipeline, 'named_steps'):\n",
    "    tfidf = desc_pipeline.named_steps.get('tfidf')\n",
    "    svd = desc_pipeline.named_steps.get('svd')\n",
    "    \n",
    "    if tfidf and svd and hasattr(tfidf, 'vocabulary_') and hasattr(svd, 'components_'):\n",
    "        # Get vocabulary (word -> index mapping)\n",
    "        vocab = tfidf.vocabulary_\n",
    "        # Reverse mapping (index -> word)\n",
    "        index_to_word = {idx: word for word, idx in vocab.items()}\n",
    "        \n",
    "        # SVD components matrix: shape (n_components, n_features)\n",
    "        # Each row is one component, each column is one TF-IDF feature (word)\n",
    "        components = svd.components_\n",
    "        \n",
    "        print(f\"\\nTF-IDF vocabulary size: {len(vocab)}\")\n",
    "        print(f\"SVD components shape: {components.shape}\")\n",
    "        print(f\"(Each component is a weighted combination of {components.shape[1]} words)\\n\")\n",
    "        \n",
    "        # Show the most important components (based on what we know from earlier)\n",
    "        # Component 14, 4, and 1 were the most important\n",
    "        important_components = [14, 4, 1, 0, 2, 3, 5, 6, 7, 8]\n",
    "        \n",
    "        for comp_idx in important_components[:5]:  # Show top 5\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"desc_text__svd_{comp_idx}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Get the component weights\n",
    "            component_weights = components[comp_idx]\n",
    "            \n",
    "            # Get top positive and negative weights\n",
    "            top_positive_idx = np.argsort(component_weights)[-20:][::-1]\n",
    "            top_negative_idx = np.argsort(component_weights)[:20]\n",
    "            \n",
    "            print(\"\\n  Top 20 POSITIVE words (high positive weight):\")\n",
    "            for i, idx in enumerate(top_positive_idx, 1):\n",
    "                word = index_to_word.get(idx, f\"word_{idx}\")\n",
    "                weight = component_weights[idx]\n",
    "                print(f\"    {i:2d}. {word:25s}  (weight: {weight:7.4f})\")\n",
    "            \n",
    "            print(\"\\n  Top 20 NEGATIVE words (high negative weight):\")\n",
    "            for i, idx in enumerate(top_negative_idx, 1):\n",
    "                word = index_to_word.get(idx, f\"word_{idx}\")\n",
    "                weight = component_weights[idx]\n",
    "                print(f\"    {i:2d}. {word:25s}  (weight: {weight:7.4f})\")\n",
    "            \n",
    "            if comp_idx == 14:\n",
    "                print(\"\\n  \" + \"=\"*76)\n",
    "                print(\"   INTERPRETATION OF desc_text__svd_14\")\n",
    "                print(\"  \" + \"=\"*76)\n",
    "                print(\"  This is your MOST IMPORTANT text component!\")\n",
    "                print(\"   Words with HIGH POSITIVE weights  strongly associated with BOTS\")\n",
    "                print(\"   Words with HIGH NEGATIVE weights  strongly associated with HUMANS\")\n",
    "                print(\"   This SVD component captures the #1 text pattern that separates bots from humans\")\n",
    "                print(\"  \" + \"=\"*76)\n",
    "        \n",
    "        # Create a word cloud style visualization\n",
    "        print(\"\\n\\n\" + \"=\"*80)\n",
    "        print(\"QUICK SUMMARY: What words define desc_text__svd_14?\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        comp_14 = components[14]\n",
    "        top_bot_words_idx = np.argsort(comp_14)[-15:][::-1]\n",
    "        top_human_words_idx = np.argsort(comp_14)[:15]\n",
    "        \n",
    "        print(\"\\n TOP BOT-ASSOCIATED WORDS:\")\n",
    "        bot_words = [(index_to_word.get(idx, f\"word_{idx}\"), comp_14[idx]) \n",
    "                     for idx in top_bot_words_idx]\n",
    "        for word, weight in bot_words:\n",
    "            print(f\"   {word:20s}  ({weight:+.4f})\")\n",
    "        \n",
    "        print(\"\\n TOP HUMAN-ASSOCIATED WORDS:\")\n",
    "        human_words = [(index_to_word.get(idx, f\"word_{idx}\"), comp_14[idx]) \n",
    "                       for idx in top_human_words_idx]\n",
    "        for word, weight in human_words:\n",
    "            print(f\"   {word:20s}  ({weight:+.4f})\")\n",
    "        \n",
    "    else:\n",
    "        print(\" Could not access TF-IDF vocabulary or SVD components\")\n",
    "else:\n",
    "    print(\" Could not find description text pipeline\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RECOMMENDATIONS: What features should you drop?\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    " DEFINITELY KEEP:\n",
    "    is_geo_or_verified, verified, followers_count (top 3 numeric - 42.77% importance!)\n",
    "    All text SVD components (desc_text__svd_X) - these are your star performers\n",
    "    description_has_bot, description_has_link (important text patterns)\n",
    "    followers_per_day, is_not_geo_and_verified (top growth/interaction features)\n",
    "\n",
    "  CONSIDER DROPPING (test first!):\n",
    "    description_has_emoji (0.50% importance) - minimal impact\n",
    "    screen_name_len (0.58% importance) - minimal impact  \n",
    "    screen_name_digit_ratio (0.62% importance) - minimal impact\n",
    "    description_len (0.68% importance) - on the fence\n",
    "\n",
    " BIGGEST WIN:\n",
    "    Reduce categorical feature explosion (47k features!)\n",
    "    Use: OneHotEncoder(max_categories=50) or (handle_unknown='infrequent_if_exist')\n",
    "    This will speed up training 10x without losing much accuracy\n",
    "\n",
    " ACTION PLAN:\n",
    "   1. Keep all 26 numeric features for now (cheap to compute)\n",
    "   2. Fix categorical encoding to reduce from 47k to ~100 features\n",
    "   3. Keep all text SVD components (40 + 8)\n",
    "   4. After fixing categoricals, test dropping bottom 3-4 numeric features\n",
    "   5. Monitor CV score - if it drops < 0.001, the features were useful!\n",
    "\n",
    " EXPECTED IMPACT:\n",
    "    Dropping 4 lowest numeric: ~2% total importance loss  likely < 0.0005 AUC drop\n",
    "    Fixing categoricals: 10x faster training, minimal AUC change\n",
    "    Net result: Faster, cleaner model with same performance!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a47fa",
   "metadata": {},
   "source": [
    "4000 max_features\n",
    "\n",
    "================================================================================\n",
    "FEATURE IMPORTANCE SUMMARY\n",
    "================================================================================\n",
    "Total features: 50\n",
    "Top 10 features account for: 53.23% of total importance\n",
    "Top 50 features account for: 70.22% of total importance\n",
    "Mean importance: 0.014045\n",
    "Median importance: 0.003610"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381e34b",
   "metadata": {},
   "source": [
    "increasing tf-idf max features from 2000 to 4000:\n",
    "CV AUC: 0.9463680027686614 (lower)\n",
    "2000 to 3000: even lower\n",
    "\n",
    "use: OneHotEncoder(max_categories=50, handle_unknown='infrequent_if_exist')\n",
    "CV AUC: 0.946666124621012 (highest!!)\n",
    "public score: 0.94235 (highest)\n",
    "100 categories: 0.9465335787191218\n",
    "75 categories: 0.9465335787191218\n",
    "40 categories: 0.9467717521386734 (highestttt)\n",
    "30 categories: 0.9465074679762804 -> public score: 0.94261 (higher)\n",
    "\n",
    "decrease desc_components from 40 to 30\n",
    "CV AUC: 0.9463838547207862 -> falls\n",
    "increase to 50\n",
    "CV AUC: 0.9464922000002541 \n",
    "\n",
    "description_has_capitalized - worsen\n",
    "CV AUC: 0.9465462287890378\n",
    "\n",
    "description_cap_ratio\n",
    "CV AUC: 0.9463270317457046 -> worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de22b7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9467717521386734\n",
      " Model saved\n",
      " Submission created\n"
     ]
    }
   ],
   "source": [
    "#without geoenabled and verified interaction\n",
    "# CV AUC: 0.9461810576257423\n",
    "# with \n",
    "# CV AUC: 0.9462335346853962\n",
    "# public score: 0.94147\n",
    "\n",
    "# add description_has_follow -- CV AUC: 0.9460825004785388 (worsen)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    # X can be a 1D array or 2D array with shape (n_samples, 1)\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    # reference_date: use a fixed date for reproducibility if provided, otherwise use current date\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        link_pattern = r'(http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        # emoji_re = re.compile(\n",
    "        #     r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        #     r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        #     r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        #     r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        #     r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "        #     r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "        #     r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "        #     r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "        #     r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "        #     r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "        #     r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        #     r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "\n",
    "        # X['description_has_follow'] = desc.str.contains(r'\\b(follow|subscribe)\\b').fillna(False).astype(int)\n",
    "        # X['description_has_contact'] = desc.str.contains(r'\\b(contact|reach me|email|dm|direct message)\\b').fillna(False).astype(int)\n",
    "        # X['description_has_social_media'] = desc.str.contains(r'\\b(whatsapp|wa|insta|instagram|fb|facebook|snapchat|sc|tiktok|telegram|tg|linkedin|linkdln|linkdn|wechat|weibo|line|kik|viber|signal|hike|discord|reddit|pinterest|tumblr|flickr|quora|medium)\\b').fillna(False).astype(int)\n",
    "        # X['description_has_capitalized'] = desc.str.contains(r'[A-Z]').fillna(False).astype(int)\n",
    "        # X['description_cap_ratio'] = (\n",
    "        #     X['description'].fillna('').apply(lambda s: sum(1 for c in s if c.isupper()) / len(s) if len(s) > 0 else 0)\n",
    "        # )\n",
    "\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        # X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "\n",
    "        # X['description_has_follow'] = 0\n",
    "\n",
    "    # === created_at -> account_age_days ===\n",
    "    if 'account_age_days' not in X.columns or X['account_age_days'].isna().any():\n",
    "        if 'created_at' in X.columns:\n",
    "            # try parsing created_at to days difference from reference_date\n",
    "            try:\n",
    "                created = pd.to_datetime(X['created_at'], errors='coerce')\n",
    "                X['account_age_days'] = (reference_date - created).dt.days.fillna(0).astype(int)\n",
    "            except Exception:\n",
    "                # fallback if parsing fails\n",
    "                X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "        else:\n",
    "            # if neither exists, fill with median later through imputer\n",
    "            X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "\n",
    "    # === screen_name features ===\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d').astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_').astype(int)\n",
    "        # ratio of digits to length\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "        # X['screen_name_has_underscore'] = sn.str.contains(r'_').astype(int)\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "        # X['screen_name_has_underscore'] = 0\n",
    "\n",
    "    # === boolean-like flags to numeric ===\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    # === Language grouping ===\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        # high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af', 'ja', 'cy', 'so']     # > 0.4 bot rate\n",
    "        low_bot = [ 'ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']     # > 0.5 bot rate\n",
    "        mid_bot = ['ja', 'cy', 'so']                     # 0.40.5 bot rate\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he'] # < 20 samples\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            # ['high_bot_lang', 'mid_bot_lang', 'english'],\n",
    "            # ['high_bot_lang','low_bot_lang','english'],\n",
    "            # ['high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            ['low_freq_lang', 'high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    # return X\n",
    "\n",
    "    # === Location binning and low-frequency flagging ===\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "# ...existing code...\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "\n",
    "    Usage:\n",
    "      # On training data (requires 'target'):\n",
    "      df_train, loc_groups = map_loc_bin(df_train, min_samples=30)\n",
    "\n",
    "      # On test data (reuse mapping from train):\n",
    "      df_test, _ = map_loc_bin(df_test, loc_groups=loc_groups)\n",
    "\n",
    "    Returns:\n",
    "      df (modified copy), loc_groups (dict with 'mapping', 'low_freq', 'groups')\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "        # bins = [0.0, 0.1, 0.3, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    # If no precomputed groups provided, build from df (training mode)\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        # Keep locations with enough samples for reliable proportion\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        # accept either full loc_groups dict or just mapping\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    # Map each location to a combined bin\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    # df['loc_low_freq'] = df['location'].isin(low_freq).astype(int)\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "\n",
    "    return df, loc_groups\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    # keep `description` and `screen_name` for text features; drop raw location/lang/ids that we've summarized\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \"lang\", \"location\", \"created_at\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    # note: X is expected to already contain feature-engineered cols (main applies apply_feature_engineering)\n",
    "    X_temp = drop_columns(cap_and_log(X))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        # (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    # Add text pipelines if description / screen_name exist\n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # description -> TF-IDF -> SVD\n",
    "    if 'description' in X_temp.columns:\n",
    "        desc_components = 40\n",
    "        # ensure we pass a 1D array of strings (no NaN) into TfidfVectorizer\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=desc_components, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # screen_name -> TF-IDF -> SVD (shorter)\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        sn_components = 8\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=sn_components, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # model = XGBClassifier(\n",
    "    #     n_estimators=300,\n",
    "    #     learning_rate=0.05,\n",
    "    #     max_depth=6,\n",
    "    #     subsample=0.8,\n",
    "    #     colsample_bytree=0.8,\n",
    "    #     random_state=42,\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric=\"logloss\"\n",
    "    # )\n",
    "    # {'n_estimators': 350, 'learning_rate': 0.03008393676525409, 'max_depth': 9, 'subsample': 0.9809503155616375, 'colsample_bytree': 0.56044353273329, 'reg_alpha': 1.2338019395219242, 'reg_lambda': 1.6264975818536396, 'min_child_weight': 3, 'gamma': 0.36491328244932486}\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=350,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=9,\n",
    "        subsample=0.98,\n",
    "        colsample_bytree=0.56,\n",
    "        reg_alpha=1.23,\n",
    "        reg_lambda=1.63,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.36,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        # (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    # X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    X_fe, loc_groups = apply_feature_engineering(train)\n",
    "    X = X_fe.drop(columns=['target'])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "    # pipeline = build_pipeline(X_fe)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Feature importance\n",
    "    # if hasattr(pipeline.named_steps['model'], 'feature_importances_'):\n",
    "    #     importances = pipeline.named_steps['model'].feature_importances_\n",
    "    #     print(\"Feature importances:\", importances)\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_fe, _ = apply_feature_engineering(test, loc_groups=loc_groups)\n",
    "    test_probs = pipeline.predict_proba(test_fe)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6534b",
   "metadata": {},
   "source": [
    "adding stuff:\n",
    "min frequency to onehot : \n",
    "    10 -> CV AUC: 0.9467111533161185\n",
    "    5 -> CV AUC: 0.9466593395394056\n",
    "increasing max_features and changing ngrams to (1,3):\n",
    "    falls\n",
    "description_has_url_pattern:\n",
    "    CV AUC: 0.9467816258644666 (increase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f964a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_21687/376462202.py:63: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_21687/376462202.py:67: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_21687/376462202.py:97: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_url_pattern'] = desc.str.contains(r'\\.(com|org|net|io)\\b').astype(int)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:47:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:47:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:47:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:47:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:47:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:47:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:47:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:47:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:48:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:48:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.946463052316887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:48:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_21687/376462202.py:63: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_21687/376462202.py:67: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_21687/376462202.py:97: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_url_pattern'] = desc.str.contains(r'\\.(com|org|net|io)\\b').astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission created\n"
     ]
    }
   ],
   "source": [
    "#without geoenabled and verified interaction\n",
    "# CV AUC: 0.9461810576257423\n",
    "# with \n",
    "# CV AUC: 0.9462335346853962\n",
    "# public score: 0.94147\n",
    "\n",
    "# add description_has_follow -- CV AUC: 0.9460825004785388 (worsen)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    # X can be a 1D array or 2D array with shape (n_samples, 1)\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    # reference_date: use a fixed date for reproducibility if provided, otherwise use current date\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "    \n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        link_pattern = r'(http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        # emoji_re = re.compile(\n",
    "        #     r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        #     r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        #     r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        #     r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        #     r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "        #     r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "        #     r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "        #     r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "        #     r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "        #     r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "        #     r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        #     r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "\n",
    "        # X['description_has_follow'] = desc.str.contains(r'\\b(follow|subscribe)\\b').fillna(False).astype(int)\n",
    "        # X['description_has_contact'] = desc.str.contains(r'\\b(contact|reach me|email|dm|direct message)\\b').fillna(False).astype(int)\n",
    "        # X['description_has_social_media'] = desc.str.contains(r'\\b(whatsapp|wa|insta|instagram|fb|facebook|snapchat|sc|tiktok|telegram|tg|linkedin|linkdln|linkdn|wechat|weibo|line|kik|viber|signal|hike|discord|reddit|pinterest|tumblr|flickr|quora|medium)\\b').fillna(False).astype(int)\n",
    "        # X['description_has_capitalized'] = desc.str.contains(r'[A-Z]').fillna(False).astype(int)\n",
    "        # X['description_cap_ratio'] = (\n",
    "        #     X['description'].fillna('').apply(lambda s: sum(1 for c in s if c.isupper()) / len(s) if len(s) > 0 else 0)\n",
    "        # )\n",
    "        # X['description_has_hashtag'] = desc.str.contains(r'#').astype(int)\n",
    "        X['description_has_url_pattern'] = desc.str.contains(r'\\.(com|org|net|io)\\b').astype(int)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        # X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "\n",
    "        # X['description_has_follow'] = 0\n",
    "\n",
    "    # === created_at -> account_age_days ===\n",
    "    if 'account_age_days' not in X.columns or X['account_age_days'].isna().any():\n",
    "        if 'created_at' in X.columns:\n",
    "            # try parsing created_at to days difference from reference_date\n",
    "            try:\n",
    "                created = pd.to_datetime(X['created_at'], errors='coerce')\n",
    "                X['account_age_days'] = (reference_date - created).dt.days.fillna(0).astype(int)\n",
    "            except Exception:\n",
    "                # fallback if parsing fails\n",
    "                X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "        else:\n",
    "            # if neither exists, fill with median later through imputer\n",
    "            X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "\n",
    "    # === screen_name features ===\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d').astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_').astype(int)\n",
    "        # ratio of digits to length\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "        # X['screen_name_has_underscore'] = sn.str.contains(r'_').astype(int)\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "        # X['screen_name_has_underscore'] = 0\n",
    "\n",
    "    # === boolean-like flags to numeric ===\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    # === Language grouping ===\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        # high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af', 'ja', 'cy', 'so']     # > 0.4 bot rate\n",
    "        low_bot = [ 'ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']     # > 0.5 bot rate\n",
    "        mid_bot = ['ja', 'cy', 'so']                     # 0.40.5 bot rate\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he'] # < 20 samples\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            # ['high_bot_lang', 'mid_bot_lang', 'english'],\n",
    "            # ['high_bot_lang','low_bot_lang','english'],\n",
    "            # ['high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            ['low_freq_lang', 'high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    # return X\n",
    "\n",
    "    # === Location binning and low-frequency flagging ===\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "\n",
    "    # X['verified_with_followers'] = X['verified'] * np.log1p(X['followers_count'])\n",
    "    # X['bot_description_no_verification'] = X['description_has_bot'] * (1 - X['verified'])\n",
    "    # X['high_friends_low_followers'] = np.where(\n",
    "    #     (X['friends_count'] > X['followers_count'] * 2) & (X['followers_count'] < 100), \n",
    "    #     1, 0\n",
    "    # )\n",
    "    # X['high_friends_low_followers'] = np.where(\n",
    "    #     (X['friends_count'] > X['followers_count'] * 2), \n",
    "    #     1, 0\n",
    "    # )\n",
    "    # X['new_account_high_activity'] = np.where(\n",
    "    #     (X['account_age_days'] < 365) & (X['average_tweets_per_day'] > 10),\n",
    "    #     1, 0\n",
    "    # )\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "# ...existing code...\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "\n",
    "    Usage:\n",
    "      # On training data (requires 'target'):\n",
    "      df_train, loc_groups = map_loc_bin(df_train, min_samples=30)\n",
    "\n",
    "      # On test data (reuse mapping from train):\n",
    "      df_test, _ = map_loc_bin(df_test, loc_groups=loc_groups)\n",
    "\n",
    "    Returns:\n",
    "      df (modified copy), loc_groups (dict with 'mapping', 'low_freq', 'groups')\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "        # bins = [0.0, 0.1, 0.3, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    # If no precomputed groups provided, build from df (training mode)\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        # Keep locations with enough samples for reliable proportion\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        # accept either full loc_groups dict or just mapping\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    # Map each location to a combined bin\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    # df['loc_low_freq'] = df['location'].isin(low_freq).astype(int)\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "\n",
    "    return df, loc_groups\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day', 'status_count'\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    # keep `description` and `screen_name` for text features; drop raw location/lang/ids that we've summarized\n",
    "    # drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \"lang\", \"location\", \"created_at\"]\n",
    "    drop_cols = [\"id\", \"profile_background_image_url\", \"profile_image_url\", \"lang\", \"location\", \"created_at\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    # note: X is expected to already contain feature-engineered cols (main applies apply_feature_engineering)\n",
    "    X_temp = drop_columns(cap_and_log(X))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        # (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40,handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    # Add text pipelines if description / screen_name exist\n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # description -> TF-IDF -> SVD\n",
    "    if 'description' in X_temp.columns:\n",
    "        desc_components = 40\n",
    "        # ensure we pass a 1D array of strings (no NaN) into TfidfVectorizer\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=desc_components, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # screen_name -> TF-IDF -> SVD (shorter)\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        sn_components = 8\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=sn_components, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # model = XGBClassifier(\n",
    "    #     n_estimators=300,\n",
    "    #     learning_rate=0.05,\n",
    "    #     max_depth=6,\n",
    "    #     subsample=0.8,\n",
    "    #     colsample_bytree=0.8,\n",
    "    #     random_state=42,\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric=\"logloss\"\n",
    "    # )\n",
    "    # {'n_estimators': 350, 'learning_rate': 0.03008393676525409, 'max_depth': 9, 'subsample': 0.9809503155616375, 'colsample_bytree': 0.56044353273329, 'reg_alpha': 1.2338019395219242, 'reg_lambda': 1.6264975818536396, 'min_child_weight': 3, 'gamma': 0.36491328244932486}\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=350,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=9,\n",
    "        subsample=0.98,\n",
    "        colsample_bytree=0.56,\n",
    "        reg_alpha=1.23,\n",
    "        reg_lambda=1.63,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.36,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        # (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    # X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    X_fe, loc_groups = apply_feature_engineering(train)\n",
    "    X = X_fe.drop(columns=['target'])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "    # pipeline = build_pipeline(X_fe)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Feature importance\n",
    "    # if hasattr(pipeline.named_steps['model'], 'feature_importances_'):\n",
    "    #     importances = pipeline.named_steps['model'].feature_importances_\n",
    "    #     print(\"Feature importances:\", importances)\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_fe, _ = apply_feature_engineering(test, loc_groups=loc_groups)\n",
    "    test_probs = pipeline.predict_proba(test_fe)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71aab1",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna\n",
    "\n",
    "We'll use Optuna to automatically search for the best XGBoost hyperparameters. The objective function will:\n",
    "1. Build a pipeline with the candidate hyperparameters\n",
    "2. Perform 3-fold stratified CV to estimate AUC\n",
    "3. Return the mean CV AUC (Optuna will maximize this)\n",
    "\n",
    "We'll tune: `n_estimators`, `learning_rate`, `max_depth`, `subsample`, `colsample_bytree`, `reg_alpha`, `reg_lambda`, `min_child_weight`, and `gamma`.\n",
    "\n",
    "**Note**: This will take time (20-50 trials  ~2-5 min/trial). Consider running with fewer trials for a quick test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f939822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:43:02,426] A new study created in memory with name: xgboost_bot_detection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting Optuna hyperparameter search...\n",
      "   This will take some time. Monitor progress below.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 0. Best value: 0.943391:   2%|         | 1/50 [00:19<15:41, 19.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:43:21,647] Trial 0 finished with value: 0.9433908479646924 and parameters: {'n_estimators': 250, 'learning_rate': 0.08927180304353628, 'max_depth': 10, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.4936111842654619, 'reg_alpha': 0.026364803038431653, 'reg_lambda': 0.014347159517201415, 'min_child_weight': 9, 'gamma': 0.6011150117432088}. Best is trial 0 with value: 0.9433908479646924.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:   4%|         | 2/50 [01:01<26:19, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:44:04,135] Trial 1 finished with value: 0.9462165073855378 and parameters: {'n_estimators': 400, 'learning_rate': 0.010485387725194618, 'max_depth': 12, 'subsample': 0.9329770563201687, 'colsample_bytree': 0.5274034664069657, 'reg_alpha': 0.030955664602423716, 'reg_lambda': 0.0312610291031106, 'min_child_weight': 4, 'gamma': 0.5247564316322378}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:   6%|         | 3/50 [01:22<21:26, 27.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:44:24,902] Trial 2 finished with value: 0.944852764065863 and parameters: {'n_estimators': 250, 'learning_rate': 0.019553708662745254, 'max_depth': 9, 'subsample': 0.6557975442608167, 'colsample_bytree': 0.575286789121131, 'reg_alpha': 0.09745399020374085, 'reg_lambda': 0.17018418817029168, 'min_child_weight': 8, 'gamma': 0.19967378215835974}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:   8%|         | 4/50 [01:34<16:28, 21.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:44:37,411] Trial 3 finished with value: 0.9323897110387426 and parameters: {'n_estimators': 300, 'learning_rate': 0.03912141628549697, 'max_depth': 3, 'subsample': 0.8430179407605753, 'colsample_bytree': 0.502314474212375, 'reg_alpha': 0.014982086432155482, 'reg_lambda': 3.639264345367793, 'min_child_weight': 10, 'gamma': 0.8083973481164611}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:  10%|         | 5/50 [01:53<15:26, 20.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:44:56,413] Trial 4 finished with value: 0.9415782434091364 and parameters: {'n_estimators': 200, 'learning_rate': 0.012521954287060391, 'max_depth': 9, 'subsample': 0.7760609974958405, 'colsample_bytree': 0.47322294090686734, 'reg_alpha': 0.21700394405050158, 'reg_lambda': 0.012382649697023556, 'min_child_weight': 10, 'gamma': 0.2587799816000169}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:44:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:  12%|        | 6/50 [02:17<15:43, 21.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:45:19,497] Trial 5 finished with value: 0.9442164784078262 and parameters: {'n_estimators': 350, 'learning_rate': 0.02049798052095018, 'max_depth': 8, 'subsample': 0.8186841117373118, 'colsample_bytree': 0.5109126733153162, 'reg_alpha': 4.138851334163265, 'reg_lambda': 1.236118879733734, 'min_child_weight': 10, 'gamma': 0.8948273504276488}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:  14%|        | 7/50 [02:30<13:33, 18.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:45:33,237] Trial 6 finished with value: 0.9389190494493379 and parameters: {'n_estimators': 350, 'learning_rate': 0.0835361075531176, 'max_depth': 3, 'subsample': 0.678393144967658, 'colsample_bytree': 0.4271363733463229, 'reg_alpha': 0.07551909976018513, 'reg_lambda': 0.11195109511439837, 'min_child_weight': 3, 'gamma': 0.8287375091519293}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:  16%|        | 8/50 [02:50<13:20, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:45:52,570] Trial 7 finished with value: 0.9431558091282982 and parameters: {'n_estimators': 250, 'learning_rate': 0.01909565280104538, 'max_depth': 8, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.8813181884524238, 'reg_alpha': 0.01589314885825813, 'reg_lambda': 4.608697883952072, 'min_child_weight': 8, 'gamma': 0.1987156815341724}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:  18%|        | 9/50 [03:06<12:23, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:46:08,701] Trial 8 finished with value: 0.9448708641137287 and parameters: {'n_estimators': 100, 'learning_rate': 0.06538248584518043, 'max_depth': 10, 'subsample': 0.8916028672163949, 'colsample_bytree': 0.8627622080115674, 'reg_alpha': 0.01584325068438868, 'reg_lambda': 0.09278723835524694, 'min_child_weight': 2, 'gamma': 0.8631034258755935}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 1. Best value: 0.946217:  20%|        | 10/50 [03:19<11:08, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:46:22,216] Trial 9 finished with value: 0.927648627185261 and parameters: {'n_estimators': 350, 'learning_rate': 0.02142387495644906, 'max_depth': 3, 'subsample': 0.7243929286862648, 'colsample_bytree': 0.5951099932160483, 'reg_alpha': 0.9315049998499164, 'reg_lambda': 0.5257127272786868, 'min_child_weight': 9, 'gamma': 0.4722149251619493}. Best is trial 1 with value: 0.9462165073855378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 10. Best value: 0.946392:  22%|       | 11/50 [04:12<17:59, 27.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:47:14,800] Trial 10 finished with value: 0.9463923638186413 and parameters: {'n_estimators': 500, 'learning_rate': 0.010139048090380883, 'max_depth': 12, 'subsample': 0.9810323243403002, 'colsample_bytree': 0.7274309680493293, 'reg_alpha': 0.7293838570500595, 'reg_lambda': 0.048914118687593024, 'min_child_weight': 5, 'gamma': 0.4792951727359478}. Best is trial 10 with value: 0.9463923638186413.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:47:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 10. Best value: 0.946392:  24%|       | 12/50 [05:02<21:53, 34.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:48:05,068] Trial 11 finished with value: 0.9462672241050865 and parameters: {'n_estimators': 500, 'learning_rate': 0.010195761595928408, 'max_depth': 12, 'subsample': 0.9884860601009259, 'colsample_bytree': 0.7230991331057792, 'reg_alpha': 0.788068831487826, 'reg_lambda': 0.0346442741627291, 'min_child_weight': 5, 'gamma': 0.48341897064943684}. Best is trial 10 with value: 0.9463923638186413.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  26%|       | 13/50 [05:48<23:20, 37.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:48:50,504] Trial 12 finished with value: 0.9465300448406078 and parameters: {'n_estimators': 500, 'learning_rate': 0.013798879007647813, 'max_depth': 12, 'subsample': 0.9995060732338602, 'colsample_bytree': 0.7281931493003116, 'reg_alpha': 0.865316281896809, 'reg_lambda': 0.03957294609537995, 'min_child_weight': 6, 'gamma': 0.3945277342875057}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:48:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  28%|       | 14/50 [06:13<20:24, 34.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:49:15,686] Trial 13 finished with value: 0.9435878604350847 and parameters: {'n_estimators': 500, 'learning_rate': 0.01422972884572149, 'max_depth': 6, 'subsample': 0.9997449754566207, 'colsample_bytree': 0.7383162215340979, 'reg_alpha': 1.1927293107480876, 'reg_lambda': 0.048727288629626955, 'min_child_weight': 6, 'gamma': 0.3745901082381332}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  30%|       | 15/50 [06:52<20:50, 35.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:49:55,378] Trial 14 finished with value: 0.9460006302223964 and parameters: {'n_estimators': 450, 'learning_rate': 0.031490027357049935, 'max_depth': 12, 'subsample': 0.9406922517300094, 'colsample_bytree': 0.9970042655939768, 'reg_alpha': 2.6922973407100486, 'reg_lambda': 0.32224086458128676, 'min_child_weight': 6, 'gamma': 0.6326424826625558}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:49:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  32%|      | 16/50 [07:48<23:32, 41.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:50:50,439] Trial 15 finished with value: 0.946468763122212 and parameters: {'n_estimators': 450, 'learning_rate': 0.015603395817192153, 'max_depth': 11, 'subsample': 0.9253031597060487, 'colsample_bytree': 0.6563209767092624, 'reg_alpha': 0.39966674462576135, 'reg_lambda': 0.06842475934196321, 'min_child_weight': 1, 'gamma': 0.3803680717461042}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:50:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  34%|      | 17/50 [08:09<19:32, 35.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:51:11,947] Trial 16 finished with value: 0.9451790721321082 and parameters: {'n_estimators': 450, 'learning_rate': 0.031172450797941648, 'max_depth': 6, 'subsample': 0.8929440269159079, 'colsample_bytree': 0.6370878317881636, 'reg_alpha': 0.29956548533275196, 'reg_lambda': 0.020435551828086894, 'min_child_weight': 1, 'gamma': 0.013179214380923565}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  36%|      | 18/50 [08:45<18:56, 35.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:51:47,485] Trial 17 finished with value: 0.9465029273538361 and parameters: {'n_estimators': 450, 'learning_rate': 0.01668577399627212, 'max_depth': 11, 'subsample': 0.9332573174980773, 'colsample_bytree': 0.8138046551270606, 'reg_alpha': 0.2868799911218273, 'reg_lambda': 0.0791728491043733, 'min_child_weight': 7, 'gamma': 0.3240127988665327}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  38%|      | 19/50 [09:15<17:37, 34.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:52:18,342] Trial 18 finished with value: 0.9456325989064721 and parameters: {'n_estimators': 400, 'learning_rate': 0.046536364192714647, 'max_depth': 10, 'subsample': 0.8846413360717517, 'colsample_bytree': 0.8161972401727597, 'reg_alpha': 2.062812456423385, 'reg_lambda': 0.2032548542712548, 'min_child_weight': 7, 'gamma': 0.04843670853793375}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  40%|      | 20/50 [09:44<16:17, 32.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:52:47,346] Trial 19 finished with value: 0.9461786790996033 and parameters: {'n_estimators': 400, 'learning_rate': 0.026855169717792893, 'max_depth': 11, 'subsample': 0.7727431143998708, 'colsample_bytree': 0.7974047183967423, 'reg_alpha': 0.16018052512154368, 'reg_lambda': 0.600209810834089, 'min_child_weight': 7, 'gamma': 0.3156024876970409}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 12. Best value: 0.94653:  42%|     | 21/50 [09:54<12:25, 25.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:52:56,966] Trial 20 finished with value: 0.9275177392330777 and parameters: {'n_estimators': 100, 'learning_rate': 0.015507122387216327, 'max_depth': 5, 'subsample': 0.9606649352518468, 'colsample_bytree': 0.9568617209397235, 'reg_alpha': 0.5332316379543479, 'reg_lambda': 0.02368840960690798, 'min_child_weight': 4, 'gamma': 0.697806427880589}. Best is trial 12 with value: 0.9465300448406078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:52:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  44%|     | 22/50 [10:31<13:31, 28.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:53:33,568] Trial 21 finished with value: 0.9468913411088528 and parameters: {'n_estimators': 450, 'learning_rate': 0.01549042826720894, 'max_depth': 11, 'subsample': 0.9215606325104604, 'colsample_bytree': 0.6579847353498133, 'reg_alpha': 0.4084502410452837, 'reg_lambda': 0.07197792872541109, 'min_child_weight': 7, 'gamma': 0.3609053426643346}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:53:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  46%|     | 23/50 [11:02<13:24, 29.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:54:05,282] Trial 22 finished with value: 0.9465245484570985 and parameters: {'n_estimators': 450, 'learning_rate': 0.025273627142217783, 'max_depth': 11, 'subsample': 0.9144256130009472, 'colsample_bytree': 0.6677484690709268, 'reg_alpha': 0.13216686565352845, 'reg_lambda': 0.12743775083276027, 'min_child_weight': 7, 'gamma': 0.1321682771570255}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  48%|     | 24/50 [11:37<13:33, 31.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:54:40,033] Trial 23 finished with value: 0.9457571866685079 and parameters: {'n_estimators': 500, 'learning_rate': 0.024148212444554576, 'max_depth': 11, 'subsample': 0.6073248792362046, 'colsample_bytree': 0.6715236621697855, 'reg_alpha': 0.09940670537846207, 'reg_lambda': 0.13151361482745785, 'min_child_weight': 6, 'gamma': 0.11211255029254164}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:54:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  50%|     | 25/50 [12:05<12:37, 30.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:55:08,026] Trial 24 finished with value: 0.945977837158748 and parameters: {'n_estimators': 400, 'learning_rate': 0.013143576262131992, 'max_depth': 9, 'subsample': 0.8800953188604057, 'colsample_bytree': 0.5858995506000683, 'reg_alpha': 0.05471234317543593, 'reg_lambda': 0.4168060382186737, 'min_child_weight': 8, 'gamma': 0.1402497237470613}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  52%|    | 26/50 [12:36<12:09, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:55:38,638] Trial 25 finished with value: 0.946102890616012 and parameters: {'n_estimators': 450, 'learning_rate': 0.037242929172618185, 'max_depth': 10, 'subsample': 0.9643874115534763, 'colsample_bytree': 0.7760998150961993, 'reg_alpha': 1.4751598491659916, 'reg_lambda': 0.045363488887751435, 'min_child_weight': 7, 'gamma': 0.3880084473437882}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:55:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  54%|    | 27/50 [13:17<12:52, 33.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:56:19,732] Trial 26 finished with value: 0.9467232186791454 and parameters: {'n_estimators': 500, 'learning_rate': 0.024811005322543055, 'max_depth': 11, 'subsample': 0.8570552384294298, 'colsample_bytree': 0.695429597674626, 'reg_alpha': 0.14799675915247523, 'reg_lambda': 0.2705351948856252, 'min_child_weight': 5, 'gamma': 0.24730369952857822}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  56%|    | 28/50 [13:44<11:38, 31.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:56:47,182] Trial 27 finished with value: 0.9449951502609247 and parameters: {'n_estimators': 500, 'learning_rate': 0.01214659618751002, 'max_depth': 7, 'subsample': 0.8470322103171236, 'colsample_bytree': 0.6232931827415775, 'reg_alpha': 0.5651144752162227, 'reg_lambda': 0.29218655686029843, 'min_child_weight': 5, 'gamma': 0.27773417826698454}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:56:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  58%|    | 29/50 [14:29<12:30, 35.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:57:32,151] Trial 28 finished with value: 0.9467657741425024 and parameters: {'n_estimators': 500, 'learning_rate': 0.017346373749506525, 'max_depth': 12, 'subsample': 0.8633238878740679, 'colsample_bytree': 0.6856380526319257, 'reg_alpha': 0.19922725680218342, 'reg_lambda': 0.8027473982046415, 'min_child_weight': 4, 'gamma': 0.22740773939996783}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:57:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  60%|    | 30/50 [14:58<11:10, 33.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:58:00,478] Trial 29 finished with value: 0.9460951780712101 and parameters: {'n_estimators': 300, 'learning_rate': 0.017285400459756895, 'max_depth': 10, 'subsample': 0.800814216017065, 'colsample_bytree': 0.6861941799052765, 'reg_alpha': 0.04428381241663468, 'reg_lambda': 1.0665656519045745, 'min_child_weight': 4, 'gamma': 0.22539868899789592}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  62%|   | 31/50 [15:16<09:13, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:58:19,400] Trial 30 finished with value: 0.9459233704644691 and parameters: {'n_estimators': 200, 'learning_rate': 0.052132124771319135, 'max_depth': 9, 'subsample': 0.8595849191581006, 'colsample_bytree': 0.553230163818983, 'reg_alpha': 0.20191529111172124, 'reg_lambda': 0.9878612638067796, 'min_child_weight': 3, 'gamma': 0.5704633936716939}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:58:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  64%|   | 32/50 [16:03<10:19, 34.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:59:06,134] Trial 31 finished with value: 0.9463787562683599 and parameters: {'n_estimators': 500, 'learning_rate': 0.02287696199234424, 'max_depth': 12, 'subsample': 0.8256850254969179, 'colsample_bytree': 0.7621131242449497, 'reg_alpha': 0.4035043194877919, 'reg_lambda': 2.2252553055327073, 'min_child_weight': 3, 'gamma': 0.3875617847739561}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 21. Best value: 0.946891:  66%|   | 33/50 [16:49<10:42, 37.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 00:59:51,739] Trial 32 finished with value: 0.9467664297971623 and parameters: {'n_estimators': 500, 'learning_rate': 0.01815481998316856, 'max_depth': 12, 'subsample': 0.864607805424336, 'colsample_bytree': 0.7069194033089563, 'reg_alpha': 0.31904791800126525, 'reg_lambda': 0.7419279611193074, 'min_child_weight': 5, 'gamma': 0.42417531916385587}. Best is trial 21 with value: 0.9468913411088528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:59:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 33. Best value: 0.946995:  68%|   | 34/50 [17:32<10:31, 39.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:00:35,272] Trial 33 finished with value: 0.9469948368940344 and parameters: {'n_estimators': 450, 'learning_rate': 0.0180414195768643, 'max_depth': 11, 'subsample': 0.8635901634654518, 'colsample_bytree': 0.6128171350362523, 'reg_alpha': 0.11961952360494553, 'reg_lambda': 0.71006821317159, 'min_child_weight': 4, 'gamma': 0.4385806919957125}. Best is trial 33 with value: 0.9469948368940344.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:00:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  70%|   | 35/50 [18:12<09:51, 39.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:01:14,618] Trial 34 finished with value: 0.9469976334984966 and parameters: {'n_estimators': 400, 'learning_rate': 0.01818965322291987, 'max_depth': 12, 'subsample': 0.9089044013517584, 'colsample_bytree': 0.5968303772495912, 'reg_alpha': 0.34341485605720035, 'reg_lambda': 1.7747160863049662, 'min_child_weight': 4, 'gamma': 0.5508393571724655}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  72%|  | 36/50 [18:50<09:06, 39.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:01:52,721] Trial 35 finished with value: 0.9459786077739446 and parameters: {'n_estimators': 400, 'learning_rate': 0.011837316489311698, 'max_depth': 10, 'subsample': 0.915821878509774, 'colsample_bytree': 0.5417065475777638, 'reg_alpha': 0.31990264400239926, 'reg_lambda': 1.6581343115721676, 'min_child_weight': 2, 'gamma': 0.6871417744456499}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:01:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  74%|  | 37/50 [19:22<08:02, 37.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:02:25,248] Trial 36 finished with value: 0.9464836246104695 and parameters: {'n_estimators': 400, 'learning_rate': 0.01897907313697455, 'max_depth': 11, 'subsample': 0.7769200745036144, 'colsample_bytree': 0.46958382925131237, 'reg_alpha': 0.09288256571436214, 'reg_lambda': 2.1398025098381557, 'min_child_weight': 4, 'gamma': 0.9986409325592858}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:02:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  76%|  | 38/50 [20:01<07:30, 37.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:03:03,783] Trial 37 finished with value: 0.9463129444479748 and parameters: {'n_estimators': 350, 'learning_rate': 0.014871315310321293, 'max_depth': 12, 'subsample': 0.8261230952889264, 'colsample_bytree': 0.6147586925380532, 'reg_alpha': 0.02889934780316049, 'reg_lambda': 3.1983906115937843, 'min_child_weight': 3, 'gamma': 0.5589580322390841}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  78%|  | 39/50 [20:29<06:22, 34.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:03:32,020] Trial 38 finished with value: 0.946284558223345 and parameters: {'n_estimators': 300, 'learning_rate': 0.019516260073652893, 'max_depth': 10, 'subsample': 0.9084585395210589, 'colsample_bytree': 0.5606385344303416, 'reg_alpha': 0.4844767864896189, 'reg_lambda': 0.652614603607503, 'min_child_weight': 4, 'gamma': 0.6473237408151806}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:03:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  80%|  | 40/50 [21:01<05:38, 33.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:04:03,691] Trial 39 finished with value: 0.9462616083831218 and parameters: {'n_estimators': 450, 'learning_rate': 0.02819201649082574, 'max_depth': 8, 'subsample': 0.9565741774241949, 'colsample_bytree': 0.6451687230479564, 'reg_alpha': 0.06132134731594899, 'reg_lambda': 1.6175815884828464, 'min_child_weight': 2, 'gamma': 0.4510071211597446}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  82%| | 41/50 [21:32<04:57, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:04:34,790] Trial 40 finished with value: 0.9452743199255972 and parameters: {'n_estimators': 400, 'learning_rate': 0.011418220484664596, 'max_depth': 9, 'subsample': 0.8726025630771211, 'colsample_bytree': 0.5147417214413536, 'reg_alpha': 0.2241998643280918, 'reg_lambda': 0.010090519786203029, 'min_child_weight': 9, 'gamma': 0.4296061542004981}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:04:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  84%| | 42/50 [22:12<04:41, 35.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:05:14,934] Trial 41 finished with value: 0.9469069972000403 and parameters: {'n_estimators': 450, 'learning_rate': 0.01740391719523379, 'max_depth': 12, 'subsample': 0.8028751893059826, 'colsample_bytree': 0.609877612035117, 'reg_alpha': 0.20804862206131494, 'reg_lambda': 1.3957853570432126, 'min_child_weight': 5, 'gamma': 0.5412231569315367}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  86%| | 43/50 [22:50<04:11, 35.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:05:52,730] Trial 42 finished with value: 0.9465032423542153 and parameters: {'n_estimators': 450, 'learning_rate': 0.018545320474002723, 'max_depth': 12, 'subsample': 0.749478589410862, 'colsample_bytree': 0.6010398963513343, 'reg_alpha': 0.1295691315047395, 'reg_lambda': 2.9087043138408144, 'min_child_weight': 5, 'gamma': 0.5238348772051633}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:05:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  88%| | 44/50 [23:22<03:28, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:06:24,566] Trial 43 finished with value: 0.9464775231696748 and parameters: {'n_estimators': 350, 'learning_rate': 0.02207169145878509, 'max_depth': 11, 'subsample': 0.8992729767675465, 'colsample_bytree': 0.5757446986200685, 'reg_alpha': 0.25755679405188625, 'reg_lambda': 1.437741823162743, 'min_child_weight': 5, 'gamma': 0.5499649440347562}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:06:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  90%| | 45/50 [23:57<02:55, 35.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:07:00,332] Trial 44 finished with value: 0.9466213238698618 and parameters: {'n_estimators': 450, 'learning_rate': 0.016806341103897417, 'max_depth': 12, 'subsample': 0.8034764222500811, 'colsample_bytree': 0.46171137200835655, 'reg_alpha': 0.34974499768101874, 'reg_lambda': 0.42838588956177753, 'min_child_weight': 6, 'gamma': 0.7360501688910541}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  92%|| 46/50 [24:12<01:55, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:07:14,516] Trial 45 finished with value: 0.93574741613395 and parameters: {'n_estimators': 350, 'learning_rate': 0.020920302522145516, 'max_depth': 4, 'subsample': 0.8398427248424729, 'colsample_bytree': 0.624433538875922, 'reg_alpha': 0.5805963963840436, 'reg_lambda': 4.6320398514334835, 'min_child_weight': 4, 'gamma': 0.597636046967165}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  94%|| 47/50 [24:28<01:15, 25.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:07:30,750] Trial 46 finished with value: 0.9412504044019062 and parameters: {'n_estimators': 150, 'learning_rate': 0.014840922222213919, 'max_depth': 12, 'subsample': 0.7138356333360499, 'colsample_bytree': 0.4214750920268831, 'reg_alpha': 0.10630059561929688, 'reg_lambda': 0.8790007433824262, 'min_child_weight': 8, 'gamma': 0.5129795669680058}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:07:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  96%|| 48/50 [25:03<00:56, 28.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:08:05,979] Trial 47 finished with value: 0.946141153069776 and parameters: {'n_estimators': 400, 'learning_rate': 0.01341498852601489, 'max_depth': 11, 'subsample': 0.815807710295106, 'colsample_bytree': 0.5348087300717995, 'reg_alpha': 0.6840994418328755, 'reg_lambda': 2.0031537039542173, 'min_child_weight': 3, 'gamma': 0.43015918816810483}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998:  98%|| 49/50 [25:48<00:33, 33.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:08:51,403] Trial 48 finished with value: 0.9461671916603025 and parameters: {'n_estimators': 450, 'learning_rate': 0.010996826438411746, 'max_depth': 12, 'subsample': 0.9399033114908927, 'colsample_bytree': 0.7045801926280374, 'reg_alpha': 1.1742835322779697, 'reg_lambda': 0.7111442302096957, 'min_child_weight': 5, 'gamma': 0.3396941720806247}. Best is trial 34 with value: 0.9469976334984966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:08:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:09:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:09:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:09:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:09:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:09:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:09:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:09:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:09:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "Best trial: 34. Best value: 0.946998: 100%|| 50/50 [26:27<00:00, 31.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 01:09:29,488] Trial 49 finished with value: 0.9465489506237192 and parameters: {'n_estimators': 450, 'learning_rate': 0.020219804743093307, 'max_depth': 11, 'subsample': 0.7740006137331563, 'colsample_bytree': 0.6021636476531871, 'reg_alpha': 0.16556222680254912, 'reg_lambda': 1.2472157112907565, 'min_child_weight': 6, 'gamma': 0.4836192688292539}. Best is trial 34 with value: 0.9469976334984966.\n",
      "\n",
      " Optimization complete!\n",
      "Best trial: 34\n",
      "Best CV AUC: 0.946998\n",
      "\n",
      "Best parameters:\n",
      "  n_estimators: 400\n",
      "  learning_rate: 0.01818965322291987\n",
      "  max_depth: 12\n",
      "  subsample: 0.9089044013517584\n",
      "  colsample_bytree: 0.5968303772495912\n",
      "  reg_alpha: 0.34341485605720035\n",
      "  reg_lambda: 1.7747160863049662\n",
      "  min_child_weight: 4\n",
      "  gamma: 0.5508393571724655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 5.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 5.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "    }\n",
    "    \n",
    "    # Build a modified pipeline with trial params\n",
    "    # We'll reuse the same preprocessing but swap the model params\n",
    "    X_temp = drop_columns(cap_and_log(X))\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    \n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    \n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "    \n",
    "    if 'description' in X_temp.columns:\n",
    "        desc_components = 40\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=desc_components, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "    \n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        sn_components = 8\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=sn_components, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "    \n",
    "    # Create model with trial params\n",
    "    model = XGBClassifier(\n",
    "        **params,\n",
    "        random_state=42,\n",
    "        # use_label_encoder=False,\n",
    "        eval_metric=\"logloss\",\n",
    "        n_jobs=-1  # use all cores\n",
    "    )\n",
    "    \n",
    "    trial_pipeline = Pipeline([\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    # 5-fold CV to save time (use 5-fold for final validation)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(trial_pipeline, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=1)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# Create and run the study\n",
    "print(\" Starting Optuna hyperparameter search...\")\n",
    "print(\"   This will take some time. Monitor progress below.\\n\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='xgboost_bot_detection',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# Run optimization (adjust n_trials based on time budget)\n",
    "# Start with 20-30 trials for a quick run, increase to 50-100 for thorough search\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n Optimization complete!\")\n",
    "print(f\"Best trial: {study.best_trial.number}\")\n",
    "print(f\"Best CV AUC: {study.best_value:.6f}\")\n",
    "print(f\"\\nBest parameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5ba23",
   "metadata": {},
   "source": [
    "### Visualize Optuna Results\n",
    "\n",
    "Let's plot the optimization history and parameter importances to understand which hyperparameters matter most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ba898f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/visualization/_plotly_imports.py:7\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_optimization_history, plot_param_importances\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Plot optimization history\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m fig1 = \u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m fig1.show()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Plot parameter importances\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/visualization/_optimization_history.py:200\u001b[39m, in \u001b[36mplot_optimization_history\u001b[39m\u001b[34m(study, target, target_name, error_bar)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_optimization_history\u001b[39m(\n\u001b[32m    173\u001b[39m     study: Study | Sequence[Study],\n\u001b[32m    174\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m     error_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    178\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mgo.Figure\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    179\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[32m    180\u001b[39m \n\u001b[32m    181\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m \u001b[33;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[43m_imports\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     info_list = _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/optuna/_imports.py:97\u001b[39m, in \u001b[36m_DeferredImportExceptionContextManager.check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     96\u001b[39m     exc_value, message = \u001b[38;5;28mself\u001b[39m._deferred\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc_value\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "# Plot optimization history\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig1.show()\n",
    "\n",
    "# Plot parameter importances\n",
    "fig2 = plot_param_importances(study)\n",
    "fig2.show()\n",
    "\n",
    "# Show all trials sorted by value\n",
    "trials_df = study.trials_dataframe().sort_values('value', ascending=False)\n",
    "print(\"\\nTop 5 trials:\")\n",
    "print(trials_df[['number', 'value', 'params_n_estimators', 'params_learning_rate', \n",
    "                 'params_max_depth', 'params_subsample']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf2a79",
   "metadata": {},
   "source": [
    "### Analysis: Why Optuna didn't beat the manual baseline\n",
    "\n",
    "**Your manual best CV AUC: 0.9467816** (5-fold)  \n",
    "**Optuna best CV AUC: 0.946173** (3-fold during search)\n",
    "\n",
    "This is a common outcome. Here's why and what to do next:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa58378",
   "metadata": {},
   "source": [
    "### Retrain with Best Parameters\n",
    "\n",
    "Now we'll retrain the full pipeline using the best hyperparameters found by Optuna and evaluate with 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3684d437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running 5-fold CV with best parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5-Fold CV Results with Best Params:\n",
      "   Mean AUC: 0.946998\n",
      "   Std AUC:  0.004070\n",
      "   Individual folds: ['0.944212', '0.951744', '0.952037', '0.942353', '0.944643']\n",
      "\n",
      " Training final model on full training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximus/Downloads/SCHOOL/bt4012/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [01:10:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Optimized model saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_optuna.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_760/3934499683.py:63: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_760/3934499683.py:67: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
      "/var/folders/68/3bnqqrc16vl0r8p4ym_m3yyr0000gn/T/ipykernel_760/3934499683.py:97: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  X['description_has_url_pattern'] = desc.str.contains(r'\\.(com|org|net|io)\\b').astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_optuna.csv\n"
     ]
    }
   ],
   "source": [
    "# Build final pipeline with best params\n",
    "def build_pipeline_with_params(X, params):\n",
    "    \"\"\"Build pipeline with custom XGBoost params\"\"\"\n",
    "    X_temp = drop_columns(cap_and_log(X))\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    \n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    \n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "    \n",
    "    if 'description' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=40, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "    \n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=8, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        **params,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Build pipeline with best params\n",
    "best_pipeline = build_pipeline_with_params(X, study.best_params)\n",
    "\n",
    "# 5-fold CV with best params\n",
    "print(\" Running 5-fold CV with best parameters...\")\n",
    "cv5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_auc_scores = cross_val_score(best_pipeline, X, y, cv=cv5, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"\\n 5-Fold CV Results with Best Params:\")\n",
    "print(f\"   Mean AUC: {best_auc_scores.mean():.6f}\")\n",
    "print(f\"   Std AUC:  {best_auc_scores.std():.6f}\")\n",
    "print(f\"   Individual folds: {[f'{score:.6f}' for score in best_auc_scores]}\")\n",
    "\n",
    "# Train on full data\n",
    "print(\"\\n Training final model on full training set...\")\n",
    "best_pipeline.fit(X, y)\n",
    "\n",
    "# Save the optimized model\n",
    "model_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_optuna.pkl\"\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "print(f\" Optimized model saved to: {model_path}\")\n",
    "\n",
    "# Generate predictions\n",
    "test_fe_optuna, _ = apply_feature_engineering(test, loc_groups=loc_groups)\n",
    "test_probs_optuna = best_pipeline.predict_proba(test_fe_optuna)[:, 1]\n",
    "\n",
    "submission_optuna = pd.DataFrame({\n",
    "    \"index\": test.index,\n",
    "    \"target\": test_probs_optuna\n",
    "})\n",
    "\n",
    "submission_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_optuna.csv\"\n",
    "submission_optuna.to_csv(submission_path, index=False)\n",
    "print(f\" Submission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "387a3de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best parameters saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/best_xgb_params_optuna.json\n"
     ]
    }
   ],
   "source": [
    "# Save best parameters to JSON for documentation\n",
    "import json\n",
    "\n",
    "params_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/best_xgb_params_optuna.json\"\n",
    "with open(params_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'best_params': study.best_params,\n",
    "        'best_cv_auc': float(study.best_value),\n",
    "        'best_trial': study.best_trial.number,\n",
    "        'n_trials': len(study.trials)\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\" Best parameters saved to: {params_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baafcc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9471000052335284\n",
      " Model saved\n",
      " Submission created\n"
     ]
    }
   ],
   "source": [
    "# increasing tf-idf max features from 2000 to 4000:\n",
    "# CV AUC: 0.9463680027686614 (lower)\n",
    "# 2000 to 3000: even lower\n",
    "\n",
    "# use: OneHotEncoder(max_categories=50, handle_unknown='infrequent_if_exist')\n",
    "# CV AUC: 0.946666124621012 (highest!!)\n",
    "# public score: 0.94235 (highest)\n",
    "# 100 categories: 0.9465335787191218\n",
    "# 75 categories: 0.9465335787191218\n",
    "# 40 categories: 0.9467717521386734 (highestttt)\n",
    "# 30 categories: 0.9465074679762804 -> public score: 0.94261 (higher)\n",
    "\n",
    "# add description_has_url_pattern\n",
    "# CV AUC: 0.9467816258644666 (increase)\n",
    "\n",
    "# optuna fine tuned params: {\n",
    "#     \"n_estimators\": 400,\n",
    "#     \"learning_rate\": 0.01818965322291987,\n",
    "#     \"max_depth\": 12,\n",
    "#     \"subsample\": 0.9089044013517584,\n",
    "#     \"colsample_bytree\": 0.5968303772495912,\n",
    "#     \"reg_alpha\": 0.34341485605720035,\n",
    "#     \"reg_lambda\": 1.7747160863049662,\n",
    "#     \"min_child_weight\": 4,\n",
    "#     \"gamma\": 0.5508393571724655\n",
    "#   }, CV AUC: 0.9469976334984966 (increase)\n",
    "\n",
    "# \n",
    "# CV AUC: 0.9471603829102276\n",
    "\n",
    "# incldue statuses_count, drop screen_name\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    # X can be a 1D array or 2D array with shape (n_samples, 1)\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    # reference_date: use a fixed date for reproducibility if provided, otherwise use current date\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        # link_pattern = r'(http[s]?://|www\\.)'\n",
    "        link_pattern = r'(?:http[s]?://|www\\.)'  # use non-capturing group\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(?:bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        # emoji_re = re.compile(\n",
    "        #     r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        #     r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        #     r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        #     r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        #     r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "        #     r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "        #     r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "        #     r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "        #     r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "        #     r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "        #     r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        #     r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "\n",
    "        # X['description_has_follow'] = desc.str.contains(r'\\b(follow|subscribe)\\b').fillna(False).astype(int)\n",
    "        X['description_has_url_pattern'] = desc.str.contains(r'\\.(?:com|org|net|io)\\b', regex=True).fillna(False).astype(int)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        # X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "\n",
    "        # X['description_has_follow'] = 0\n",
    "\n",
    "    # === created_at -> account_age_days ===\n",
    "    if 'account_age_days' not in X.columns or X['account_age_days'].isna().any():\n",
    "        if 'created_at' in X.columns:\n",
    "            # try parsing created_at to days difference from reference_date\n",
    "            try:\n",
    "                created = pd.to_datetime(X['created_at'], errors='coerce')\n",
    "                X['account_age_days'] = (reference_date - created).dt.days.fillna(0).astype(int)\n",
    "            except Exception:\n",
    "                # fallback if parsing fails\n",
    "                X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "        else:\n",
    "            # if neither exists, fill with median later through imputer\n",
    "            X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "\n",
    "    # === screen_name features ===\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d').astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_').astype(int)\n",
    "        # ratio of digits to length\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "\n",
    "    # === boolean-like flags to numeric ===\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    # === Language grouping ===\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        # high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af', 'ja', 'cy', 'so']     # > 0.4 bot rate\n",
    "        low_bot = [ 'ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']     # > 0.5 bot rate\n",
    "        mid_bot = ['ja', 'cy', 'so']                     # 0.40.5 bot rate\n",
    "        mid_lower_bot = ['th', 'pt', 'tr', 'et', 'id', 'fi', 'sl'] # 0.30.4 bot rate\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he'] # < 20 samples\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(mid_lower_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            # ['high_bot_lang', 'mid_bot_lang', 'english'],\n",
    "            # ['high_bot_lang','low_bot_lang','english'],\n",
    "            # ['high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            ['low_freq_lang', 'high_bot_lang','mid_bot_lang','mid_lower_bot_lang','low_bot_lang','english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    # return X\n",
    "\n",
    "    # === Location binning and low-frequency flagging ===\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "# ...existing code...\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "\n",
    "    Usage:\n",
    "      # On training data (requires 'target'):\n",
    "      df_train, loc_groups = map_loc_bin(df_train, min_samples=30)\n",
    "\n",
    "      # On test data (reuse mapping from train):\n",
    "      df_test, _ = map_loc_bin(df_test, loc_groups=loc_groups)\n",
    "\n",
    "    Returns:\n",
    "      df (modified copy), loc_groups (dict with 'mapping', 'low_freq', 'groups')\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "        # bins = [0.0, 0.1, 0.3, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    # If no precomputed groups provided, build from df (training mode)\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        # Keep locations with enough samples for reliable proportion\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        # accept either full loc_groups dict or just mapping\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    # Map each location to a combined bin\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    # df['loc_low_freq'] = df['location'].isin(low_freq).astype(int)\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "\n",
    "    return df, loc_groups\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day', 'statuses_count',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    # keep `description` and `screen_name` for text features; drop raw location/lang/ids that we've summarized\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \"lang\", \"location\", \"created_at\"]\n",
    "    \n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    # note: X is expected to already contain feature-engineered cols (main applies apply_feature_engineering)\n",
    "    X_temp = drop_columns(cap_and_log(X))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        # (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    # Add text pipelines if description / screen_name exist\n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # description -> TF-IDF -> SVD\n",
    "    if 'description' in X_temp.columns:\n",
    "        desc_components = 40\n",
    "        # ensure we pass a 1D array of strings (no NaN) into TfidfVectorizer\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=desc_components, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # screen_name -> TF-IDF -> SVD (shorter)\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        sn_components = 8\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=sn_components, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # model = XGBClassifier(\n",
    "    #     n_estimators=300,\n",
    "    #     learning_rate=0.05,\n",
    "    #     max_depth=6,\n",
    "    #     subsample=0.8,\n",
    "    #     colsample_bytree=0.8,\n",
    "    #     random_state=42,\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric=\"logloss\"\n",
    "    # )\n",
    "    # {'n_estimators': 350, 'learning_rate': 0.03008393676525409, 'max_depth': 9, 'subsample': 0.9809503155616375, 'colsample_bytree': 0.56044353273329, 'reg_alpha': 1.2338019395219242, 'reg_lambda': 1.6264975818536396, 'min_child_weight': 3, 'gamma': 0.36491328244932486}\n",
    "    # model = XGBClassifier(\n",
    "    #     n_estimators=350,\n",
    "    #     learning_rate=0.03,\n",
    "    #     max_depth=9,\n",
    "    #     subsample=0.98,\n",
    "    #     colsample_bytree=0.56,\n",
    "    #     reg_alpha=1.23,\n",
    "    #     reg_lambda=1.63,\n",
    "    #     min_child_weight=3,\n",
    "    #     gamma=0.36,\n",
    "    #     random_state=42,\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric=\"logloss\"\n",
    "    # )\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.01818965322291987,\n",
    "        max_depth=12,\n",
    "        subsample=0.9089044013517584,\n",
    "        colsample_bytree=0.5968303772495912,\n",
    "        reg_alpha=0.34341485605720035,\n",
    "        reg_lambda=1.7747160863049662,\n",
    "        min_child_weight=4,\n",
    "        gamma=0.5508393571724655,\n",
    "        random_state=42,\n",
    "        # use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        # (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    # X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    X_fe, loc_groups = apply_feature_engineering(train)\n",
    "    X = X_fe.drop(columns=['target'])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "    # pipeline = build_pipeline(X_fe)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Feature importance\n",
    "    # if hasattr(pipeline.named_steps['model'], 'feature_importances_'):\n",
    "    #     importances = pipeline.named_steps['model'].feature_importances_\n",
    "    #     print(\"Feature importances:\", importances)\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_fe, _ = apply_feature_engineering(test, loc_groups=loc_groups)\n",
    "    test_probs = pipeline.predict_proba(test_fe)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf746d4",
   "metadata": {},
   "source": [
    "keep statuses_count drop average tweets per day -> worse CV AUC: 0.9466918769391632\n",
    "drop screen_name -> (may be better??) -> worsen\n",
    "drop description -> (worse) oh cos we doing one hot\n",
    "\n",
    "try including:\n",
    "- 0.3-0.4 bot languages = ['th', pt', 'tr', 'et', 'id', 'fi', 'sl']\n",
    "    CV AUC: 0.9471000052335284 (wow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc433277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC: 0.9471154721279694\n",
      " Model saved\n",
      " Submission created\n"
     ]
    }
   ],
   "source": [
    "# increasing tf-idf max features from 2000 to 4000:\n",
    "# CV AUC: 0.9463680027686614 (lower)\n",
    "# 2000 to 3000: even lower\n",
    "\n",
    "# use: OneHotEncoder(max_categories=50, handle_unknown='infrequent_if_exist')\n",
    "# CV AUC: 0.946666124621012 (highest!!)\n",
    "# public score: 0.94235 (highest)\n",
    "# 100 categories: 0.9465335787191218\n",
    "# 75 categories: 0.9465335787191218\n",
    "# 40 categories: 0.9467717521386734 (highestttt)\n",
    "# 30 categories: 0.9465074679762804 -> public score: 0.94261 (higher)\n",
    "\n",
    "# add description_has_url_pattern\n",
    "# CV AUC: 0.9467816258644666 (increase)\n",
    "\n",
    "# optuna fine tuned params: {\n",
    "#     \"n_estimators\": 400,\n",
    "#     \"learning_rate\": 0.01818965322291987,\n",
    "#     \"max_depth\": 12,\n",
    "#     \"subsample\": 0.9089044013517584,\n",
    "#     \"colsample_bytree\": 0.5968303772495912,\n",
    "#     \"reg_alpha\": 0.34341485605720035,\n",
    "#     \"reg_lambda\": 1.7747160863049662,\n",
    "#     \"min_child_weight\": 4,\n",
    "#     \"gamma\": 0.5508393571724655\n",
    "#   }, CV AUC: 0.9469976334984966 (increase)\n",
    "\n",
    "# \n",
    "# CV AUC: 0.9471603829102276\n",
    "\n",
    "# incldue statuses_count, drop screen_name\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    # X can be a 1D array or 2D array with shape (n_samples, 1)\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    # reference_date: use a fixed date for reproducibility if provided, otherwise use current date\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    # X['friends_per_day'] = safe_ratio(X['friends_count'], X['account_age_days'])\n",
    "    # X['friends_per_logday_log'] = np.log1p(safe_ratio(X['friends_count'], np.log1p(X['account_age_days'])))\n",
    "    # X['friends_per_day_log'] = np.log1p(safe_ratio(X['friends_count'], X['account_age_days']))\n",
    "    # X['friends_per_logday'] = safe_ratio(X['friends_count'], np.log1p(X['account_age_days']))\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        # X['description_is_empty'] = (desc == '').astype(int)\n",
    "        # untouched_desc = X['description'].fillna('').astype(str)\n",
    "        # X['description_uppercase_ratio'] = np.where(untouched_desc.str.len() > 0,\n",
    "        #                                             untouched_desc.str.count(r'[A-Z]') / untouched_desc.str.len(),\n",
    "        #                                             0)\n",
    "        # has link (http(s)://, www., common tlds)\n",
    "        # link_pattern = r'(http[s]?://|www\\.)'\n",
    "        link_pattern = r'(?:http[s]?://|www\\.)'  # use non-capturing group\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        # has bot-like token (bot, automated, rss, feed, auto)\n",
    "        bot_pattern = r'\\b(?:bot|automated|auto|rss|feed)\\b'\n",
    "        # bot_pattern = r\"\\bbot\\b\"\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        # length and word count\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        # X['description_word_count'] = desc.str.split().apply(lambda s: len(s) if isinstance(s, list) else 0).astype(int)\n",
    "\n",
    "        # emoji_re = re.compile(\n",
    "        #     r\"[\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        #     r\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        #     r\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        #     r\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        #     r\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "        #     r\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "        #     r\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "        #     r\"\\U0001FA70-\\U0001FAFF\"  # symbols and pictographs extended-A\n",
    "        #     r\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "        #     r\"\\U00002B00-\\U00002BFF\"  # arrows\n",
    "        #     r\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        #     r\"]+\", flags=re.UNICODE)\n",
    "        X['description_has_at'] = desc.str.contains(r'@').fillna(False).astype(int)\n",
    "        # X['description_has_emoji'] = desc.apply(lambda x: 1 if emoji_re.search(x) else 0)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]').fillna(False).astype(int)\n",
    "\n",
    "        # X['description_has_follow'] = desc.str.contains(r'\\b(follow|subscribe)\\b').fillna(False).astype(int)\n",
    "        X['description_has_url_pattern'] = desc.str.contains(r'\\.(?:com|org|net|io)\\b', regex=True).fillna(False).astype(int)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # defaults if column missing\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        # X['description_word_count'] = 0\n",
    "\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "\n",
    "        # X['description_has_follow'] = 0\n",
    "\n",
    "    # === created_at -> account_age_days ===\n",
    "    if 'account_age_days' not in X.columns or X['account_age_days'].isna().any():\n",
    "        if 'created_at' in X.columns:\n",
    "            # try parsing created_at to days difference from reference_date\n",
    "            try:\n",
    "                created = pd.to_datetime(X['created_at'], errors='coerce')\n",
    "                X['account_age_days'] = (reference_date - created).dt.days.fillna(0).astype(int)\n",
    "            except Exception:\n",
    "                # fallback if parsing fails\n",
    "                X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "        else:\n",
    "            # if neither exists, fill with median later through imputer\n",
    "            X['account_age_days'] = X.get('account_age_days', pd.Series(0, index=X.index))\n",
    "\n",
    "    # === screen_name features ===\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d').astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_').astype(int)\n",
    "        # ratio of digits to length\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "\n",
    "    # === boolean-like flags to numeric ===\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    # === Language grouping ===\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        # high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af', 'ja', 'cy', 'so']     # > 0.4 bot rate\n",
    "        low_bot = [ 'ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']     # > 0.5 bot rate\n",
    "        mid_bot = ['ja', 'cy', 'so']                     # 0.40.5 bot rate\n",
    "        mid_lower_bot = ['th', 'pt', 'tr', 'et', 'id', 'fi', 'sl'] # 0.30.4 bot rate\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he'] # < 20 samples\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(mid_lower_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            # ['high_bot_lang', 'mid_bot_lang', 'english'],\n",
    "            # ['high_bot_lang','low_bot_lang','english'],\n",
    "            # ['high_bot_lang','mid_bot_lang','low_bot_lang','english'],\n",
    "            ['low_freq_lang', 'high_bot_lang','mid_bot_lang','mid_lower_bot_lang','low_bot_lang','english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    # return X\n",
    "\n",
    "    # === Location binning and low-frequency flagging ===\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "# ...existing code...\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "\n",
    "    Usage:\n",
    "      # On training data (requires 'target'):\n",
    "      df_train, loc_groups = map_loc_bin(df_train, min_samples=30)\n",
    "\n",
    "      # On test data (reuse mapping from train):\n",
    "      df_test, _ = map_loc_bin(df_test, loc_groups=loc_groups)\n",
    "\n",
    "    Returns:\n",
    "      df (modified copy), loc_groups (dict with 'mapping', 'low_freq', 'groups')\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "        # bins = [0.0, 0.1, 0.3, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    # If no precomputed groups provided, build from df (training mode)\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        # Keep locations with enough samples for reliable proportion\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        # accept either full loc_groups dict or just mapping\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    # Map each location to a combined bin\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    # df['loc_low_freq'] = df['location'].isin(low_freq).astype(int)\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "\n",
    "    return df, loc_groups\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    # numeric_cols = X.select_dtypes(include=[np.number]).columns.drop('account_age_days')\n",
    "    # capped_cols = ['favourites_count', 'followers_count', 'friends_count', 'average_tweets_per_day']\n",
    "    # for col in capped_cols:\n",
    "    #     lower, upper = X[col].quantile([0.01, 0.99])\n",
    "    #     X[col] = X[col].clip(lower, upper)\n",
    "\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day', 'statuses_count',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    # keep `description` and `screen_name` for text features; drop raw location/lang/ids that we've summarized\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \"lang\", \"location\", \"created_at\"]\n",
    "    \n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Builds full preprocessing + model pipeline dynamically based on columns in X\"\"\"\n",
    "    # Step 1: preview feature-engineered data to detect final schema\n",
    "    # note: X is expected to already contain feature-engineered cols (main applies apply_feature_engineering)\n",
    "    X_temp = drop_columns(cap_and_log(X))\n",
    "\n",
    "\n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        # (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        # (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    # Add text pipelines if description / screen_name exist\n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # description -> TF-IDF -> SVD\n",
    "    if 'description' in X_temp.columns:\n",
    "        desc_components = 40\n",
    "        # ensure we pass a 1D array of strings (no NaN) into TfidfVectorizer\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=desc_components, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # screen_name -> TF-IDF -> SVD (shorter)\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        sn_components = 8\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=sn_components, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # model = XGBClassifier(\n",
    "    #     n_estimators=300,\n",
    "    #     learning_rate=0.05,\n",
    "    #     max_depth=6,\n",
    "    #     subsample=0.8,\n",
    "    #     colsample_bytree=0.8,\n",
    "    #     random_state=42,\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric=\"logloss\"\n",
    "    # )\n",
    "    # {'n_estimators': 350, 'learning_rate': 0.03008393676525409, 'max_depth': 9, 'subsample': 0.9809503155616375, 'colsample_bytree': 0.56044353273329, 'reg_alpha': 1.2338019395219242, 'reg_lambda': 1.6264975818536396, 'min_child_weight': 3, 'gamma': 0.36491328244932486}\n",
    "    # model = XGBClassifier(\n",
    "    #     n_estimators=350,\n",
    "    #     learning_rate=0.03,\n",
    "    #     max_depth=9,\n",
    "    #     subsample=0.98,\n",
    "    #     colsample_bytree=0.56,\n",
    "    #     reg_alpha=1.23,\n",
    "    #     reg_lambda=1.63,\n",
    "    #     min_child_weight=3,\n",
    "    #     gamma=0.36,\n",
    "    #     random_state=42,\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric=\"logloss\"\n",
    "    # )\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.01818965322291987,\n",
    "        max_depth=12,\n",
    "        subsample=0.9089044013517584,\n",
    "        colsample_bytree=0.5968303772495912,\n",
    "        reg_alpha=0.34341485605720035,\n",
    "        reg_lambda=1.7747160863049662,\n",
    "        min_child_weight=4,\n",
    "        gamma=0.5508393571724655,\n",
    "        random_state=42,\n",
    "        # use_label_encoder=False,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        # (\"feature_engineering\", FunctionTransformer(apply_feature_engineering, validate=False)),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "\n",
    "    y = train[\"target\"]\n",
    "    # X = train.drop(columns=[\"target\"])\n",
    "\n",
    "    X_fe, loc_groups = apply_feature_engineering(train)\n",
    "    X = X_fe.drop(columns=['target'])\n",
    "\n",
    "    pipeline = build_pipeline(X)\n",
    "    # pipeline = build_pipeline(X_fe)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    print(\"CV AUC:\", auc_scores.mean())\n",
    "\n",
    "    # Train full model\n",
    "    pipeline.fit(X, y)\n",
    "    joblib.dump(pipeline, \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline.pkl\")\n",
    "    print(\" Model saved\")\n",
    "\n",
    "    # Feature importance\n",
    "    # if hasattr(pipeline.named_steps['model'], 'feature_importances_'):\n",
    "    #     importances = pipeline.named_steps['model'].feature_importances_\n",
    "    #     print(\"Feature importances:\", importances)\n",
    "\n",
    "    # Predict on test\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "    test_fe, _ = apply_feature_engineering(test, loc_groups=loc_groups)\n",
    "    test_probs = pipeline.predict_proba(test_fe)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission.csv\", index=False)\n",
    "    print(\" Submission created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab7f97",
   "metadata": {},
   "source": [
    "try later:\n",
    "- previous best: CV AUC: 0.9471000052335284 (wow)\n",
    "- remove standard scaler: CV AUC: 0.9471154721279694 (increase)\n",
    "\n",
    "\n",
    "tried:\n",
    "- description is missing -> lower\n",
    "    tried to drop description_len -> still lower\n",
    "- uppercase ratio -> lower 0.9468784531241127\n",
    "\n",
    "do SHAP\n",
    "do optuna again.\n",
    "explore on other models...\n",
    "\n",
    "need to try with the other no data leakage one.\n",
    "\n",
    "2 more submissions: \n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cafcad87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Building pipeline...\n",
      "\n",
      " Running 5-fold stratified cross-validation...\n",
      "   (Feature engineering computed separately for each fold)\n",
      "\n",
      " CV Results:\n",
      "   Mean AUC: 0.946966\n",
      "   Std AUC:  0.004102\n",
      "   Individual folds: ['0.944188', '0.952143', '0.951645', '0.942272', '0.944579']\n",
      "\n",
      " Training final model on full training set...\n",
      "\n",
      " CV Results:\n",
      "   Mean AUC: 0.946966\n",
      "   Std AUC:  0.004102\n",
      "   Individual folds: ['0.944188', '0.952143', '0.951645', '0.942272', '0.944579']\n",
      "\n",
      " Training final model on full training set...\n",
      " Model saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\n",
      "\n",
      " Generating test predictions...\n",
      " Model saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\n",
      "\n",
      " Generating test predictions...\n",
      " Submission saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\n",
      " Submission saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "# 11_xgboost.py - Fixed version with NO DATA LEAKAGE\n",
    "# \n",
    "# KEY FIX: Feature engineering (especially location binning) is now done INSIDE\n",
    "# the pipeline using FeatureEngineerTransformer. This ensures that loc_groups\n",
    "# are computed separately for each CV fold, preventing target leakage.\n",
    "#\n",
    "# Previous issue in 10_xgboost_onehot.py:\n",
    "# - apply_feature_engineering(train) was called BEFORE cross_val_score\n",
    "# - map_loc_bin computed location->target mappings using the FULL training set\n",
    "# - These mappings leaked into CV, making CV scores optimistically biased\n",
    "#\n",
    "# Solution:\n",
    "# - FeatureEngineerTransformer.fit(X, y) computes loc_groups from training fold only\n",
    "# - FeatureEngineerTransformer.transform(X) applies the learned mappings\n",
    "# - Pipeline includes feature engineering as first step\n",
    "# - CV properly fits feature engineering on train folds, transforms on validation folds\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    \n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    \n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        link_pattern = r'(?:http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        bot_pattern = r'\\b(?:bot|automated|auto|rss|feed)\\b'\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        X['description_has_at'] = desc.str.contains(r'@', regex=True).fillna(False).astype(int)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]', regex=True).fillna(False).astype(int)\n",
    "        X['description_has_url_pattern'] = desc.str.contains(r'\\.(?:com|org|net|io)\\b', regex=True).fillna(False).astype(int)\n",
    "    else:\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "        X['description_has_url_pattern'] = 0\n",
    "\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d', regex=True).astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_', regex=True).astype(int)\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        low_bot = ['ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']\n",
    "        mid_bot = ['ja', 'cy', 'so']\n",
    "        mid_lower_bot = ['th', 'pt', 'tr', 'et', 'id', 'fi', 'sl']\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he']\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(mid_lower_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            ['low_freq_lang', 'high_bot_lang', 'mid_bot_lang', 'mid_lower_bot_lang', 'low_bot_lang', 'english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "    return df, loc_groups\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \n",
    "                 \"lang\", \"location\", \"created_at\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Custom Transformer to Avoid Data Leakage ========= #\n",
    "\n",
    "class FeatureEngineerTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Sklearn-compatible transformer that applies feature engineering.\n",
    "    \n",
    "    KEY: On fit(X, y) it computes location groups using the training fold's target.\n",
    "    This prevents data leakage because each CV fold will compute its own loc_groups\n",
    "    from its training split only.\n",
    "    \n",
    "    On transform(X) it applies feature engineering using the stored loc_groups.\n",
    "    \"\"\"\n",
    "    def __init__(self, reference_date=None, min_samples=30):\n",
    "        self.reference_date = reference_date\n",
    "        self.min_samples = min_samples\n",
    "        self.loc_groups_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit on training data. Computes loc_groups from X and y.\n",
    "        \"\"\"\n",
    "        if y is None:\n",
    "            # No target provided, create empty loc_groups (will map all to 'other')\n",
    "            # This happens during pipeline building when we discover schema\n",
    "            self.loc_groups_ = {\n",
    "                'mapping': {},\n",
    "                'low_freq': [],\n",
    "                'groups': {},\n",
    "                'min_samples': self.min_samples,\n",
    "                'bins': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "            }\n",
    "            return self\n",
    "        \n",
    "        # Attach target temporarily to compute location mappings\n",
    "        df = X.copy()\n",
    "        df['target'] = np.asarray(y).ravel()\n",
    "        \n",
    "        # Compute loc_groups from this training fold only\n",
    "        _, loc_groups = apply_feature_engineering(df, loc_groups=None, reference_date=self.reference_date)\n",
    "        self.loc_groups_ = loc_groups\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform data using the learned loc_groups (from fit).\n",
    "        \"\"\"\n",
    "        X_fe, _ = apply_feature_engineering(X.copy(), loc_groups=self.loc_groups_, \n",
    "                                           reference_date=self.reference_date)\n",
    "        # Drop target if it exists (from fit phase)\n",
    "        if 'target' in X_fe.columns:\n",
    "            X_fe = X_fe.drop(columns=['target'])\n",
    "        return X_fe\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X_sample):\n",
    "    \"\"\"\n",
    "    Builds full preprocessing + model pipeline.\n",
    "    \n",
    "    Args:\n",
    "        X_sample: A small sample of raw data (before feature engineering) to\n",
    "                 determine column types after feature engineering\n",
    "    \"\"\"\n",
    "    # Create feature engineering transformer\n",
    "    feat_eng = FeatureEngineerTransformer()\n",
    "    \n",
    "    # Apply to sample to discover column schema (use dummy y if target exists in sample)\n",
    "    sample = X_sample.head(100).copy()\n",
    "    y_dummy = sample['target'] if 'target' in sample.columns else None\n",
    "    if 'target' in sample.columns:\n",
    "        sample = sample.drop(columns=['target'])\n",
    "    X_sample_fe = feat_eng.fit_transform(sample, y_dummy)\n",
    "    X_temp = drop_columns(cap_and_log(X_sample_fe))\n",
    "    \n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        # (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    \n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # TF-IDF + SVD for description\n",
    "    if 'description' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=40, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # TF-IDF + SVD for screen_name\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=8, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # Optuna-tuned parameters\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.01818965322291987,\n",
    "        max_depth=12,\n",
    "        subsample=0.9089044013517584,\n",
    "        colsample_bytree=0.5968303772495912,\n",
    "        reg_alpha=0.34341485605720035,\n",
    "        reg_lambda=1.7747160863049662,\n",
    "        min_child_weight=4,\n",
    "        gamma=0.5508393571724655,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    # Complete pipeline with feature engineering INSIDE\n",
    "    pipeline = Pipeline([\n",
    "        (\"feature_engineering\", FeatureEngineerTransformer()),  #  FIX: Inside pipeline!\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load data\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "\n",
    "    # Prepare training data (NO feature engineering here!)\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    # Build pipeline (pass raw X for schema discovery)\n",
    "    print(\" Building pipeline...\")\n",
    "    pipeline = build_pipeline(X)\n",
    "\n",
    "    # Cross-validation (pipeline handles feature engineering internally)\n",
    "    print(\"\\n Running 5-fold stratified cross-validation...\")\n",
    "    print(\"   (Feature engineering computed separately for each fold)\")\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    \n",
    "    print(f\"\\n CV Results:\")\n",
    "    print(f\"   Mean AUC: {auc_scores.mean():.6f}\")\n",
    "    print(f\"   Std AUC:  {auc_scores.std():.6f}\")\n",
    "    print(f\"   Individual folds: {[f'{s:.6f}' for s in auc_scores]}\")\n",
    "\n",
    "    # Train full model\n",
    "    print(\"\\n Training final model on full training set...\")\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\"\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    print(f\" Model saved to: {model_path}\")\n",
    "\n",
    "    # Predict on test (pipeline handles feature engineering)\n",
    "    print(\"\\n Generating test predictions...\")\n",
    "    test_probs = pipeline.predict_proba(test)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\"\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\" Submission saved to: {submission_path}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5413500",
   "metadata": {},
   "source": [
    "Using optuna params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7158ed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Building pipeline...\n",
      "\n",
      " Running 5-fold stratified cross-validation...\n",
      "   (Feature engineering computed separately for each fold)\n",
      "\n",
      " CV Results:\n",
      "   Mean AUC: 0.947080\n",
      "   Std AUC:  0.003694\n",
      "   Individual folds: ['0.944192', '0.951417', '0.951409', '0.942511', '0.945871']\n",
      "\n",
      " Training final model on full training set...\n",
      " Model saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\n",
      "\n",
      " Generating test predictions...\n",
      " Submission saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "# 11_xgboost.py - Fixed version with NO DATA LEAKAGE\n",
    "# \n",
    "# KEY FIX: Feature engineering (especially location binning) is now done INSIDE\n",
    "# the pipeline using FeatureEngineerTransformer. This ensures that loc_groups\n",
    "# are computed separately for each CV fold, preventing target leakage.\n",
    "#\n",
    "# Previous issue in 10_xgboost_onehot.py:\n",
    "# - apply_feature_engineering(train) was called BEFORE cross_val_score\n",
    "# - map_loc_bin computed location->target mappings using the FULL training set\n",
    "# - These mappings leaked into CV, making CV scores optimistically biased\n",
    "#\n",
    "# Solution:\n",
    "# - FeatureEngineerTransformer.fit(X, y) computes loc_groups from training fold only\n",
    "# - FeatureEngineerTransformer.transform(X) applies the learned mappings\n",
    "# - Pipeline includes feature engineering as first step\n",
    "# - CV properly fits feature engineering on train folds, transforms on validation folds\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    \n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    \n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        link_pattern = r'(?:http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        bot_pattern = r'\\b(?:bot|automated|auto|rss|feed)\\b'\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        X['description_has_at'] = desc.str.contains(r'@', regex=True).fillna(False).astype(int)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]', regex=True).fillna(False).astype(int)\n",
    "        X['description_has_url_pattern'] = desc.str.contains(r'\\.(?:com|org|net|io)\\b', regex=True).fillna(False).astype(int)\n",
    "    else:\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "        X['description_has_url_pattern'] = 0\n",
    "\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d', regex=True).astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_', regex=True).astype(int)\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        low_bot = ['ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']\n",
    "        mid_bot = ['ja', 'cy', 'so']\n",
    "        mid_lower_bot = ['th', 'pt', 'tr', 'et', 'id', 'fi', 'sl']\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he']\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(mid_lower_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            ['low_freq_lang', 'high_bot_lang', 'mid_bot_lang', 'mid_lower_bot_lang', 'low_bot_lang', 'english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "    return df, loc_groups\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \n",
    "                 \"lang\", \"location\", \"created_at\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Custom Transformer to Avoid Data Leakage ========= #\n",
    "\n",
    "class FeatureEngineerTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Sklearn-compatible transformer that applies feature engineering.\n",
    "    \n",
    "    KEY: On fit(X, y) it computes location groups using the training fold's target.\n",
    "    This prevents data leakage because each CV fold will compute its own loc_groups\n",
    "    from its training split only.\n",
    "    \n",
    "    On transform(X) it applies feature engineering using the stored loc_groups.\n",
    "    \"\"\"\n",
    "    def __init__(self, reference_date=None, min_samples=30):\n",
    "        self.reference_date = reference_date\n",
    "        self.min_samples = min_samples\n",
    "        self.loc_groups_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit on training data. Computes loc_groups from X and y.\n",
    "        \"\"\"\n",
    "        if y is None:\n",
    "            # No target provided, create empty loc_groups (will map all to 'other')\n",
    "            # This happens during pipeline building when we discover schema\n",
    "            self.loc_groups_ = {\n",
    "                'mapping': {},\n",
    "                'low_freq': [],\n",
    "                'groups': {},\n",
    "                'min_samples': self.min_samples,\n",
    "                'bins': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "            }\n",
    "            return self\n",
    "        \n",
    "        # Attach target temporarily to compute location mappings\n",
    "        df = X.copy()\n",
    "        df['target'] = np.asarray(y).ravel()\n",
    "        \n",
    "        # Compute loc_groups from this training fold only\n",
    "        _, loc_groups = apply_feature_engineering(df, loc_groups=None, reference_date=self.reference_date)\n",
    "        self.loc_groups_ = loc_groups\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform data using the learned loc_groups (from fit).\n",
    "        \"\"\"\n",
    "        X_fe, _ = apply_feature_engineering(X.copy(), loc_groups=self.loc_groups_, \n",
    "                                           reference_date=self.reference_date)\n",
    "        # Drop target if it exists (from fit phase)\n",
    "        if 'target' in X_fe.columns:\n",
    "            X_fe = X_fe.drop(columns=['target'])\n",
    "        return X_fe\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X_sample):\n",
    "    \"\"\"\n",
    "    Builds full preprocessing + model pipeline.\n",
    "    \n",
    "    Args:\n",
    "        X_sample: A small sample of raw data (before feature engineering) to\n",
    "                 determine column types after feature engineering\n",
    "    \"\"\"\n",
    "    # Create feature engineering transformer\n",
    "    feat_eng = FeatureEngineerTransformer()\n",
    "    \n",
    "    # Apply to sample to discover column schema (use dummy y if target exists in sample)\n",
    "    sample = X_sample.head(100).copy()\n",
    "    y_dummy = sample['target'] if 'target' in sample.columns else None\n",
    "    if 'target' in sample.columns:\n",
    "        sample = sample.drop(columns=['target'])\n",
    "    X_sample_fe = feat_eng.fit_transform(sample, y_dummy)\n",
    "    X_temp = drop_columns(cap_and_log(X_sample_fe))\n",
    "    \n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    \n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # TF-IDF + SVD for description\n",
    "    if 'description' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=40, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # TF-IDF + SVD for screen_name\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=8, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # Optuna-tuned parameters\n",
    "    model_params = {\n",
    "            'n_estimators': 425,\n",
    "            'learning_rate': 0.022044901543373786,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 0.8434691595054062,\n",
    "            'colsample_bytree': 0.6587724738727377,\n",
    "            'reg_alpha': 0.07414660251138733,\n",
    "            'reg_lambda': 0.6342433928694735,\n",
    "            'min_child_weight': 4,\n",
    "            'gamma': 0.6574372743526198,\n",
    "            'random_state': 42,\n",
    "            'eval_metric': 'logloss'\n",
    "        }\n",
    "    model = XGBClassifier(**model_params)\n",
    "\n",
    "    # Complete pipeline with feature engineering INSIDE\n",
    "    pipeline = Pipeline([\n",
    "        (\"feature_engineering\", FeatureEngineerTransformer()),  #  FIX: Inside pipeline!\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load data\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "\n",
    "    # Prepare training data (NO feature engineering here!)\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    # Build pipeline (pass raw X for schema discovery)\n",
    "    print(\" Building pipeline...\")\n",
    "    pipeline = build_pipeline(X)\n",
    "\n",
    "    # Cross-validation (pipeline handles feature engineering internally)\n",
    "    print(\"\\n Running 5-fold stratified cross-validation...\")\n",
    "    print(\"   (Feature engineering computed separately for each fold)\")\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    \n",
    "    print(f\"\\n CV Results:\")\n",
    "    print(f\"   Mean AUC: {auc_scores.mean():.6f}\")\n",
    "    print(f\"   Std AUC:  {auc_scores.std():.6f}\")\n",
    "    print(f\"   Individual folds: {[f'{s:.6f}' for s in auc_scores]}\")\n",
    "\n",
    "    # Train full model\n",
    "    print(\"\\n Training final model on full training set...\")\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\"\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    print(f\" Model saved to: {model_path}\")\n",
    "\n",
    "    # Predict on test (pipeline handles feature engineering)\n",
    "    print(\"\\n Generating test predictions...\")\n",
    "    test_probs = pipeline.predict_proba(test)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\"\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\" Submission saved to: {submission_path}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb58323",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17a413eb",
   "metadata": {},
   "source": [
    "with Standard scaler 0.946822\n",
    "without: 0.946754\n",
    "\n",
    "mid_lower_bot: 0.946929\n",
    "without sc: 0.946966\n",
    "\n",
    "after fine tune\n",
    "without sc: 0.947048\n",
    "with sc: 0.947080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d195697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Building pipeline for cross-validation (no early stopping)...\n",
      "\n",
      " Running 5-fold stratified cross-validation...\n",
      "   (Feature engineering computed separately for each fold)\n",
      "\n",
      " CV Results:\n",
      "   Mean AUC: 0.947080\n",
      "   Std AUC:  0.003694\n",
      "   Individual folds: ['0.944192', '0.951417', '0.951409', '0.942511', '0.945871']\n",
      "\n",
      "============================================================\n",
      " Training final model WITH early stopping to prevent overfitting...\n",
      "============================================================\n",
      "\n",
      " Training with early stopping (50 rounds)...\n",
      "[0]\tvalidation_0-logloss:0.62579\n",
      "[50]\tvalidation_0-logloss:0.36018\n",
      "[100]\tvalidation_0-logloss:0.29286\n",
      "[150]\tvalidation_0-logloss:0.27066\n",
      "[200]\tvalidation_0-logloss:0.26177\n",
      "[250]\tvalidation_0-logloss:0.25826\n",
      "[300]\tvalidation_0-logloss:0.25656\n",
      "[350]\tvalidation_0-logloss:0.25536\n",
      "[400]\tvalidation_0-logloss:0.25422\n",
      "[450]\tvalidation_0-logloss:0.25416\n",
      "[500]\tvalidation_0-logloss:0.25393\n",
      "[550]\tvalidation_0-logloss:0.25393\n",
      "[585]\tvalidation_0-logloss:0.25418\n",
      "\n",
      " Training stopped at iteration: 536\n",
      "   Best validation logloss: 0.253864\n",
      "   Validation AUC: 0.952026\n",
      "\n",
      " Retraining on FULL training data with n_estimators=536...\n",
      " Model saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\n",
      "\n",
      " Generating test predictions...\n",
      " Submission saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\n",
      "\n",
      " Training complete! Optimal iterations: 536\n"
     ]
    }
   ],
   "source": [
    "# 11_xgboost.py - Fixed version with NO DATA LEAKAGE + Early Stopping\n",
    "# \n",
    "# KEY FIX: Feature engineering (especially location binning) is now done INSIDE\n",
    "# the pipeline using FeatureEngineerTransformer. This ensures that loc_groups\n",
    "# are computed separately for each CV fold, preventing target leakage.\n",
    "#\n",
    "# NEW: Added early stopping to prevent overfitting\n",
    "# - Early stopping is applied during final model training (not CV)\n",
    "# - CV uses model without early stopping to estimate performance\n",
    "# - Final model uses early stopping with a validation split\n",
    "#\n",
    "# Previous issue in 10_xgboost_onehot.py:\n",
    "# - apply_feature_engineering(train) was called BEFORE cross_val_score\n",
    "# - map_loc_bin computed location->target mappings using the FULL training set\n",
    "# - These mappings leaked into CV, making CV scores optimistically biased\n",
    "#\n",
    "# Solution:\n",
    "# - FeatureEngineerTransformer.fit(X, y) computes loc_groups from training fold only\n",
    "# - FeatureEngineerTransformer.transform(X) applies the learned mappings\n",
    "# - Pipeline includes feature engineering as first step\n",
    "# - CV properly fits feature engineering on train folds, transforms on validation folds\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    \n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    \n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        link_pattern = r'(?:http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        bot_pattern = r'\\b(?:bot|automated|auto|rss|feed)\\b'\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        X['description_has_at'] = desc.str.contains(r'@', regex=True).fillna(False).astype(int)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]', regex=True).fillna(False).astype(int)\n",
    "        X['description_has_url_pattern'] = desc.str.contains(r'\\.(?:com|org|net|io)\\b', regex=True).fillna(False).astype(int)\n",
    "    else:\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "        X['description_has_url_pattern'] = 0\n",
    "\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d', regex=True).astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_', regex=True).astype(int)\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        low_bot = ['ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']\n",
    "        mid_bot = ['ja', 'cy', 'so']\n",
    "        mid_lower_bot = ['th', 'pt', 'tr', 'et', 'id', 'fi', 'sl']\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he']\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(mid_lower_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            ['low_freq_lang', 'high_bot_lang', 'mid_bot_lang', 'mid_lower_bot_lang', 'low_bot_lang', 'english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "    return df, loc_groups\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \n",
    "                 \"lang\", \"location\", \"created_at\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Custom Transformer to Avoid Data Leakage ========= #\n",
    "\n",
    "class FeatureEngineerTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Sklearn-compatible transformer that applies feature engineering.\n",
    "    \n",
    "    KEY: On fit(X, y) it computes location groups using the training fold's target.\n",
    "    This prevents data leakage because each CV fold will compute its own loc_groups\n",
    "    from its training split only.\n",
    "    \n",
    "    On transform(X) it applies feature engineering using the stored loc_groups.\n",
    "    \"\"\"\n",
    "    def __init__(self, reference_date=None, min_samples=30):\n",
    "        self.reference_date = reference_date\n",
    "        self.min_samples = min_samples\n",
    "        self.loc_groups_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit on training data. Computes loc_groups from X and y.\n",
    "        \"\"\"\n",
    "        if y is None:\n",
    "            # No target provided, create empty loc_groups (will map all to 'other')\n",
    "            # This happens during pipeline building when we discover schema\n",
    "            self.loc_groups_ = {\n",
    "                'mapping': {},\n",
    "                'low_freq': [],\n",
    "                'groups': {},\n",
    "                'min_samples': self.min_samples,\n",
    "                'bins': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "            }\n",
    "            return self\n",
    "        \n",
    "        # Attach target temporarily to compute location mappings\n",
    "        df = X.copy()\n",
    "        df['target'] = np.asarray(y).ravel()\n",
    "        \n",
    "        # Compute loc_groups from this training fold only\n",
    "        _, loc_groups = apply_feature_engineering(df, loc_groups=None, reference_date=self.reference_date)\n",
    "        self.loc_groups_ = loc_groups\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform data using the learned loc_groups (from fit).\n",
    "        \"\"\"\n",
    "        X_fe, _ = apply_feature_engineering(X.copy(), loc_groups=self.loc_groups_, \n",
    "                                           reference_date=self.reference_date)\n",
    "        # Drop target if it exists (from fit phase)\n",
    "        if 'target' in X_fe.columns:\n",
    "            X_fe = X_fe.drop(columns=['target'])\n",
    "        return X_fe\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X_sample, use_early_stopping=False):\n",
    "    \"\"\"\n",
    "    Builds full preprocessing + model pipeline.\n",
    "    \n",
    "    Args:\n",
    "        X_sample: A small sample of raw data (before feature engineering) to\n",
    "                 determine column types after feature engineering\n",
    "        use_early_stopping: Whether to enable early stopping (only for final training, not CV)\n",
    "    \"\"\"\n",
    "    # Create feature engineering transformer\n",
    "    feat_eng = FeatureEngineerTransformer()\n",
    "    \n",
    "    # Apply to sample to discover column schema (use dummy y if target exists in sample)\n",
    "    sample = X_sample.head(100).copy()\n",
    "    y_dummy = sample['target'] if 'target' in sample.columns else None\n",
    "    if 'target' in sample.columns:\n",
    "        sample = sample.drop(columns=['target'])\n",
    "    X_sample_fe = feat_eng.fit_transform(sample, y_dummy)\n",
    "    X_temp = drop_columns(cap_and_log(X_sample_fe))\n",
    "    \n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    \n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # TF-IDF + SVD for description\n",
    "    if 'description' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=40, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # TF-IDF + SVD for screen_name\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=8, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "    \n",
    "    # XGBClassifier - early stopping only enabled when explicitly requested\n",
    "    model_params = {\n",
    "        'n_estimators': 425,\n",
    "        'learning_rate': 0.022044901543373786,\n",
    "        'max_depth': 10,\n",
    "        'subsample': 0.8434691595054062,\n",
    "        'colsample_bytree': 0.6587724738727377,\n",
    "        'reg_alpha': 0.07414660251138733,\n",
    "        'reg_lambda': 0.6342433928694735,\n",
    "        'min_child_weight': 4,\n",
    "        'gamma': 0.6574372743526198,\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    \n",
    "    #  Only add early_stopping_rounds for final training (not CV)\n",
    "    if use_early_stopping:\n",
    "        model_params['early_stopping_rounds'] = 50\n",
    "    \n",
    "    model = XGBClassifier(**model_params)\n",
    "\n",
    "    # Complete pipeline with feature engineering INSIDE\n",
    "    pipeline = Pipeline([\n",
    "        (\"feature_engineering\", FeatureEngineerTransformer()),\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load data\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "\n",
    "    # Prepare training data (NO feature engineering here!)\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    # ===== STEP 1: Cross-validation WITHOUT early stopping =====\n",
    "    print(\" Building pipeline for cross-validation (no early stopping)...\")\n",
    "    pipeline_cv = build_pipeline(X, use_early_stopping=False)\n",
    "\n",
    "    print(\"\\n Running 5-fold stratified cross-validation...\")\n",
    "    print(\"   (Feature engineering computed separately for each fold)\")\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline_cv, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    \n",
    "    print(f\"\\n CV Results:\")\n",
    "    print(f\"   Mean AUC: {auc_scores.mean():.6f}\")\n",
    "    print(f\"   Std AUC:  {auc_scores.std():.6f}\")\n",
    "    print(f\"   Individual folds: {[f'{s:.6f}' for s in auc_scores]}\")\n",
    "\n",
    "    # ===== STEP 2: Train final model WITH early stopping =====\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" Training final model WITH early stopping to prevent overfitting...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Split data into train and validation for early stopping\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Build a fresh pipeline (to avoid any state issues)\n",
    "    pipeline_final = build_pipeline(X, use_early_stopping=False)\n",
    "    \n",
    "    # Preprocess validation data through pipeline steps (without model)\n",
    "    feat_eng = pipeline_final.named_steps['feature_engineering']\n",
    "    cap_log_step = pipeline_final.named_steps['cap_log']\n",
    "    drop_step = pipeline_final.named_steps['drop']\n",
    "    preprocessor = pipeline_final.named_steps['preprocessor']\n",
    "    \n",
    "    # Fit feature engineering on training data\n",
    "    feat_eng.fit(X_train, y_train)\n",
    "    \n",
    "    # Transform both train and validation\n",
    "    X_train_fe = feat_eng.transform(X_train)\n",
    "    X_val_fe = feat_eng.transform(X_val)\n",
    "    \n",
    "    X_train_cl = cap_log_step.transform(X_train_fe)\n",
    "    X_val_cl = cap_log_step.transform(X_val_fe)\n",
    "    \n",
    "    X_train_dr = drop_step.transform(X_train_cl)\n",
    "    X_val_dr = drop_step.transform(X_val_cl)\n",
    "    \n",
    "    # Fit preprocessor and transform\n",
    "    X_train_processed = preprocessor.fit_transform(X_train_dr)\n",
    "    X_val_processed = preprocessor.transform(X_val_dr)\n",
    "    \n",
    "    # Train XGBoost with early stopping\n",
    "    print(\"\\n Training with early stopping (50 rounds)...\")\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=1000,  # Set high, early stopping will determine actual number\n",
    "        learning_rate=0.022044901543373786,\n",
    "        max_depth=10,\n",
    "        subsample=0.8434691595054062,\n",
    "        colsample_bytree=0.6587724738727377,\n",
    "        reg_alpha=0.07414660251138733,\n",
    "        reg_lambda=0.6342433928694735,\n",
    "        min_child_weight=4,\n",
    "        gamma=0.6574372743526198,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=50  #  Stop if no improvement for 50 rounds\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(\n",
    "        X_train_processed, \n",
    "        y_train,\n",
    "        eval_set=[(X_val_processed, y_val)],  #  Validation set for early stopping\n",
    "        verbose=50  # Show progress every 50 iterations\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n Training stopped at iteration: {xgb_model.best_iteration}\")\n",
    "    print(f\"   Best validation logloss: {xgb_model.best_score:.6f}\")\n",
    "    \n",
    "    # Validate the early stopped model\n",
    "    val_preds = xgb_model.predict_proba(X_val_processed)[:, 1]\n",
    "    val_auc = roc_auc_score(y_val, val_preds)\n",
    "    print(f\"   Validation AUC: {val_auc:.6f}\")\n",
    "    \n",
    "    # ===== STEP 3: Retrain on full data with optimal n_estimators =====\n",
    "    print(f\"\\n Retraining on FULL training data with n_estimators={xgb_model.best_iteration}...\")\n",
    "    \n",
    "    optimal_n_estimators = xgb_model.best_iteration\n",
    "    pipeline_final_full = build_pipeline(X, use_early_stopping=False)\n",
    "    \n",
    "    # Update the model's n_estimators to the optimal value found\n",
    "    pipeline_final_full.named_steps['model'].set_params(n_estimators=optimal_n_estimators)\n",
    "    \n",
    "    # Fit on full training data\n",
    "    pipeline_final_full.fit(X, y)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\"\n",
    "    joblib.dump(pipeline_final_full, model_path)\n",
    "    print(f\" Model saved to: {model_path}\")\n",
    "\n",
    "    # Predict on test (pipeline handles feature engineering)\n",
    "    print(\"\\n Generating test predictions...\")\n",
    "    test_probs = pipeline_final_full.predict_proba(test)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\"\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\" Submission saved to: {submission_path}\")\n",
    "    print(f\"\\n Training complete! Optimal iterations: {optimal_n_estimators}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51da58",
   "metadata": {},
   "source": [
    "with standard scaler\n",
    "old params auc: 0.947080\n",
    "\n",
    "new params: {'n_estimators': 578, 'learning_rate': 0.021177114497701984, 'max_depth': 14, 'subsample': 0.8418080640677738, 'colsample_bytree': 0.6071102813385763, 'reg_alpha': 1.2807246591143306, 'reg_lambda': 0.9419367670130911, 'min_child_weight': 4, 'gamma': 1.3529793966185775}\n",
    "auc: 0.946812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "247676f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Building pipeline...\n",
      "\n",
      " Running 5-fold stratified cross-validation...\n",
      "   (Feature engineering computed separately for each fold)\n",
      "\n",
      " CV Results:\n",
      "   Mean AUC: 0.946812\n",
      "   Std AUC:  0.004026\n",
      "   Individual folds: ['0.944117', '0.951565', '0.951594', '0.941823', '0.944960']\n",
      "\n",
      " Training final model on full training set...\n",
      " Model saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\n",
      "\n",
      " Generating test predictions...\n",
      " Submission saved to: /Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def _fill_text_series(X):\n",
    "    \"\"\"Convert input array-like to a 1D numpy array of strings with NaNs filled.\"\"\"\n",
    "    s = pd.Series(np.asarray(X).ravel()).fillna('').astype(str).values\n",
    "    return s\n",
    "\n",
    "\n",
    "# ========= Feature Engineering Functions ========= #\n",
    "\n",
    "def apply_feature_engineering(X, loc_groups=None, reference_date=None):\n",
    "    X = X.copy()\n",
    "    if reference_date is None:\n",
    "        reference_date = pd.Timestamp.now().normalize()\n",
    "    else:\n",
    "        reference_date = pd.to_datetime(reference_date)\n",
    "    \n",
    "    def safe_ratio(num, denom):\n",
    "        return np.where(denom == 0, 0, num / denom)\n",
    "    \n",
    "    X['followers_friends_ratio'] = safe_ratio(X['followers_count'], X['friends_count'])\n",
    "    X['favourites_per_status'] = safe_ratio(X['favourites_count'], X['statuses_count'])\n",
    "    X['followers_per_day'] = safe_ratio(X['followers_count'], X['account_age_days'])\n",
    "    X['statuses_per_follower'] = safe_ratio(X['statuses_count'], X['followers_count'])\n",
    "\n",
    "    X['is_geo_and_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_and_not_verified'] = np.where((X['geo_enabled'] == True) & (X['verified'] == False), 1, 0)\n",
    "    X['is_not_geo_and_verified'] = np.where((X['geo_enabled'] == False) & (X['verified'] == True), 1, 0)\n",
    "    X['is_geo_or_verified'] = np.where((X['geo_enabled'] == True) | (X['verified'] == True), 1, 0)\n",
    "\n",
    "    if 'description' in X.columns:\n",
    "        desc = X['description'].fillna('').astype(str).str.lower()\n",
    "        link_pattern = r'(?:http[s]?://|www\\.)'\n",
    "        X['description_has_link'] = desc.str.contains(link_pattern, regex=True).fillna(False).astype(int)\n",
    "        bot_pattern = r'\\b(?:bot|automated|auto|rss|feed)\\b'\n",
    "        X['description_has_bot'] = desc.str.contains(bot_pattern, regex=True).fillna(False).astype(int)\n",
    "        X['description_len'] = desc.str.len().fillna(0).astype(int)\n",
    "        X['description_has_at'] = desc.str.contains(r'@', regex=True).fillna(False).astype(int)\n",
    "        X['description_has_emoji'] = desc.str.contains(r'[^\\w\\s,]', regex=True).fillna(False).astype(int)\n",
    "        X['description_has_url_pattern'] = desc.str.contains(r'\\.(?:com|org|net|io)\\b', regex=True).fillna(False).astype(int)\n",
    "    else:\n",
    "        X['description_has_link'] = 0\n",
    "        X['description_has_bot'] = 0\n",
    "        X['description_len'] = 0\n",
    "        X['description_has_at'] = 0\n",
    "        X['description_has_emoji'] = 0\n",
    "        X['description_has_url_pattern'] = 0\n",
    "\n",
    "    if 'screen_name' in X.columns:\n",
    "        sn = X['screen_name'].fillna('').astype(str)\n",
    "        X['screen_name_len'] = sn.str.len().astype(int)\n",
    "        X['screen_name_has_digits'] = sn.str.contains(r'\\d', regex=True).astype(int)\n",
    "        X['screen_name_has_bot'] = sn.str.lower().str.contains(r'bot|auto|_bot|bot_', regex=True).astype(int)\n",
    "        X['screen_name_digit_ratio'] = np.where(X['screen_name_len'] == 0, 0,\n",
    "                                                sn.str.count(r'\\d') / X['screen_name_len'])\n",
    "    else:\n",
    "        X['screen_name_len'] = 0\n",
    "        X['screen_name_has_digits'] = 0\n",
    "        X['screen_name_has_bot'] = 0\n",
    "        X['screen_name_digit_ratio'] = 0\n",
    "\n",
    "    for col in ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "\n",
    "    if 'lang' in X.columns:\n",
    "        lang = X['lang'].fillna('unknown').str.lower()\n",
    "        low_bot = ['ro', 'ru']\n",
    "        high_bot = ['zh-cn', 'ar', 'sw', 'ko', 'af']\n",
    "        mid_bot = ['ja', 'cy', 'so']\n",
    "        mid_lower_bot = ['th', 'pt', 'tr', 'et', 'id', 'fi', 'sl']\n",
    "        low_freq_lang = ['pa', 'zh-tw', 'fa', 'hi', 'el', 'ur', 'bg', 'sq', 'lv', 'mk', 'cs', 'ne', 'uk', 'he']\n",
    "\n",
    "        X['lang_grouped'] = np.select(\n",
    "            [\n",
    "                lang.isin(low_freq_lang),\n",
    "                lang.isin(high_bot),\n",
    "                lang.isin(mid_bot),\n",
    "                lang.isin(mid_lower_bot),\n",
    "                lang.isin(low_bot),\n",
    "                lang.eq('en')\n",
    "            ],\n",
    "            ['low_freq_lang', 'high_bot_lang', 'mid_bot_lang', 'mid_lower_bot_lang', 'low_bot_lang', 'english'],\n",
    "            default='other_lang'\n",
    "        )\n",
    "    else:\n",
    "        X['lang_grouped'] = 'unknown'\n",
    "\n",
    "    if 'location' in X.columns:\n",
    "        X, loc_groups = map_loc_bin(X, loc_groups=loc_groups, min_samples=30)\n",
    "    else:\n",
    "        X['loc_bin_combined'] = 'other'\n",
    "\n",
    "    return X, loc_groups\n",
    "\n",
    "\n",
    "def map_loc_bin(df, loc_groups=None, min_samples=30, bins=None):\n",
    "    \"\"\"\n",
    "    Map locations into proportion bins and flag low-frequency locations.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if bins is None:\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "    labels = [f\"{lo:.2f}-{hi:.2f}\" for lo, hi in zip(bins[:-1], bins[1:])]\n",
    "\n",
    "    if loc_groups is None:\n",
    "        if 'target' not in df.columns:\n",
    "            raise ValueError(\"loc_groups is None -> df must contain 'target' to compute location bot proportions\")\n",
    "        loc_stats = df.groupby('location')['target'].agg(['count', 'sum']).copy()\n",
    "        loc_stats['bot_proportion'] = loc_stats['sum'] / loc_stats['count']\n",
    "        loc_stats_min = loc_stats[loc_stats['count'] >= min_samples].copy()\n",
    "        loc_stats_min['proportion_bin'] = pd.cut(loc_stats_min['bot_proportion'],\n",
    "                                                 bins=bins, labels=labels, include_lowest=True)\n",
    "        groups = {label: loc_stats_min[loc_stats_min['proportion_bin'] == label].sort_values('bot_proportion', ascending=False)\n",
    "                  for label in labels}\n",
    "        mapping = {}\n",
    "        for label, grp in groups.items():\n",
    "            for loc in grp.index:\n",
    "                mapping[loc] = label\n",
    "        low_freq = loc_stats[loc_stats['count'] < min_samples].index.tolist()\n",
    "        loc_groups = {'mapping': mapping, 'low_freq': low_freq, 'groups': groups, 'min_samples': min_samples, 'bins': bins}\n",
    "    else:\n",
    "        if isinstance(loc_groups, dict) and 'mapping' in loc_groups:\n",
    "            mapping = loc_groups['mapping']\n",
    "            low_freq = loc_groups.get('low_freq', [])\n",
    "        elif isinstance(loc_groups, dict):\n",
    "            mapping = loc_groups\n",
    "            low_freq = []\n",
    "            loc_groups = {'mapping': mapping, 'low_freq': low_freq}\n",
    "        else:\n",
    "            raise ValueError(\"loc_groups must be dict (mapping) or None\")\n",
    "\n",
    "    def _map_loc(loc):\n",
    "        if pd.isna(loc):\n",
    "            return 'other'\n",
    "        if loc in low_freq:\n",
    "            return 'low_freq'\n",
    "        return mapping.get(loc, 'other')\n",
    "\n",
    "    df['loc_bin_combined'] = df['location'].apply(_map_loc)\n",
    "    return df, loc_groups\n",
    "\n",
    "\n",
    "def cap_and_log(X):\n",
    "    X = X.copy()\n",
    "    log_cols = [\n",
    "        'favourites_count', 'followers_count', 'friends_count',\n",
    "        'average_tweets_per_day',\n",
    "        'followers_friends_ratio', 'favourites_per_status',\n",
    "        'followers_per_day', 'statuses_per_follower'\n",
    "    ]\n",
    "    for col in log_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = np.where(X[col] > 0, np.log1p(X[col]), 0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def drop_columns(X):\n",
    "    X = X.copy()\n",
    "    drop_cols = [\"id\", \"statuses_count\", \"profile_background_image_url\", \"profile_image_url\", \n",
    "                 \"lang\", \"location\", \"created_at\"]\n",
    "    return X.drop(columns=[c for c in drop_cols if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# ========= Custom Transformer to Avoid Data Leakage ========= #\n",
    "\n",
    "class FeatureEngineerTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Sklearn-compatible transformer that applies feature engineering.\n",
    "    \n",
    "    KEY: On fit(X, y) it computes location groups using the training fold's target.\n",
    "    This prevents data leakage because each CV fold will compute its own loc_groups\n",
    "    from its training split only.\n",
    "    \n",
    "    On transform(X) it applies feature engineering using the stored loc_groups.\n",
    "    \"\"\"\n",
    "    def __init__(self, reference_date=None, min_samples=30):\n",
    "        self.reference_date = reference_date\n",
    "        self.min_samples = min_samples\n",
    "        self.loc_groups_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit on training data. Computes loc_groups from X and y.\n",
    "        \"\"\"\n",
    "        if y is None:\n",
    "            # No target provided, create empty loc_groups (will map all to 'other')\n",
    "            # This happens during pipeline building when we discover schema\n",
    "            self.loc_groups_ = {\n",
    "                'mapping': {},\n",
    "                'low_freq': [],\n",
    "                'groups': {},\n",
    "                'min_samples': self.min_samples,\n",
    "                'bins': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "            }\n",
    "            return self\n",
    "        \n",
    "        # Attach target temporarily to compute location mappings\n",
    "        df = X.copy()\n",
    "        df['target'] = np.asarray(y).ravel()\n",
    "        \n",
    "        # Compute loc_groups from this training fold only\n",
    "        _, loc_groups = apply_feature_engineering(df, loc_groups=None, reference_date=self.reference_date)\n",
    "        self.loc_groups_ = loc_groups\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform data using the learned loc_groups (from fit).\n",
    "        \"\"\"\n",
    "        X_fe, _ = apply_feature_engineering(X.copy(), loc_groups=self.loc_groups_, \n",
    "                                           reference_date=self.reference_date)\n",
    "        # Drop target if it exists (from fit phase)\n",
    "        if 'target' in X_fe.columns:\n",
    "            X_fe = X_fe.drop(columns=['target'])\n",
    "        return X_fe\n",
    "\n",
    "\n",
    "# ========= Build Pipeline ========= #\n",
    "\n",
    "def build_pipeline(X_sample):\n",
    "    \"\"\"\n",
    "    Builds full preprocessing + model pipeline.\n",
    "    \n",
    "    Args:\n",
    "        X_sample: A small sample of raw data (before feature engineering) to\n",
    "                 determine column types after feature engineering\n",
    "    \"\"\"\n",
    "    # Create feature engineering transformer\n",
    "    feat_eng = FeatureEngineerTransformer()\n",
    "    \n",
    "    # Apply to sample to discover column schema (use dummy y if target exists in sample)\n",
    "    sample = X_sample.head(100).copy()\n",
    "    y_dummy = sample['target'] if 'target' in sample.columns else None\n",
    "    if 'target' in sample.columns:\n",
    "        sample = sample.drop(columns=['target'])\n",
    "    X_sample_fe = feat_eng.fit_transform(sample, y_dummy)\n",
    "    X_temp = drop_columns(cap_and_log(X_sample_fe))\n",
    "    \n",
    "    numeric_cols = X_temp.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X_temp.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(max_categories=40, handle_unknown='infrequent_if_exist'))\n",
    "    ])\n",
    "    \n",
    "    transformers = [\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    "\n",
    "    # TF-IDF + SVD for description\n",
    "    if 'description' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"desc_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=2000, ngram_range=(1,2), stop_words='english')),\n",
    "                (\"svd\", TruncatedSVD(n_components=40, random_state=42))\n",
    "            ]),\n",
    "            'description'\n",
    "        ))\n",
    "\n",
    "    # TF-IDF + SVD for screen_name\n",
    "    if 'screen_name' in X_temp.columns:\n",
    "        transformers.append((\n",
    "            \"sn_text\",\n",
    "            Pipeline([\n",
    "                (\"fill\", FunctionTransformer(_fill_text_series, validate=False)),\n",
    "                (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "                (\"svd\", TruncatedSVD(n_components=8, random_state=42))\n",
    "            ]),\n",
    "            'screen_name'\n",
    "        ))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers)\n",
    "\n",
    "    # Optuna-tuned parameters\n",
    "    # model_params = {\n",
    "    #         'n_estimators': 425,\n",
    "    #         'learning_rate': 0.022044901543373786,\n",
    "    #         'max_depth': 10,\n",
    "    #         'subsample': 0.8434691595054062,\n",
    "    #         'colsample_bytree': 0.6587724738727377,\n",
    "    #         'reg_alpha': 0.07414660251138733,\n",
    "    #         'reg_lambda': 0.6342433928694735,\n",
    "    #         'min_child_weight': 4,\n",
    "    #         'gamma': 0.6574372743526198,\n",
    "    #         'random_state': 42,\n",
    "    #         'eval_metric': 'logloss'\n",
    "    #     }\n",
    "    model_params = {'n_estimators': 578, 'learning_rate': 0.021177114497701984, 'max_depth': 14, 'subsample': 0.8418080640677738, 'colsample_bytree': 0.6071102813385763, 'reg_alpha': 1.2807246591143306, 'reg_lambda': 0.9419367670130911, 'min_child_weight': 4, 'gamma': 1.3529793966185775}\n",
    "    model = XGBClassifier(**model_params)\n",
    "\n",
    "    # Complete pipeline with feature engineering INSIDE\n",
    "    pipeline = Pipeline([\n",
    "        (\"feature_engineering\", FeatureEngineerTransformer()),  #  FIX: Inside pipeline!\n",
    "        (\"cap_log\", FunctionTransformer(cap_and_log, validate=False)),\n",
    "        (\"drop\", FunctionTransformer(drop_columns, validate=False)),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ========= Main ========= #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load data\n",
    "    train = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/train.csv\")\n",
    "    test = pd.read_csv(\"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/data/test.csv\")\n",
    "\n",
    "    # Prepare training data (NO feature engineering here!)\n",
    "    X = train.drop(columns=[\"target\"])\n",
    "    y = train[\"target\"]\n",
    "\n",
    "    # Build pipeline (pass raw X for schema discovery)\n",
    "    print(\" Building pipeline...\")\n",
    "    pipeline = build_pipeline(X)\n",
    "\n",
    "    # Cross-validation (pipeline handles feature engineering internally)\n",
    "    print(\"\\n Running 5-fold stratified cross-validation...\")\n",
    "    print(\"   (Feature engineering computed separately for each fold)\")\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"roc_auc\", error_score='raise')\n",
    "    \n",
    "    print(f\"\\n CV Results:\")\n",
    "    print(f\"   Mean AUC: {auc_scores.mean():.6f}\")\n",
    "    print(f\"   Std AUC:  {auc_scores.std():.6f}\")\n",
    "    print(f\"   Individual folds: {[f'{s:.6f}' for s in auc_scores]}\")\n",
    "\n",
    "    # Train full model\n",
    "    print(\"\\n Training final model on full training set...\")\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/models/xgboost_pipeline_fixed.pkl\"\n",
    "    joblib.dump(pipeline, model_path)\n",
    "    print(f\" Model saved to: {model_path}\")\n",
    "\n",
    "    # Predict on test (pipeline handles feature engineering)\n",
    "    print(\"\\n Generating test predictions...\")\n",
    "    test_probs = pipeline.predict_proba(test)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"index\": test.index,\n",
    "        \"target\": test_probs\n",
    "    })\n",
    "\n",
    "    submission_path = \"/Users/maximus/Downloads/SCHOOL/bt4012/bt-4012-in-class-kaggle-competiton-1-2025/outputs/submission_fixed.csv\"\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\" Submission saved to: {submission_path}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
