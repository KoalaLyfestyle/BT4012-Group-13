{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9738e86",
   "metadata": {},
   "source": [
    "# Phishing URL Linear Model Experiments\n",
    "\n",
    "This notebook explores various linear models using the Kaggle phishing URL dataset.\n",
    "\n",
    "In increasing order of complexity, we will experiment with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af33e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report, roc_curve)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "train_w_features_df = pd.read_csv('dataset/df_train_feature_engineered.csv')\n",
    "test_w_features_df = pd.read_csv('dataset/df_test_feature_engineered.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "print(f\"Train with features shape: {train_w_features_df.shape}\")\n",
    "print(f\"Test with features shape: {test_w_features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_features_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd5c46",
   "metadata": {},
   "source": [
    "Following the EDA, we use the transformed features and drop the original ones since linear models require normalized and scaled inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3287fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original versions of log transformed features\n",
    "train_w_features_df.drop(columns=['length_url', 'length_path',  'ratio_hostname_url', 'length_words_url', 'avg_word_hostname', 'num_unique_chars_hostname'], inplace=True)\n",
    "\n",
    "# Drop original versions of squared transformed features\n",
    "train_w_features_df.drop(columns=['ratio_letter_url', 'entropy_hostname'], inplace=True)\n",
    "\n",
    "# Drop original versions of is_zero transformed features\n",
    "train_w_features_df.drop(columns=['num_hyphens_domain', 'length_subdomains', 'num_hyphens',  'num_at', 'num_question_marks', 'num_and', 'num_equal', 'num_percent', 'ratio_digits_url', 'ratio_digits_hostname', 'avg_word_path', 'length_query'], inplace=True)\n",
    "\n",
    "# Drop original versions of bucketed transformed features\n",
    "train_w_features_df.drop(columns=['num_subdomain', 'length_tld', 'path_depth'], inplace=True)\n",
    "\n",
    "# Check final columns\n",
    "train_w_features_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229250e",
   "metadata": {},
   "source": [
    "## Training Models\n",
    "\n",
    "Now lets move on to training the models. We use the saver class to help us standardize the storing of metrics and models for evaluation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35654109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ModelSaver\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "from save_model import ModelSaver\n",
    "\n",
    "# Configuration\n",
    "SAVE_MODELS = True\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Check device (not strictly needed for sklearn but good for consistency)\n",
    "print(f\"Running on: {sys.platform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Preparation ---\n",
    "\n",
    "# 1. Prepare Numeric Features\n",
    "# Select numeric and boolean columns and exclude target\n",
    "numeric_cols = train_w_features_df.select_dtypes(include=[np.number, bool]).columns.tolist()\n",
    "if 'target' in numeric_cols:\n",
    "    numeric_cols.remove('target')\n",
    "\n",
    "print(f\"Selected {len(numeric_cols)} numeric/boolean features.\")\n",
    "\n",
    "# Ensure boolean columns are converted to integers (0/1) for the model\n",
    "X_numeric = train_w_features_df[numeric_cols].astype(float).values\n",
    "y = train_w_features_df['target'].values\n",
    "\n",
    "# Prepare Test Data for Numeric\n",
    "X_numeric_test = test_w_features_df[numeric_cols].astype(float).values\n",
    "\n",
    "# 2. Prepare Text Features (URLs)\n",
    "X_text = train_df['url'].values\n",
    "X_text_test = test_df['url'].values\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Numeric Train Shape: {X_numeric.shape}\")\n",
    "print(f\"Numeric Test Shape: {X_numeric_test.shape}\")\n",
    "print(f\"Text Train Shape: {X_text.shape}\")\n",
    "print(f\"Text Test Shape: {X_text_test.shape}\")\n",
    "print(f\"Target Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74110c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def calculate_metrics(y_true, y_pred_proba, threshold=0.5):\n",
    "    \"\"\"Calculate standard metrics for binary classification.\"\"\"\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_true, y_pred_proba),\n",
    "        'TP': int(tp), 'FP': int(fp), 'TN': int(tn), 'FN': int(fn)\n",
    "    }\n",
    "\n",
    "def run_cv_experiment(X, y, X_test, pipeline_creator, experiment_name, model_name, vectorizer_name, params, feature_names_func=None):\n",
    "    \"\"\"\n",
    "    Run a cross-validation experiment and save results using ModelSaver.\n",
    "    \n",
    "    Args:\n",
    "        X: Training features\n",
    "        y: Training targets\n",
    "        X_test: Test features\n",
    "        pipeline_creator: Function that returns a fresh sklearn Pipeline\n",
    "        experiment_name: Name of the experiment for saving\n",
    "        model_name: Name of the model type\n",
    "        vectorizer_name: Name of the vectorizer/feature set\n",
    "        params: Dictionary containing 'model_params' and 'vectorizer_params'\n",
    "        feature_names_func: Optional function to extract feature names from fitted pipeline\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Running Experiment: {experiment_name} ===\")\n",
    "    \n",
    "    saver = ModelSaver(base_path=\"experiments\")\n",
    "    saver.start_experiment(\n",
    "        experiment_name=experiment_name,\n",
    "        model_type=model_name,\n",
    "        vectorizer=vectorizer_name,\n",
    "        vectorizer_params=params.get('vectorizer_params', {}),\n",
    "        model_params=params.get('model_params', {}),\n",
    "        n_folds=N_FOLDS\n",
    "    )\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
    "        print(f\"Fold {fold}/{N_FOLDS}\")\n",
    "        \n",
    "        # Split data\n",
    "                # Split data\n",
    "        if hasattr(X, \"iloc\"): # Check if DataFrame\n",
    "             X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        else:\n",
    "             X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        \n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Create and fit pipeline\n",
    "        pipeline = pipeline_creator()\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Validation metrics\n",
    "        val_probs = pipeline.predict_proba(X_val_fold)[:, 1]\n",
    "        val_metrics = calculate_metrics(y_val_fold, val_probs)\n",
    "        val_metrics['fold'] = fold\n",
    "        \n",
    "        print(f\"  Val AUC: {val_metrics['roc_auc']:.4f}\")\n",
    "        \n",
    "        # Test predictions (for ensemble later)\n",
    "        test_probs = pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Get feature names if possible\n",
    "        feature_names = None\n",
    "        if feature_names_func:\n",
    "            try:\n",
    "                feature_names = feature_names_func(pipeline)\n",
    "            except Exception as e:\n",
    "                print(f\"  Could not extract feature names: {e}\")\n",
    "            \n",
    "        saver.add_fold(\n",
    "            fold_model=pipeline,\n",
    "            fold_metric=val_metrics,\n",
    "            test_predictions=test_probs,\n",
    "            feature_names=feature_names\n",
    "        )\n",
    "        \n",
    "    saver.finalize_experiment()\n",
    "    print(f\"Experiment saved to {saver._exp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d06d47",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression (Engineered Numeric Features)\n",
    "\n",
    "We first test a simple Logistic Regression model using only the manually engineered numeric features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c137f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numeric_lr_pipeline():\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, solver='lbfgs'))\n",
    "    ])\n",
    "\n",
    "def get_numeric_feature_names(pipeline):\n",
    "    return numeric_cols\n",
    "\n",
    "numeric_params = {\n",
    "    'model_params': {'max_iter': 1000, 'solver': 'lbfgs'},\n",
    "    'vectorizer_params': {'type': 'StandardScaler'}\n",
    "}\n",
    "\n",
    "run_cv_experiment(\n",
    "    X=X_numeric, \n",
    "    y=y, \n",
    "    X_test=X_numeric_test,\n",
    "    pipeline_creator=create_numeric_lr_pipeline,\n",
    "    experiment_name=\"exp_1_numeric_lr\",\n",
    "    model_name=\"LogisticRegression\",\n",
    "    vectorizer_name=\"NumericFeatures\",\n",
    "    params=numeric_params,\n",
    "    feature_names_func=get_numeric_feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee0974",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression (TF-IDF Features)\n",
    "\n",
    "Next, we test Logistic Regression using TF-IDF features extracted directly from the URL strings. We use character n-grams to capture patterns in the URL structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15871e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_lr_pipeline():\n",
    "    return Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, analyzer='char', ngram_range=(3, 5))),\n",
    "        ('clf', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))\n",
    "    ])\n",
    "\n",
    "def get_tfidf_feature_names(pipeline):\n",
    "    return pipeline.named_steps['tfidf'].get_feature_names_out().tolist()\n",
    "\n",
    "tfidf_params = {\n",
    "    'model_params': {'max_iter': 1000},\n",
    "    'vectorizer_params': {'max_features': 5000, 'analyzer': 'char', 'ngram_range': (3, 5)}\n",
    "}\n",
    "\n",
    "run_cv_experiment(\n",
    "    X=X_text, \n",
    "    y=y, \n",
    "    X_test=X_text_test,\n",
    "    pipeline_creator=create_tfidf_lr_pipeline,\n",
    "    experiment_name=\"exp_1_tfidf_lr\",\n",
    "    model_name=\"LogisticRegression\",\n",
    "    vectorizer_name=\"TfidfVectorizer\",\n",
    "    params=tfidf_params,\n",
    "    feature_names_func=get_tfidf_feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf17bc6",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression (Combined Features)\n",
    "\n",
    "Since we see that tf-idf features perform better, lets try combining both feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ede24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined DataFrame with both text and numeric features\n",
    "X_combined_df = train_w_features_df[numeric_cols].copy()\n",
    "X_combined_df['url'] = train_df['url']\n",
    "\n",
    "X_combined_test_df = test_w_features_df[numeric_cols].copy()\n",
    "X_combined_test_df['url'] = test_df['url']\n",
    "\n",
    "# Define the preprocessor\n",
    "# Note: TfidfVectorizer expects a 1D array, so we specify the column name 'url'\n",
    "# but we might need a custom transformer or ensure ColumnTransformer passes it correctly.\n",
    "# ColumnTransformer passes the column as a Series (which is array-like) to TfidfVectorizer.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, analyzer='char', ngram_range=(3, 5)), 'url'),\n",
    "        ('scaler', StandardScaler(), numeric_cols)\n",
    "    ],\n",
    "    remainder='drop' # Drop any other columns if present\n",
    ")\n",
    "\n",
    "def create_combined_lr_pipeline():\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))\n",
    "    ])\n",
    "\n",
    "def get_combined_feature_names(pipeline):\n",
    "    # Extract feature names from the preprocessor\n",
    "    tfidf_features = pipeline.named_steps['preprocessor'].named_transformers_['tfidf'].get_feature_names_out().tolist()\n",
    "    # Numeric features are passed through, so their names are preserved\n",
    "    return tfidf_features + numeric_cols\n",
    "\n",
    "combined_params = {\n",
    "    'model_params': {'max_iter': 1000},\n",
    "    'vectorizer_params': {'tfidf': {'max_features': 5000, 'analyzer': 'char', 'ngram_range': (3, 5)}, 'scaler': 'StandardScaler'}\n",
    "}\n",
    "\n",
    "run_cv_experiment(\n",
    "    X=X_combined_df, \n",
    "    y=y, \n",
    "    X_test=X_combined_test_df,\n",
    "    pipeline_creator=create_combined_lr_pipeline,\n",
    "    experiment_name=\"exp_1_combined_lr\",\n",
    "    model_name=\"LogisticRegression\",\n",
    "    vectorizer_name=\"CombinedFeatures\",\n",
    "    params=combined_params,\n",
    "    feature_names_func=get_combined_feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594fc18",
   "metadata": {},
   "source": [
    "### 4. SVM (Combined Features)\n",
    "\n",
    "Our combined features seem to perform better overall, telling us that both feature sets contribute useful information. Lets try using SVM to see if accuracy improves further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_svm_pipeline():\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', SVC(kernel='linear', C=1.0, random_state=RANDOM_STATE, probability=True))\n",
    "    ])\n",
    "\n",
    "combined_svm_params = {\n",
    "    'model_params': {'kernel': 'linear', 'C': 1.0, 'probability': True},\n",
    "    'vectorizer_params': {'tfidf': {'max_features': 5000, 'analyzer': 'char', 'ngram_range': (3, 5)}, 'scaler': 'StandardScaler'}\n",
    "}\n",
    "\n",
    "run_cv_experiment(\n",
    "    X=X_combined_df, \n",
    "    y=y, \n",
    "    X_test=X_combined_test_df,\n",
    "    pipeline_creator=create_combined_svm_pipeline,\n",
    "    experiment_name=\"exp_1_combined_svm\",\n",
    "    model_name=\"SVM\",\n",
    "    vectorizer_name=\"CombinedFeatures\",\n",
    "    params=combined_svm_params,\n",
    "    feature_names_func=get_combined_feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d969f32",
   "metadata": {},
   "source": [
    "### 5. Optuna Hyperparameter Tuning\n",
    "\n",
    "We will use Optuna to tune the hyperparameters of our best model (SVM) to see if we can improve performance further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.exceptions import TrialPruned\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_STATE, multivariate=True, group=True)\n",
    "pruner = MedianPruner(n_startup_trials=10, n_warmup_steps=0)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective to tune a calibrated LinearSVC on combined features.\"\"\"\n",
    "    C = trial.suggest_float('C', 1e-4, 1e3, log=True)\n",
    "    class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "    loss = trial.suggest_categorical('loss', ['hinge', 'squared_hinge'])\n",
    "    if loss == 'hinge':\n",
    "        dual = True\n",
    "    else:\n",
    "        dual = trial.suggest_categorical('dual', [True, False])\n",
    "    tol = trial.suggest_float('tol', 1e-5, 1e-2, log=True)\n",
    "    max_iter = trial.suggest_int('max_iter', 2000, 20000)\n",
    "    calibration_method = trial.suggest_categorical('calibration_method', ['sigmoid', 'isotonic'])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_aucs = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_combined_df, y)):\n",
    "        X_train_fold, X_val_fold = X_combined_df.iloc[train_idx], X_combined_df.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        base_estimator = LinearSVC(\n",
    "            C=C,\n",
    "            class_weight=class_weight,\n",
    "            loss=loss,\n",
    "            dual=dual,\n",
    "            tol=tol,\n",
    "            max_iter=max_iter,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        \n",
    "        calibrated_clf = CalibratedClassifierCV(\n",
    "            estimator=base_estimator,\n",
    "            cv=3,\n",
    "            method=calibration_method,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clf', calibrated_clf)\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            val_probs = model.predict_proba(X_val_fold)[:, 1]\n",
    "            fold_auc = roc_auc_score(y_val_fold, val_probs)\n",
    "        except ValueError as exc:\n",
    "            raise TrialPruned() from exc\n",
    "\n",
    "        fold_aucs.append(fold_auc)\n",
    "        trial.report(fold_auc, step=fold_idx)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise TrialPruned()\n",
    "\n",
    "    mean_auc = float(np.mean(fold_aucs))\n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler=sampler, pruner=pruner)\n",
    "study.optimize(objective, n_trials=60, show_progress_bar=True)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best AUC:', study.best_value)\n",
    "print('Best params:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params.copy()\n",
    "best_params['random_state'] = RANDOM_STATE\n",
    "best_params['dual'] = best_params.get('dual', True if best_params['loss'] == 'hinge' else True)\n",
    "best_params['max_iter'] = int(best_params['max_iter'])\n",
    "calibration_method = best_params.pop('calibration_method')\n",
    "\n",
    "def create_tuned_linear_svc_pipeline():\n",
    "    base_estimator = LinearSVC(\n",
    "        C=best_params['C'],\n",
    "        class_weight=best_params['class_weight'],\n",
    "        loss=best_params['loss'],\n",
    "        dual=best_params['dual'],\n",
    "        tol=best_params['tol'],\n",
    "        max_iter=best_params['max_iter'],\n",
    "        random_state=best_params['random_state']\n",
    "    )\n",
    "    calibrated_clf = CalibratedClassifierCV(\n",
    "        estimator=base_estimator,\n",
    "        cv=3,\n",
    "        method=calibration_method,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', calibrated_clf)\n",
    "    ])\n",
    "\n",
    "tuned_linear_svc_params = {\n",
    "    'model_params': {**best_params, 'calibration_method': calibration_method, 'calibration_cv': 3},\n",
    "    'vectorizer_params': {'tfidf': {'max_features': 5000, 'analyzer': 'char', 'ngram_range': (3, 5)}, 'scaler': 'StandardScaler'}\n",
    "}\n",
    "\n",
    "print(\"Running final experiment with tuned LinearSVC parameters...\")\n",
    "run_cv_experiment(\n",
    "    X=X_combined_df, \n",
    "    y=y, \n",
    "    X_test=X_combined_test_df,\n",
    "    pipeline_creator=create_tuned_linear_svc_pipeline,\n",
    "    experiment_name=\"exp_1_combined_linear_svc_optuna\",\n",
    "    model_name=\"LinearSVC\",\n",
    "    vectorizer_name=\"CombinedFeatures\",\n",
    "    params=tuned_linear_svc_params,\n",
    "    feature_names_func=get_combined_feature_names\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
