{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40acefe8",
   "metadata": {
    "id": "40acefe8"
   },
   "source": [
    "# Phishing URL Transformer Model Experiments\n",
    "\n",
    "This notebook explores various transformer architectures using the Kaggle phishing URL dataset.\n",
    "\n",
    "In increasing order of complexity, we will experiment with:\n",
    "\n",
    "1. DeBERTa on URL only\n",
    "2. DeBERTa on URL and Engineered Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30d6e1",
   "metadata": {
    "id": "fd30d6e1"
   },
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006c1f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f006c1f0",
    "outputId": "d2a06245-720a-470d-aa11-af5dfb1c9ef5"
   },
   "outputs": [],
   "source": [
    "use_drive = False\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "use_drive = True\n",
    "drive_root = '/content/drive/MyDrive/fraud-grp-proj/'\n",
    "print(os.path.exists(drive_root)) # check path exists\n",
    "\n",
    "base_path = os.path.join(drive_root, \"experiments\")\n",
    "\n",
    "from save_model import ModelSaver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190dc67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5190dc67",
    "outputId": "f9ce6d80-7935-4dea-d218-46bb3b85927a"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix,\n",
    "                             classification_report, roc_curve)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f895aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46f895aa",
    "outputId": "876c683d-cae6-451d-bbbf-4380aae30c0c"
   },
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "train_w_features_df = pd.read_csv('dataset/df_train_feature_engineered.csv')\n",
    "test_w_features_df = pd.read_csv('dataset/df_test_feature_engineered.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "print(f\"Train with features shape: {train_w_features_df.shape}\")\n",
    "print(f\"Test with features shape: {test_w_features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe3ec5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1fe3ec5",
    "outputId": "aae2c1a5-b7fa-4ac5-b74d-9079eacd6092"
   },
   "outputs": [],
   "source": [
    "train_w_features_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L0sCrmLog0Wq",
   "metadata": {
    "id": "L0sCrmLog0Wq"
   },
   "source": [
    "#Transformer-Based Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WGY0HqWXp-2y",
   "metadata": {
    "id": "WGY0HqWXp-2y"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "MAX_LEN = 256\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yw86vTbliUeS",
   "metadata": {
    "id": "Yw86vTbliUeS"
   },
   "outputs": [],
   "source": [
    "class URLOnlyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=MAX_LEN):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        enc = self.tokenizer(\n",
    "            row[\"url\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(enc[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(enc[\"attention_mask\"], dtype=torch.long),\n",
    "            \"labels\": torch.tensor(row[\"target\"], dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ofqxd7v9I6XB",
   "metadata": {
    "id": "ofqxd7v9I6XB"
   },
   "outputs": [],
   "source": [
    "class URLWithFeaturesDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, feature_cols, max_len=MAX_LEN):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_cols = feature_cols\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        enc = self.tokenizer(\n",
    "            row[\"url\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len\n",
    "        )\n",
    "        features = row[self.feature_cols].values.astype(\"float32\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(enc[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(enc[\"attention_mask\"], dtype=torch.long),\n",
    "            \"features\": torch.tensor(features, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(row[\"target\"], dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4jVwFwPfI6YL",
   "metadata": {
    "id": "4jVwFwPfI6YL"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    out = {\n",
    "        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n",
    "        \"attention_mask\": torch.stack([b[\"attention_mask\"] for b in batch]),\n",
    "        \"labels\": torch.stack([b[\"labels\"] for b in batch]),\n",
    "    }\n",
    "    if \"features\" in batch[0]:\n",
    "        out[\"features\"] = torch.stack([b[\"features\"] for b in batch])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O2D8sWppqDq9",
   "metadata": {
    "id": "O2D8sWppqDq9"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "def DebertaURLOnly():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6PbBzcI96S",
   "metadata": {
    "id": "5f6PbBzcI96S"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig, PreTrainedModel, DebertaV2Config\n",
    "\n",
    "# Define our custom config by inheriting from the specific base model config\n",
    "class DebertaWithFeaturesConfig(DebertaV2Config):\n",
    "    model_type = \"deberta_with_features\" # Custom model_type for identification\n",
    "\n",
    "    def __init__(self, num_features=0, **kwargs):\n",
    "        super().__init__(**kwargs) # Call the parent DebertaV2Config constructor\n",
    "        self.num_features = num_features # Add our custom attribute\n",
    "\n",
    "\n",
    "class DebertaWithFeatures(PreTrainedModel):\n",
    "    config_class = DebertaWithFeaturesConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        # Load pretrained DeBERTa encoder using its standard config.\n",
    "        # AutoModel.from_pretrained will automatically load the correct DebertaV2Config\n",
    "        # and weights based on MODEL_NAME.\n",
    "        self.deberta = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        # Ensure hidden size is retrieved from the DeBERTa model's config\n",
    "        hidden = self.deberta.config.hidden_size\n",
    "\n",
    "        # Feature projection - `config` here is DebertaWithFeaturesConfig, which has num_features\n",
    "        self.feature_proj = nn.Sequential(\n",
    "            nn.Linear(config.num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        # Combined classifier\n",
    "        self.classifier = nn.Linear(hidden + 128, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, features, labels=None):\n",
    "        out = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]\n",
    "\n",
    "        feat_emb = self.feature_proj(features)\n",
    "        combined = torch.cat([cls, feat_emb], dim=1)\n",
    "\n",
    "        logits = self.classifier(combined)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "\n",
    "def create_deberta_with_features(num_features):\n",
    "    # Load the standard DeBERTaV2Config from the pretrained model\n",
    "    base_deberta_config = DebertaV2Config.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # Create an instance of our custom config,\n",
    "    # incorporating all parameters from the base config and adding num_features\n",
    "    config = DebertaWithFeaturesConfig(\n",
    "        num_features=num_features,\n",
    "        **base_deberta_config.to_dict()\n",
    "    )\n",
    "    return DebertaWithFeatures(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PPCvSyFUqFD-",
   "metadata": {
    "id": "PPCvSyFUqFD-"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
    "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(labels, probs),\n",
    "        \"TP\": cm[1, 1],\n",
    "        \"FP\": cm[0, 1],\n",
    "        \"TN\": cm[0, 0],\n",
    "        \"FN\": cm[1, 0]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fl9ryJ9nqLdK",
   "metadata": {
    "id": "Fl9ryJ9nqLdK"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "def run_transformer_experiment(model_type, experiment_name):\n",
    "    print(f\"\\n=== Running {experiment_name} ({model_type}) ===\")\n",
    "\n",
    "    saver = ModelSaver(base_path=base_path)\n",
    "    saver.start_experiment(\n",
    "        experiment_name=experiment_name,\n",
    "        model_type=\"DeBERTa Transformer\",\n",
    "        vectorizer=\"DeBERTa Tokenizer\",\n",
    "        vectorizer_params={\"model\": MODEL_NAME, \"max_len\": MAX_LEN},\n",
    "        model_params={\"epochs\": 2, \"batch_size\": 16},\n",
    "        n_folds=5,\n",
    "        save_format=\"transformers\"\n",
    "    )\n",
    "\n",
    "    # Preprocess categorical columns for both train and test dataframes\n",
    "    global train_w_features_df, test_w_features_df\n",
    "\n",
    "    # List of categorical columns to one-hot encode\n",
    "    categorical_cols_to_encode = [col for col in train_w_features_df.select_dtypes(include=['object']).columns if col not in ['url']]\n",
    "    if \"target\" in categorical_cols_to_encode: # ensure target is not encoded if it's an object type\n",
    "      categorical_cols_to_encode.remove(\"target\")\n",
    "\n",
    "    if categorical_cols_to_encode:\n",
    "        print(f\"One-hot encoding columns: {categorical_cols_to_encode}\")\n",
    "        train_w_features_df = pd.get_dummies(train_w_features_df, columns=categorical_cols_to_encode, prefix=[f'ohe_{col}' for col in categorical_cols_to_encode])\n",
    "        test_w_features_df = pd.get_dummies(test_w_features_df, columns=categorical_cols_to_encode, prefix=[f'ohe_{col}' for col in categorical_cols_to_encode])\n",
    "\n",
    "        # Align columns between train and test after one-hot encoding\n",
    "        train_cols = set(train_w_features_df.columns)\n",
    "        test_cols = set(test_w_features_df.columns)\n",
    "\n",
    "        missing_in_test = list(train_cols - test_cols)\n",
    "        for col in missing_in_test:\n",
    "            if col != 'url' and col != 'target': # Exclude url and target from adding as zero columns\n",
    "                test_w_features_df[col] = 0\n",
    "\n",
    "        missing_in_train = list(test_cols - train_cols)\n",
    "        for col in missing_in_train:\n",
    "            if col != 'url' and col != 'target': # Exclude url and target from adding as zero columns\n",
    "                train_w_features_df[col] = 0\n",
    "\n",
    "        # Ensure columns are in the same order\n",
    "        test_w_features_df = test_w_features_df[train_w_features_df.columns]\n",
    "\n",
    "    feature_cols = [c for c in train_w_features_df.columns if c not in [\"url\", \"target\"]]\n",
    "    num_features = len(feature_cols)\n",
    "\n",
    "    # Prepare test dataset\n",
    "    if model_type == \"url_only\":\n",
    "        test_dataset = URLOnlyDataset(test_df, tokenizer)\n",
    "        test_data_collator = None\n",
    "    else:\n",
    "        test_dataset = URLWithFeaturesDataset(test_w_features_df, tokenizer, feature_cols)\n",
    "        test_data_collator = collate_fn\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df[\"target\"]), start=1):\n",
    "        print(f\"\\n--- Fold {fold_idx}/5 ---\")\n",
    "\n",
    "        if model_type == \"url_only\":\n",
    "            train_fold = train_df.iloc[train_idx]\n",
    "            val_fold = train_df.iloc[val_idx]\n",
    "\n",
    "            train_dataset = URLOnlyDataset(train_fold, tokenizer)\n",
    "            val_dataset = URLOnlyDataset(val_fold, tokenizer)\n",
    "\n",
    "            model = DebertaURLOnly()\n",
    "            data_collator = None\n",
    "\n",
    "        else:\n",
    "            train_fold = train_w_features_df.iloc[train_idx]\n",
    "            val_fold = train_w_features_df.iloc[val_idx]\n",
    "\n",
    "            train_dataset = URLWithFeaturesDataset(train_fold, tokenizer, feature_cols)\n",
    "            val_dataset = URLWithFeaturesDataset(val_fold, tokenizer, feature_cols)\n",
    "\n",
    "            model = create_deberta_with_features(num_features)\n",
    "            data_collator = collate_fn\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            output_dir=f\"./tmp_{experiment_name}_fold_{fold_idx}\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"no\",\n",
    "            learning_rate=2e-5,\n",
    "            weight_decay=0.01,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=32,\n",
    "            num_train_epochs=2,\n",
    "            logging_steps=50,\n",
    "            remove_unused_columns=False,\n",
    "            report_to=\"none\",\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "            data_collator=data_collator\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        metrics = trainer.evaluate()\n",
    "        print(f\"Fold {fold_idx} ROC AUC: {metrics['eval_roc_auc']:.4f}\")\n",
    "\n",
    "        # Predict on test set\n",
    "        test_preds = trainer.predict(test_dataset)\n",
    "        test_logits = test_preds.predictions\n",
    "        test_probs = torch.softmax(torch.tensor(test_logits), dim=1)[:, 1].numpy()\n",
    "\n",
    "        fold_metrics = {k.replace(\"eval_\", \"\"): v for k, v in metrics.items()}\n",
    "        fold_metrics[\"fold\"] = fold_idx\n",
    "\n",
    "        saver.add_fold(\n",
    "            fold_model=(model, tokenizer),\n",
    "            fold_metric=fold_metrics,\n",
    "            test_predictions=test_probs\n",
    "        )\n",
    "\n",
    "        fold_results.append(fold_metrics)\n",
    "\n",
    "    saver.finalize_experiment()\n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OXiCiJPsqNe9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OXiCiJPsqNe9",
    "outputId": "686055fc-8917-4e26-9ae1-0c4e1142c509"
   },
   "outputs": [],
   "source": [
    "results = run_transformer_experiment(\"url_only\", \"exp_4_deberta_url_only\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8vh2iLLzqPlg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8vh2iLLzqPlg",
    "outputId": "248eff2d-6fec-46b2-c4c2-326e84028bba"
   },
   "outputs": [],
   "source": [
    "results2 = run_transformer_experiment(\"url_features\", \"exp_4_deberta_url_features\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
